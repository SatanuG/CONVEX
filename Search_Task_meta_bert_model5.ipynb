{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35475,
     "status": "ok",
     "timestamp": 1597358536347,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "4kEFttWg0B4y",
    "outputId": "6c285bab-c294-4587-c61a-d9e308f0b40b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive',  force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11095,
     "status": "ok",
     "timestamp": 1597358547385,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "7xBUaZBf0Bor",
    "outputId": "ce258d27-b705-44d1-f018-1488dda2d5fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
      "\r",
      "\u001b[K     |▍                               | 10kB 16.5MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 20kB 21.2MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 30kB 23.8MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 40kB 21.6MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 51kB 16.1MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 61kB 13.9MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 71kB 13.3MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 81kB 13.1MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 92kB 12.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 102kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 112kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 122kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 133kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 143kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 153kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 163kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 174kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 184kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 194kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 204kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 215kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 225kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 235kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 245kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 256kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 266kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 276kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 286kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 296kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 307kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 317kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 327kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 337kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 348kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 358kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 368kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 378kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 389kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 399kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 409kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 419kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 430kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 440kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 450kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 460kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 471kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 481kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 491kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 501kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 512kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 522kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 532kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 542kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 552kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 563kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 573kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 583kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 593kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 604kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 614kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 624kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 634kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 645kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 655kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 665kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 675kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 686kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 696kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 706kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 716kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 727kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 737kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 747kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 757kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 768kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 778kB 13.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 43.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 45.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 45.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=aca355c3f795ac06a0da3a7ab9fcf122b99d1dd9c8f88fda581748d03bbce013\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8520,
     "status": "ok",
     "timestamp": 1597358553425,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "fwYkpYAP0LD8"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4128,
     "status": "ok",
     "timestamp": 1597358553431,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "cPah4WHvMICz"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "16d2cb6bd9694f108856ebbd50f7e87f",
      "458ca1c7330b467d91046cdb235396f9",
      "aa9c7ce6e1f6462186db4faa5d239f74",
      "453b861e1ca84482b2f675a78aa8b963",
      "08225350738f4eda80b04e7acd78ab6f",
      "91aa0aeca61d4f0f8854d605f02dd0ac",
      "a4acee8ccfaa4226874f765ae468b01d",
      "6b37793c0f9547f58012dbc5e2e933d4",
      "d6d3c033fcff4b898a3da807cbc16c65",
      "0116bcbc437945248db742e3e8449119",
      "16ae2bcc93254828bb381680db1e0ec9",
      "8fda16b2d2bf478088b516948be38856",
      "4b2ce0e2377a48ae9c467ff55d145015",
      "5bf09a37e050409089d1bdb16d026e68",
      "9a706da06583442d867ea30378f0a7fa",
      "a02b1e0fccae4eea9dbc22987ebedcd2"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27433,
     "status": "ok",
     "timestamp": 1597358580779,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "wbl-sqxJ0Qt1",
    "outputId": "137c31f0-af65-49c0-e938-d7c39e964213"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d2cb6bd9694f108856ebbd50f7e87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d3c033fcff4b898a3da807cbc16c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=363423424.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFBertModel: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'distilbert', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of TFBertModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['bert']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "nlp_bert = transformers.TFBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "4b9de3dec8f74577ba87e10253f40a00",
      "3a817b84538b495aa33df8d8ab830d48",
      "59d7ef87be104cf0aeee435a179ef4c7",
      "1936274243f5452ab867c6a4ade1a694",
      "64bf32cba4f342c486e74d03f03b0724",
      "af4e33765b3a46be91f13bba4e266ddc",
      "461117018af046158e4d59bf95661b86",
      "33dc31d39c2b4c3ea1034f401836d245"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28581,
     "status": "ok",
     "timestamp": 1597358584194,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "axTuRVsx0Tkb",
    "outputId": "3a1ceac5-cfe9-4ab9-df80-783903afdbb3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9de3dec8f74577ba87e10253f40a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7qHEd58YoMdL"
   },
   "source": [
    "# Generating Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1682,
     "status": "ok",
     "timestamp": 1597358800322,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "5qbUimGofhiE"
   },
   "outputs": [],
   "source": [
    "def get_metadata_features(i):\n",
    "    print(\"Inside get_metadata_features\")\n",
    "    \"\"\"\n",
    "    Obtain the dataset\n",
    "    \"\"\"\n",
    "    # Extracted the text for nlp embeddings  \n",
    "    df_X_train= pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/search/X_train_' + str(i) + '.pkl')\n",
    "    #print(df_X_train.head())\n",
    "    df_X_test= pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/search/X_test_' + str(i) + '.pkl')\n",
    "    df_Y_train=pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/search/Y_train_' + str(i) + '.pkl')\n",
    "    df_Y_test=pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/search/Y_test_' + str(i) + '.pkl')\n",
    "    #print(df_X_train.shape) #(835, 5)\n",
    "    #print(df_Y_train.shape) #(835, 1)\n",
    "    #print(df_X_test.shape) #(209, 5)\n",
    "    #print(df_Y_test.shape) #(209, 1)\n",
    "    \n",
    "    X_train_meta = df_X_train.drop(['Previous_User_Utterance'], axis=1)\n",
    "    X_test_meta = df_X_test.drop(['Previous_User_Utterance'], axis=1)\n",
    "    \n",
    "    #print(X_train_meta['Previous_Speech_Act'].unique())\n",
    "    #print(X_train_meta['Previous_Search_Act'].unique())\n",
    "    \n",
    "    return X_train_meta, X_test_meta, df_Y_train, df_Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g9dNbyTVomQB"
   },
   "source": [
    "# Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23938,
     "status": "ok",
     "timestamp": 1597358584198,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "CGZkzItVoLgX"
   },
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "class AttentionLayer(Layer):\n",
    "    \n",
    "    def __init__(self,attention_dim=100,return_coefficients=False,**kwargs):\n",
    "        # Initializer \n",
    "        self.supports_masking = True\n",
    "        self.return_coefficients = return_coefficients\n",
    "        self.init = initializers.get('glorot_uniform') # initializes values with uniform distribution\n",
    "        self.attention_dim = attention_dim\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Builds all weights\n",
    "        # W = Weight matrix, b = bias vector, u = context vector\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)),name='W')\n",
    "        self.b = K.variable(self.init((self.attention_dim, )),name='b')\n",
    "        self.u = K.variable(self.init((self.attention_dim, 1)),name='u')\n",
    "        self.trainable_weight = [self.W, self.b, self.u]\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, hit, mask=None):\n",
    "        # Here, the actual calculation is done\n",
    "        uit = K.bias_add(K.dot(hit, self.W),self.b)\n",
    "        uit = K.tanh(uit)\n",
    "        \n",
    "        ait = K.dot(uit, self.u)\n",
    "        ait = K.squeeze(ait, -1)\n",
    "        ait = K.exp(ait)\n",
    "        \n",
    "        if mask is not None:\n",
    "            ait *= K.cast(mask, K.floatx())\n",
    "\n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        ait = K.expand_dims(ait)\n",
    "        weighted_input = hit * ait\n",
    "        \n",
    "        if self.return_coefficients:\n",
    "            return [K.sum(weighted_input, axis=1), ait]\n",
    "        else:\n",
    "            return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_coefficients:\n",
    "            return [(input_shape[0], input_shape[-1]), (input_shape[0], input_shape[-1], 1)]\n",
    "        else:\n",
    "            return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PURM9ikIt8uf"
   },
   "source": [
    "# BERT feature generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20899,
     "status": "ok",
     "timestamp": 1597358584200,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "zKKfFcpnuG6y"
   },
   "outputs": [],
   "source": [
    "def load_files(i):\n",
    "\n",
    "    df_X_train= pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/search/X_train_' + str(i) + '.pkl')\n",
    "    df_X_test= pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/search/X_test_' + str(i) + '.pkl')\n",
    "    df_Y_train=pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/search/Y_train_' + str(i) + '.pkl')\n",
    "    df_Y_test=pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/search/Y_test_' + str(i) + '.pkl')\n",
    "    df_train = pd.concat([df_X_train,df_Y_train], axis=1)\n",
    "    df_test = pd.concat([df_X_test,df_Y_test], axis=1)\n",
    "\n",
    "    #print(list(df_train.columns))\n",
    "\n",
    "    df_train = df_train[[\"Search_acts\",\"Previous_User_Utterance\"]]\n",
    "    df_train = df_train.rename(columns={\"Search_acts\":\"y\", \"Previous_User_Utterance\":\"text\"})\n",
    "\n",
    "    \n",
    "\n",
    "    df_test = df_test[[\"Search_acts\",\"Previous_User_Utterance\"]]\n",
    "    df_test = df_test.rename(columns={\"Search_acts\":\"y\", \"Previous_User_Utterance\":\"text\"})\n",
    "\n",
    "    return df_train,df_test,df_Y_train,df_Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10289,
     "status": "ok",
     "timestamp": 1597358584201,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "9Fh_bG0NuoFL"
   },
   "outputs": [],
   "source": [
    "def generate_maskid(training, test):\n",
    "  #print(training['text'])\n",
    "  corpus_train = training['text']\n",
    "  corpus_test = test['text']\n",
    "  #the length of the feature vector is 150\n",
    "  maxlen = 150\n",
    "\n",
    "  #add special tokens\n",
    "  maxqnans = np.int((maxlen-20)/2)\n",
    "  corpus_tokenized_train = [\"[CLS] \"+\n",
    "              \" \".join(tokenizer.tokenize(re.sub(r'[^\\w\\s]+|\\n', '', \n",
    "              str(txt).lower().strip()))[:maxqnans])+\n",
    "              \" [SEP] \" for txt in corpus_train]\n",
    "  corpus_tokenized_test = [\"[CLS] \"+\n",
    "              \" \".join(tokenizer.tokenize(re.sub(r'[^\\w\\s]+|\\n', '', \n",
    "              str(txt).lower().strip()))[:maxqnans])+\n",
    "              \" [SEP] \" for txt in corpus_test]\n",
    "  #generate masks\n",
    "  masks_train = [[1]*len(txt.split(\" \")) + [0]*(maxlen - len(txt.split(\" \"))) for txt in corpus_tokenized_train]\n",
    "  masks_test = [[1]*len(txt.split(\" \")) + [0]*(maxlen - len(txt.split(\" \"))) for txt in corpus_tokenized_test]\n",
    "\n",
    "  #padding\n",
    "  txt2seq_train = [txt + \" [PAD]\"*(maxlen-len(txt.split(\" \"))-2) if len(txt.split(\" \")) != (maxlen) else txt for txt in corpus_tokenized_train]\n",
    "  txt2seq_test = [txt + \" [PAD]\"*(maxlen-len(txt.split(\" \"))-2) if len(txt.split(\" \")) != (maxlen) else txt for txt in corpus_tokenized_test]\n",
    "\n",
    "  #generate idx\n",
    "  idx_train = [tokenizer.encode(seq.split(\" \")) for seq in txt2seq_train]\n",
    "  idx_test = [tokenizer.encode(seq.split(\" \")) for seq in txt2seq_test]      \n",
    "\n",
    "  ## feature matrix\n",
    "  X_train = [np.asarray(idx_train, dtype='int32'), \n",
    "            np.asarray(masks_train, dtype='int32')]\n",
    "  X_test = [np.asarray(idx_test, dtype='int32'), \n",
    "            np.asarray(masks_test, dtype='int32')]\n",
    "  \n",
    "\n",
    "  idx_train = np.asarray(idx_train, dtype='int32')\n",
    "  masks_train = np.asarray(masks_train, dtype='int32')\n",
    "  idx_test = np.asarray(idx_test, dtype='int32')\n",
    "  masks_test = np.asarray(masks_test, dtype='int32')\n",
    "\n",
    "  #print(\"txt: \", training[\"text\"].iloc[0])\n",
    "  #print(\"tokenized:\", [tokenizer.convert_ids_to_tokens(idx) for idx in X_train[0][i].tolist()])\n",
    "  #print(\"idx: \", X_train[0][i])\n",
    "  #print(\"mask: \", X_train[1][i])\n",
    "  return idx_train, masks_train, idx_test, masks_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O2Cqo7YUp6ji"
   },
   "source": [
    "# Deep Neural Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6554,
     "status": "ok",
     "timestamp": 1597358584202,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "OTW2A-hSpzQO"
   },
   "outputs": [],
   "source": [
    "def create_bilstm_meta_bert_channels(reshaped_data_meta):\n",
    "    \n",
    "    idx = Input((150), dtype=\"int32\", name=\"input_idx\")\n",
    "    masks = Input((150), dtype=\"int32\", name=\"input_masks\")\n",
    "    ## pre-trained bert with config\n",
    "    config = transformers.DistilBertConfig(dropout=0.2,attention_dropout=0.2)\n",
    "    config.output_hidden_states = False\n",
    "    nlp_bert = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config)\n",
    "    bert_out = nlp_bert(idx, attention_mask=masks)[0]\n",
    "    ## fine-tuning\n",
    "    x = GlobalAveragePooling1D()(bert_out)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    #x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    y_out = Dense(4, activation='softmax')(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    samples,timesteps,features = reshaped_data_meta.shape\n",
    "    inp_meta = Input(shape=(timesteps,features), name='input_meta')\n",
    "    # lstm needs (samples,timesteps,features) tensor as the input\n",
    "    x1 = Bidirectional(LSTM(BATCH_SIZE, return_sequences=True, dropout=0.25, recurrent_dropout=0.1))(inp_meta) \n",
    "    x1, sent_coeffs1 = AttentionLayer(features,return_coefficients=True,name='sent_attention1')(x1)\n",
    "    #x1 = GlobalMaxPool1D()(x1)\n",
    "    #x1 = Dense(100, activation=\"relu\")(x1)\n",
    "    x1 = Dropout(0.25)(x1)\n",
    "    x1 = Dense(4, activation=\"softmax\")(x1) #output layer  \n",
    "    \n",
    "    \n",
    "      \n",
    "    \n",
    "    \"\"\"\n",
    "    Merging outputs of nlp and meta\n",
    "    \"\"\"\n",
    "    merge_meta_bert = concatenate([x1, y_out])\n",
    "\n",
    "\n",
    "    output_meta_bert = Dense(4, activation=\"softmax\")(merge_meta_bert)\n",
    "    model_meta_bert_combined = Model(inputs=[inp_meta, idx, masks], outputs=output_meta_bert)\n",
    "    \n",
    "    return model_meta_bert_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xG6A0LNAvI5b"
   },
   "source": [
    "# META BERT model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1772,
     "status": "ok",
     "timestamp": 1597358807770,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "T7uwFVM_vCeg"
   },
   "outputs": [],
   "source": [
    "def execute_bilstm_meta_bert_channel(i):\n",
    "\n",
    "  \"\"\"\n",
    "  meta data\n",
    "  \"\"\"\n",
    "  df_train_meta, df_test_meta, df_Y_train_meta, df_Y_test_meta = get_metadata_features(i)\n",
    "  train_meta = df_train_meta.values\n",
    "  test_meta = df_test_meta.values\n",
    "      \n",
    "  timestamp = 1 #number of successive sequences combined\n",
    "      \n",
    "  r, c = df_train_meta.shape\n",
    "  staggering = r - timestamp + 1 # final number of instances generated \n",
    "  X_train_reshaped_meta = np.concatenate([train_meta[x:x+timestamp,:] for x in range(r-timestamp+1)])\n",
    "  X_train_reshaped_meta = X_train_reshaped_meta.reshape(staggering, timestamp, c) # c is the number of features\n",
    "    \n",
    "  r2, c2 = df_test_meta.shape\n",
    "  staggering2 = r2 - timestamp + 1 # final number of instances generated \n",
    "  X_test_reshaped_meta = np.concatenate([test_meta[x:x+timestamp,:] for x in range(r2-timestamp+1)])\n",
    "  X_test_reshaped_meta = X_test_reshaped_meta.reshape(staggering2, timestamp, c2) # c is the number of features\n",
    "      \n",
    "  print(\"Meta data\\n------------------\")\n",
    "  print(\"Training set\\n------------------\")\n",
    "  print(X_train_reshaped_meta)\n",
    "  print(X_train_reshaped_meta.shape)\n",
    "      \n",
    "  print(\"Meta data\\n------------------\")\n",
    "  print(\"Test set\\n------------------\")\n",
    "  print(X_test_reshaped_meta)\n",
    "  print(X_test_reshaped_meta.shape)\n",
    "      \n",
    "  df_Y_train_meta = df_Y_train_meta.iloc[timestamp-1:,]\n",
    "  df_Y_test_meta = df_Y_test_meta.iloc[timestamp-1:,]\n",
    "  \n",
    "  \n",
    "  print(\"Output Labels\\n------------------\")\n",
    "  print(df_Y_train_meta.shape, df_Y_test_meta.shape)\n",
    "\n",
    "  \"\"\"\n",
    "  bert data\n",
    "  \"\"\"\n",
    "  df_train_bert,df_test_bert,df_Y_train_bert,df_Y_test_bert = load_files(i)\n",
    "  y_train_bert = df_Y_train_bert['Search_acts'].to_list()\n",
    "  y_test_bert = df_Y_test_bert['Search_acts'].to_list()\n",
    "  X_train_id, X_train_mask, X_test_id, X_test_mask = generate_maskid(df_train_bert,df_test_bert)\n",
    "      \n",
    "  model_meta_bert = create_bilstm_meta_bert_channels(X_train_reshaped_meta)\n",
    "\n",
    "\n",
    "  print(\"\\n\\n THESE ARE THE LAYERS\")\n",
    "  for layer in model_meta_bert.layers[:5]:\n",
    "    if(layer.name == 'input_meta' or layer.name == 'bidirectional'):\n",
    "      layer.trainable = True\n",
    "    else:\n",
    "      layer.trainable = False\n",
    "\n",
    "  model_meta_bert.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['binary_accuracy', 'categorical_accuracy'])\n",
    "  model_meta_bert.summary()\n",
    "\n",
    "\n",
    "  \"\"\"\n",
    "  encoding the output labels\n",
    "  \"\"\"\n",
    "      \n",
    "  encoder = LabelEncoder()\n",
    "  encoder.fit(y_train_bert)\n",
    "  training_op_labels_encoded = encoder.transform(y_train_bert)\n",
    "  test_op_labels_encoded = encoder.transform(y_test_bert)\n",
    "  print(\"Output Labels\\n-------------------\")\n",
    "  print(training_op_labels_encoded.shape, test_op_labels_encoded.shape)\n",
    "      \n",
    "  \"\"\"\n",
    "  converting the output labels to one-hot form\n",
    "  \"\"\"\n",
    "  training_op_labels_onehot= np_utils.to_categorical(training_op_labels_encoded)\n",
    "  test_op_labels_onehot = np_utils.to_categorical(test_op_labels_encoded)\n",
    "\n",
    "  print(training_op_labels_onehot.shape, len(training_op_labels_onehot))\n",
    "  print(test_op_labels_onehot.shape, len(test_op_labels_onehot))\n",
    "\n",
    "\n",
    "  X_train_reshaped_meta = np.asarray(X_train_reshaped_meta, dtype='float32')\n",
    "  #training_op_labels_onehot = tf.convert_to_tensor(training_op_labels_onehot)\n",
    "  \n",
    "  \n",
    "  model_meta_bert_train = model_meta_bert.fit(x=[X_train_reshaped_meta,X_train_id,X_train_mask], y=training_op_labels_onehot,batch_size=BATCH_SIZE, epochs=EPOCHS,  validation_split=0.1)\n",
    "  # load model if required \n",
    "  # compile model\n",
    "\n",
    "\n",
    "  model_meta_bert.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['binary_accuracy', 'categorical_accuracy'])\n",
    "      \n",
    "  # evaluate model\n",
    "  print(model_meta_bert.metrics_names)\n",
    "  #change the input_\n",
    "\n",
    "  #loss, binary_accuracy, categorical_accuracy = model_nlp_bert.evaluate(x=[X_test_reshaped_nlp,X_test_id,X_test_mask], y=test_op_labels_onehot,batch_size=BATCH_SIZE,verbose=1)\n",
    "      \n",
    "  #print(loss, binary_accuracy, categorical_accuracy)\n",
    "      \n",
    "\n",
    "  \"\"\"\n",
    "  predict the probabilty of output classes\n",
    "  and pick the best one\n",
    "  \"\"\"\n",
    "  #change the input_\n",
    "\n",
    "  X_test_reshaped_meta = np.asarray(X_test_reshaped_meta, dtype='float32')\n",
    "  prediction_vector = model_meta_bert.predict(x=[X_test_reshaped_meta,X_test_id,X_test_mask], \\\n",
    "                            batch_size=BATCH_SIZE,\\\n",
    "                            verbose=1)\n",
    "  predicted_classes = np.argmax(prediction_vector, axis=1)\n",
    "  original_classes = np.argmax(test_op_labels_onehot, axis=1)\n",
    "  accuracy = metrics.accuracy_score(original_classes, predicted_classes)\n",
    "\n",
    "  print(\"ACCURACY:\")\n",
    "  print(accuracy)\n",
    "      \n",
    "  \"\"\"\n",
    "  # verification of correctness:\n",
    "  total_correct = sum(original_classes == predicted_classes)\n",
    "  print(\"Total number of correct predictions:\",total_correct)\n",
    "  print(\"Accuracy:\",total_correct/len(test_op_labels_onehot))\n",
    "  acc = np.sum(conf_mat.diagonal()) / np.sum(conf_mat)\n",
    "  print('Overall accuracy: {} %'.format(acc*100))\n",
    "  \"\"\"\n",
    "  conf_mat = confusion_matrix(predicted_classes, original_classes)\n",
    "  print(\"\\n\", conf_mat, \"\\n\")\n",
    "      \n",
    "  return predicted_classes, accuracy, conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vL9o8LMEydoI"
   },
   "source": [
    "# Main Method and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 139854,
     "status": "ok",
     "timestamp": 1597358950057,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "1U29WTZGyg-J",
    "outputId": "a17f00d1-03d7-4fa8-ef2d-221462d27a13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside get_metadata_features\n",
      "Meta data\n",
      "------------------\n",
      "Training set\n",
      "------------------\n",
      "[[[0.0 46.0 0 ... 10 2 1]]\n",
      "\n",
      " [[0.0 12.0 0 ... 1 2 3]]\n",
      "\n",
      " [[0.0 4.0 0 ... 10 2 3]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.0 5.0 0 ... 1 2 4]]\n",
      "\n",
      " [[0.0 24.0 0 ... 1 2 1]]\n",
      "\n",
      " [[0.0 15.0 0 ... 1 2 0]]]\n",
      "(406, 1, 8)\n",
      "Meta data\n",
      "------------------\n",
      "Test set\n",
      "------------------\n",
      "[[[0.0 31.0 0 0 1 10 2 3]]\n",
      "\n",
      " [[0.0 13.0 0 0 2 1 2 2]]\n",
      "\n",
      " [[0.0 5.0 0 1 1 10 10 3]]\n",
      "\n",
      " [[0.0 7.0 0 0 0 1 2 2]]\n",
      "\n",
      " [[0.0 7.0 0 1 2 1 1 3]]\n",
      "\n",
      " [[0.0 7.0 0 0 2 12 12 3]]\n",
      "\n",
      " [[0.0 44.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 29.0 0 0 1 1 2 2]]\n",
      "\n",
      " [[0.0 8.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 47.0 0 0 1 1 2 1]]\n",
      "\n",
      " [[0.0 23.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 43.0 0 0 2 1 11 3]]\n",
      "\n",
      " [[0.0 4.0 0 1 1 10 10 3]]\n",
      "\n",
      " [[0.0 3.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 21.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 1 2 12 12 3]]\n",
      "\n",
      " [[0.0 13.0 0 1 2 6 6 1]]\n",
      "\n",
      " [[0.0 5.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 5.0 0 1 1 1 1 2]]\n",
      "\n",
      " [[0.0 25.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 10.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 7.0 0 1 2 1 1 2]]\n",
      "\n",
      " [[0.0 26.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 57.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 18.0 0 1 1 1 5 2]]\n",
      "\n",
      " [[0.0 18.0 0 0 1 1 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 0 0 1 4 3]]\n",
      "\n",
      " [[0.0 6.0 0 1 2 10 2 3]]\n",
      "\n",
      " [[0.0 15.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 8.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 1 1 3]]\n",
      "\n",
      " [[0.0 12.0 0 1 1 1 1 3]]\n",
      "\n",
      " [[0.0 6.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 3.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 8.0 0 0 2 10 2 3]]\n",
      "\n",
      " [[0.0 55.0 0 0 1 1 2 2]]\n",
      "\n",
      " [[0.0 6.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 19.0 0 1 1 1 4 1]]\n",
      "\n",
      " [[0.0 29.0 0 1 1 1 2 1]]\n",
      "\n",
      " [[0.0 65.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 11.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 8.0 0 1 1 1 2 1]]\n",
      "\n",
      " [[0.0 6.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 13.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 1 1 2]]\n",
      "\n",
      " [[0.0 3.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 1 2 4]]\n",
      "\n",
      " [[0.0 8.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 10.0 0 1 2 10 2 2]]\n",
      "\n",
      " [[0.0 7.0 0 0 1 1 11 4]]\n",
      "\n",
      " [[0.0 3.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 4.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 6.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 9.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 45.0 0 0 1 1 2 4]]\n",
      "\n",
      " [[0.0 41.0 0 0 1 1 1 3]]\n",
      "\n",
      " [[0.0 88.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 14.0 0 1 1 1 2 2]]\n",
      "\n",
      " [[0.0 12.0 0 0 1 1 9 4]]\n",
      "\n",
      " [[0.0 3.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 30.0 0 1 1 10 10 1]]\n",
      "\n",
      " [[0.0 27.0 0 0 2 1 2 2]]\n",
      "\n",
      " [[0.0 12.0 0 1 1 10 10 1]]\n",
      "\n",
      " [[0.0 3.0 0 1 2 10 2 3]]\n",
      "\n",
      " [[0.0 14.0 0 1 1 10 2 4]]\n",
      "\n",
      " [[0.0 10.0 0 0 0 1 1 3]]\n",
      "\n",
      " [[0.0 13.0 0 1 2 1 2 1]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 6 6 1]]\n",
      "\n",
      " [[0.0 14.0 0 1 1 1 1 1]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 1 2 2]]\n",
      "\n",
      " [[0.0 28.0 0 0 0 1 9 2]]\n",
      "\n",
      " [[0.0 6.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 1 1 1]]\n",
      "\n",
      " [[0.0 13.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 13.0 0 0 0 1 2 2]]\n",
      "\n",
      " [[0.0 18.0 0 1 2 9 2 2]]\n",
      "\n",
      " [[0.0 7.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 20.0 0 1 2 10 2 2]]\n",
      "\n",
      " [[0.0 20.0 0 1 1 10 2 2]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 1 1 2]]\n",
      "\n",
      " [[0.0 19.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 40.0 0 0 2 6 11 3]]\n",
      "\n",
      " [[0.0 43.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 4.0 0 0 0 1 1 2]]\n",
      "\n",
      " [[0.0 19.0 0 1 2 1 1 1]]\n",
      "\n",
      " [[0.0 13.0 0 1 2 10 2 3]]\n",
      "\n",
      " [[0.0 19.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 28.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 30.0 0 1 1 1 5 1]]\n",
      "\n",
      " [[0.0 40.0 0 0 2 1 2 4]]\n",
      "\n",
      " [[0.0 11.0 0 0 2 6 6 2]]\n",
      "\n",
      " [[0.0 21.0 0 0 2 1 2 4]]\n",
      "\n",
      " [[0.0 28.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 47.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 10.0 0 0 2 1 1 3]]\n",
      "\n",
      " [[0.0 6.0 0 1 2 10 11 1]]\n",
      "\n",
      " [[0.0 16.0 0 1 2 10 11 1]]\n",
      "\n",
      " [[0.0 46.0 0 1 1 1 2 1]]\n",
      "\n",
      " [[0.0 6.0 0 1 2 1 2 4]]]\n",
      "(102, 1, 8)\n",
      "Output Labels\n",
      "------------------\n",
      "(406, 1) (102, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_transform', 'vocab_layer_norm', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "\n",
      " THESE ARE THE LAYERS\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_meta (InputLayer)         [(None, 1, 8)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_idx (InputLayer)          [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 1, 64)        10496       input_meta[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model (TFDistilB ((None, 150, 768),)  66362880    input_idx[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sent_attention1 (AttentionLayer [(None, 64), (None,  528         bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 768)          0           tf_distil_bert_model[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 64)           0           sent_attention1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           49216       global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            260         dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            260         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8)            0           dense_2[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            36          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 66,423,676\n",
      "Trainable params: 60,796\n",
      "Non-trainable params: 66,362,880\n",
      "__________________________________________________________________________________________________\n",
      "Output Labels\n",
      "-------------------\n",
      "(406,) (102,)\n",
      "(406, 4) 406\n",
      "(102, 4) 102\n",
      "12/12 [==============================] - 4s 358ms/step - loss: 1.2801 - binary_accuracy: 0.7500 - categorical_accuracy: 0.3534 - val_loss: 1.3130 - val_binary_accuracy: 0.7500 - val_categorical_accuracy: 0.3659\n",
      "[]\n",
      "4/4 [==============================] - 0s 99ms/step\n",
      "ACCURACY:\n",
      "0.4019607843137255\n",
      "\n",
      " [[38 23 28  8]\n",
      " [ 0  0  0  0]\n",
      " [ 1  1  3  0]\n",
      " [ 0  0  0  0]] \n",
      "\n",
      "Inside get_metadata_features\n",
      "Meta data\n",
      "------------------\n",
      "Training set\n",
      "------------------\n",
      "[[[0.0 5.0 0 ... 1 2 3]]\n",
      "\n",
      " [[0.0 6.0 0 ... 1 2 4]]\n",
      "\n",
      " [[0.0 13.0 0 ... 1 2 3]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.0 6.0 0 ... 1 1 2]]\n",
      "\n",
      " [[0.0 17.0 0 ... 10 2 1]]\n",
      "\n",
      " [[0.0 58.0 0 ... 6 2 1]]]\n",
      "(406, 1, 8)\n",
      "Meta data\n",
      "------------------\n",
      "Test set\n",
      "------------------\n",
      "[[[0.0 27.0 0 0 2 1 2 2]]\n",
      "\n",
      " [[0.0 17.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 51.0 0 1 2 1 2 1]]\n",
      "\n",
      " [[0.0 15.0 0 1 2 10 10 1]]\n",
      "\n",
      " [[0.0 43.0 0 0 2 1 11 1]]\n",
      "\n",
      " [[0.0 20.0 0 1 1 1 2 2]]\n",
      "\n",
      " [[0.0 21.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 14.0 0 1 1 1 1 4]]\n",
      "\n",
      " [[0.0 6.0 0 1 2 10 10 1]]\n",
      "\n",
      " [[0.0 6.0 0 1 2 1 2 4]]\n",
      "\n",
      " [[0.0 53.0 0 0 2 1 1 3]]\n",
      "\n",
      " [[0.0 9.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 5.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 8.0 0 0 1 1 2 3]]\n",
      "\n",
      " [[0.0 61.0 0 1 2 10 2 2]]\n",
      "\n",
      " [[0.0 5.0 0 0 0 1 1 3]]\n",
      "\n",
      " [[0.0 3.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 36.0 0 0 1 1 1 4]]\n",
      "\n",
      " [[0.0 10.0 0 0 1 10 2 2]]\n",
      "\n",
      " [[0.0 34.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 3.0 0 1 2 10 2 3]]\n",
      "\n",
      " [[0.0 7.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 4.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 13.0 0 1 2 6 6 1]]\n",
      "\n",
      " [[0.0 13.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 6.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 2.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 10.0 0 1 1 10 2 2]]\n",
      "\n",
      " [[0.0 34.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 40.0 0 0 2 6 11 1]]\n",
      "\n",
      " [[0.0 55.0 0 0 1 1 2 1]]\n",
      "\n",
      " [[0.0 59.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 12.0 0 1 1 10 10 2]]\n",
      "\n",
      " [[0.0 14.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 1 2 4]]\n",
      "\n",
      " [[0.0 67.0 0 0 1 1 2 2]]\n",
      "\n",
      " [[0.0 10.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 13.0 0 0 0 1 11 3]]\n",
      "\n",
      " [[0.0 8.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 11.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 1 1 3]]\n",
      "\n",
      " [[0.0 6.0 0 1 2 1 1 3]]\n",
      "\n",
      " [[0.0 20.0 0 0 1 1 1 3]]\n",
      "\n",
      " [[0.0 5.0 0 1 1 10 10 1]]\n",
      "\n",
      " [[0.0 21.0 0 0 2 1 2 4]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 24.0 0 0 2 6 2 3]]\n",
      "\n",
      " [[0.0 11.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 13.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 35.0 0 0 2 10 10 3]]\n",
      "\n",
      " [[0.0 17.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 13.0 0 0 1 1 2 3]]\n",
      "\n",
      " [[0.0 6.0 0 0 2 6 6 3]]\n",
      "\n",
      " [[0.0 79.0 0 1 1 9 9 2]]\n",
      "\n",
      " [[0.0 8.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 19.0 0 1 2 6 4 3]]\n",
      "\n",
      " [[0.0 64.0 0 0 1 1 2 3]]\n",
      "\n",
      " [[0.0 55.0 0 0 1 1 2 2]]\n",
      "\n",
      " [[0.0 15.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 17.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 13.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 34.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 14.0 0 0 0 1 2 2]]\n",
      "\n",
      " [[0.0 8.0 0 0 2 10 2 1]]\n",
      "\n",
      " [[0.0 19.0 0 1 2 1 5 2]]\n",
      "\n",
      " [[0.0 43.0 0 1 2 1 5 1]]\n",
      "\n",
      " [[0.0 19.0 0 1 2 1 2 1]]\n",
      "\n",
      " [[0.0 27.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 4.0 0 0 0 1 1 1]]\n",
      "\n",
      " [[0.0 7.0 0 0 2 12 12 3]]\n",
      "\n",
      " [[0.0 15.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 10.0 0 1 1 10 2 2]]\n",
      "\n",
      " [[0.0 88.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 12.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 6.0 0 1 2 1 2 4]]\n",
      "\n",
      " [[0.0 29.0 0 0 1 1 2 2]]\n",
      "\n",
      " [[0.0 13.0 0 0 1 1 11 2]]\n",
      "\n",
      " [[0.0 3.0 0 1 2 10 2 3]]\n",
      "\n",
      " [[0.0 0.0 0 0 1 10 2 3]]\n",
      "\n",
      " [[0.0 14.0 0 1 1 1 2 2]]\n",
      "\n",
      " [[0.0 11.0 0 1 2 10 2 2]]\n",
      "\n",
      " [[0.0 10.0 0 0 0 6 6 2]]\n",
      "\n",
      " [[0.0 34.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 29.0 0 1 1 1 2 1]]\n",
      "\n",
      " [[0.0 33.0 0 0 1 1 2 2]]\n",
      "\n",
      " [[0.0 5.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 8.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 16.0 0 1 1 6 6 3]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 1 1 1]]\n",
      "\n",
      " [[0.0 49.0 0 0 1 1 2 3]]\n",
      "\n",
      " [[0.0 6.0 0 0 2 1 1 3]]\n",
      "\n",
      " [[0.0 25.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 8.0 0 0 2 1 2 2]]\n",
      "\n",
      " [[0.0 5.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 17.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 8.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 6.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 1 1 3]]\n",
      "\n",
      " [[0.0 8.0 0 1 2 10 5 2]]\n",
      "\n",
      " [[0.0 43.0 0 1 2 1 5 3]]\n",
      "\n",
      " [[0.0 5.0 0 0 0 1 2 1]]]\n",
      "(102, 1, 8)\n",
      "Output Labels\n",
      "------------------\n",
      "(406, 1) (102, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_transform', 'vocab_layer_norm', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "\n",
      " THESE ARE THE LAYERS\n",
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_meta (InputLayer)         [(None, 1, 8)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_idx (InputLayer)          [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1, 64)        10496       input_meta[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_1 (TFDisti ((None, 150, 768),)  66362880    input_idx[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sent_attention1 (AttentionLayer [(None, 64), (None,  528         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 768)          0           tf_distil_bert_model_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 64)           0           sent_attention1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           49216       global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4)            260         dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 4)            260         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8)            0           dense_6[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 4)            36          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 66,423,676\n",
      "Trainable params: 50,300\n",
      "Non-trainable params: 66,373,376\n",
      "__________________________________________________________________________________________________\n",
      "Output Labels\n",
      "-------------------\n",
      "(406,) (102,)\n",
      "(406, 4) 406\n",
      "(102, 4) 102\n",
      "12/12 [==============================] - 4s 351ms/step - loss: 1.3959 - binary_accuracy: 0.7500 - categorical_accuracy: 0.2274 - val_loss: 1.3805 - val_binary_accuracy: 0.7500 - val_categorical_accuracy: 0.2683\n",
      "[]\n",
      "4/4 [==============================] - 0s 90ms/step\n",
      "ACCURACY:\n",
      "0.39215686274509803\n",
      "\n",
      " [[28 18 28  2]\n",
      " [ 0  0  0  0]\n",
      " [ 8  4 12  2]\n",
      " [ 0  0  0  0]] \n",
      "\n",
      "Inside get_metadata_features\n",
      "Meta data\n",
      "------------------\n",
      "Training set\n",
      "------------------\n",
      "[[[0.0 5.0 0 ... 1 1 2]]\n",
      "\n",
      " [[0.0 12.0 0 ... 10 2 2]]\n",
      "\n",
      " [[0.0 6.0 0 ... 1 2 2]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.0 13.0 0 ... 1 2 1]]\n",
      "\n",
      " [[0.0 34.0 0 ... 10 2 3]]\n",
      "\n",
      " [[0.0 23.0 0 ... 1 1 3]]]\n",
      "(406, 1, 8)\n",
      "Meta data\n",
      "------------------\n",
      "Test set\n",
      "------------------\n",
      "[[[0.0 10.0 0 1 1 10 2 2]]\n",
      "\n",
      " [[0.0 15.0 0 1 1 10 4 2]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 67.0 0 0 1 1 2 1]]\n",
      "\n",
      " [[0.0 24.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 4.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 12.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 25.0 0 1 1 1 1 1]]\n",
      "\n",
      " [[0.0 6.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 12.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 13.0 0 0 2 1 2 2]]\n",
      "\n",
      " [[0.0 5.0 0 0 2 1 4 3]]\n",
      "\n",
      " [[0.0 18.0 0 1 1 1 5 1]]\n",
      "\n",
      " [[0.0 13.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 44.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 47.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 14.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 15.0 0 0 0 1 2 0]]\n",
      "\n",
      " [[0.0 10.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 67.0 0 0 1 1 2 2]]\n",
      "\n",
      " [[0.0 11.0 0 1 1 6 2 3]]\n",
      "\n",
      " [[0.0 8.0 0 1 1 1 2 1]]\n",
      "\n",
      " [[0.0 25.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 5.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 16.0 0 1 2 10 11 1]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 10 10 1]]\n",
      "\n",
      " [[0.0 6.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 8.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 28.0 0 0 2 10 2 3]]\n",
      "\n",
      " [[0.0 8.0 0 0 2 10 2 3]]\n",
      "\n",
      " [[0.0 46.0 0 1 1 1 2 1]]\n",
      "\n",
      " [[0.0 47.0 0 0 1 1 2 1]]\n",
      "\n",
      " [[0.0 6.0 0 0 2 1 1 3]]\n",
      "\n",
      " [[0.0 57.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 25.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 24.0 0 0 2 6 2 3]]\n",
      "\n",
      " [[0.0 88.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 14.0 0 1 1 10 2 4]]\n",
      "\n",
      " [[0.0 64.0 0 0 1 1 2 1]]\n",
      "\n",
      " [[0.0 26.0 0 1 2 10 10 1]]\n",
      "\n",
      " [[0.0 7.0 0 0 2 1 2 2]]\n",
      "\n",
      " [[0.0 9.0 0 0 1 1 2 3]]\n",
      "\n",
      " [[0.0 18.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 5.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 12.0 0 1 1 10 10 1]]\n",
      "\n",
      " [[0.0 13.0 0 1 2 10 2 3]]\n",
      "\n",
      " [[0.0 9.0 0 0 0 1 2 2]]\n",
      "\n",
      " [[0.0 21.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 16.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 0 2 1 5 3]]\n",
      "\n",
      " [[0.0 12.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 31.0 0 0 1 10 2 3]]\n",
      "\n",
      " [[0.0 9.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 12.0 0 0 1 1 2 1]]\n",
      "\n",
      " [[0.0 4.0 0 1 2 10 2 3]]\n",
      "\n",
      " [[0.0 44.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 4.0 0 0 0 1 1 3]]\n",
      "\n",
      " [[0.0 25.0 0 1 1 10 2 2]]\n",
      "\n",
      " [[0.0 25.0 0 0 2 1 2 4]]\n",
      "\n",
      " [[0.0 10.0 0 0 2 1 1 2]]\n",
      "\n",
      " [[0.0 5.0 0 1 1 10 2 2]]\n",
      "\n",
      " [[0.0 53.0 0 0 2 1 1 3]]\n",
      "\n",
      " [[0.0 13.0 0 0 2 1 2 2]]\n",
      "\n",
      " [[0.0 11.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 5.0 0 1 1 1 1 2]]\n",
      "\n",
      " [[0.0 9.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 12.0 0 1 1 10 10 2]]\n",
      "\n",
      " [[0.0 35.0 0 0 2 10 10 3]]\n",
      "\n",
      " [[0.0 43.0 0 0 1 1 2 2]]\n",
      "\n",
      " [[0.0 17.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 73.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 5.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 45.0 0 0 1 1 2 1]]\n",
      "\n",
      " [[0.0 34.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 57.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 43.0 0 1 2 1 5 3]]\n",
      "\n",
      " [[0.0 5.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 9.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 58.0 0 0 2 6 2 3]]\n",
      "\n",
      " [[0.0 6.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 7.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 8.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 6 5 3]]\n",
      "\n",
      " [[0.0 5.0 0 0 0 1 1 3]]\n",
      "\n",
      " [[0.0 13.0 0 0 2 1 2 2]]\n",
      "\n",
      " [[0.0 9.0 0 1 2 1 2 1]]\n",
      "\n",
      " [[0.0 11.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 15.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 4.0 0 0 1 1 2 4]]\n",
      "\n",
      " [[0.0 25.0 0 1 1 10 2 2]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 1 1 2]]\n",
      "\n",
      " [[0.0 4.0 0 1 2 12 12 3]]\n",
      "\n",
      " [[0.0 37.0 0 0 2 1 2 2]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 1 1 1]]\n",
      "\n",
      " [[0.0 47.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 3.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 53.0 0 1 1 10 11 3]]]\n",
      "(102, 1, 8)\n",
      "Output Labels\n",
      "------------------\n",
      "(406, 1) (102, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_transform', 'vocab_layer_norm', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "\n",
      " THESE ARE THE LAYERS\n",
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_meta (InputLayer)         [(None, 1, 8)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_idx (InputLayer)          [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1, 64)        10496       input_meta[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_2 (TFDisti ((None, 150, 768),)  66362880    input_idx[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sent_attention1 (AttentionLayer [(None, 64), (None,  528         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 768)          0           tf_distil_bert_model_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 64)           0           sent_attention1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           49216       global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 4)            260         dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 4)            260         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8)            0           dense_10[0][0]                   \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 4)            36          concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 66,423,676\n",
      "Trainable params: 50,300\n",
      "Non-trainable params: 66,373,376\n",
      "__________________________________________________________________________________________________\n",
      "Output Labels\n",
      "-------------------\n",
      "(406,) (102,)\n",
      "(406, 4) 406\n",
      "(102, 4) 102\n",
      "12/12 [==============================] - 4s 352ms/step - loss: 1.4370 - binary_accuracy: 0.7500 - categorical_accuracy: 0.3205 - val_loss: 1.3425 - val_binary_accuracy: 0.7500 - val_categorical_accuracy: 0.3659\n",
      "[]\n",
      "4/4 [==============================] - 0s 91ms/step\n",
      "ACCURACY:\n",
      "0.3137254901960784\n",
      "\n",
      " [[ 0  0  0  0]\n",
      " [ 0  0  0  0]\n",
      " [40 21 32  9]\n",
      " [ 0  0  0  0]] \n",
      "\n",
      "Inside get_metadata_features\n",
      "Meta data\n",
      "------------------\n",
      "Training set\n",
      "------------------\n",
      "[[[0.0 5.0 0 ... 1 1 2]]\n",
      "\n",
      " [[0.0 107.0 0 ... 1 2 4]]\n",
      "\n",
      " [[0.0 5.0 0 ... 1 2 4]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.0 18.0 0 ... 1 2 1]]\n",
      "\n",
      " [[0.0 7.0 0 ... 1 1 3]]\n",
      "\n",
      " [[0.0 10.0 0 ... 10 2 2]]]\n",
      "(406, 1, 8)\n",
      "Meta data\n",
      "------------------\n",
      "Test set\n",
      "------------------\n",
      "[[[0.0 8.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 12.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 7.0 0 1 2 9 9 3]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 16.0 0 1 1 12 12 3]]\n",
      "\n",
      " [[0.0 14.0 0 1 1 1 1 4]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 1 2 2]]\n",
      "\n",
      " [[0.0 12.0 0 1 2 10 2 3]]\n",
      "\n",
      " [[0.0 18.0 0 1 1 10 10 2]]\n",
      "\n",
      " [[0.0 13.0 0 0 2 1 2 2]]\n",
      "\n",
      " [[0.0 9.0 0 1 1 6 2 1]]\n",
      "\n",
      " [[0.0 14.0 0 0 2 11 11 3]]\n",
      "\n",
      " [[0.0 6.0 0 1 2 1 1 3]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 10 2 2]]\n",
      "\n",
      " [[0.0 44.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 4.0 0 1 1 10 2 2]]\n",
      "\n",
      " [[0.0 4.0 0 1 1 10 10 3]]\n",
      "\n",
      " [[0.0 19.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 47.0 0 0 1 1 2 1]]\n",
      "\n",
      " [[0.0 6.0 0 0 2 6 6 3]]\n",
      "\n",
      " [[0.0 8.0 0 0 2 1 2 2]]\n",
      "\n",
      " [[0.0 10.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 7.0 0 0 1 1 11 1]]\n",
      "\n",
      " [[0.0 3.0 0 1 2 10 2 3]]\n",
      "\n",
      " [[0.0 7.0 0 0 1 1 11 3]]\n",
      "\n",
      " [[0.0 10.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 13.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 44.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 10 2 4]]\n",
      "\n",
      " [[0.0 21.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 9.0 0 0 0 1 2 2]]\n",
      "\n",
      " [[0.0 59.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 5.0 0 0 1 1 1 3]]\n",
      "\n",
      " [[0.0 10.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 1 2 4]]\n",
      "\n",
      " [[0.0 4.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 8.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 90.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 8.0 0 0 2 6 6 3]]\n",
      "\n",
      " [[0.0 9.0 0 0 2 6 2 3]]\n",
      "\n",
      " [[0.0 12.0 0 0 1 1 2 2]]\n",
      "\n",
      " [[0.0 6.0 0 0 2 1 1 3]]\n",
      "\n",
      " [[0.0 3.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 29.0 0 1 1 1 2 1]]\n",
      "\n",
      " [[0.0 8.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 14.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 8.0 0 0 2 6 2 3]]\n",
      "\n",
      " [[0.0 9.0 0 1 1 1 2 2]]\n",
      "\n",
      " [[0.0 19.0 0 1 1 1 4 1]]\n",
      "\n",
      " [[0.0 6.0 0 1 2 10 11 1]]\n",
      "\n",
      " [[0.0 2.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 5.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 4.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 46.0 0 1 1 1 2 1]]\n",
      "\n",
      " [[0.0 7.0 0 0 1 1 11 4]]\n",
      "\n",
      " [[0.0 28.0 0 1 1 1 2 2]]\n",
      "\n",
      " [[0.0 8.0 0 1 2 10 5 2]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 17.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 4.0 0 0 0 1 1 3]]\n",
      "\n",
      " [[0.0 5.0 0 1 1 10 10 3]]\n",
      "\n",
      " [[0.0 8.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 6.0 0 1 2 10 2 2]]\n",
      "\n",
      " [[0.0 5.0 0 1 1 10 2 2]]\n",
      "\n",
      " [[0.0 8.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 12.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 40.0 0 1 2 10 2 4]]\n",
      "\n",
      " [[0.0 58.0 0 0 2 6 2 2]]\n",
      "\n",
      " [[0.0 3.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 43.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 15.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 4.0 0 1 2 10 2 3]]\n",
      "\n",
      " [[0.0 6.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 0 2 1 1 2]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 53.0 0 1 1 10 11 3]]\n",
      "\n",
      " [[0.0 5.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 31.0 0 1 1 1 5 1]]\n",
      "\n",
      " [[0.0 13.0 0 0 0 1 11 3]]\n",
      "\n",
      " [[0.0 8.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 60.0 0 1 1 8 2 3]]\n",
      "\n",
      " [[0.0 10.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 9.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 9.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 43.0 0 1 2 1 5 3]]\n",
      "\n",
      " [[0.0 19.0 0 1 2 1 5 2]]\n",
      "\n",
      " [[0.0 5.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 19.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 7.0 0 1 2 1 1 2]]\n",
      "\n",
      " [[0.0 18.0 0 1 1 1 5 1]]\n",
      "\n",
      " [[0.0 14.0 0 1 1 1 2 1]]\n",
      "\n",
      " [[0.0 65.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 7.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 5.0 0 0 2 10 10 4]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 6.0 0 0 2 1 1 3]]\n",
      "\n",
      " [[0.0 12.0 0 0 0 1 2 2]]\n",
      "\n",
      " [[0.0 10.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 9.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 12.0 0 1 1 10 10 2]]\n",
      "\n",
      " [[0.0 7.0 0 1 2 1 1 3]]]\n",
      "(102, 1, 8)\n",
      "Output Labels\n",
      "------------------\n",
      "(406, 1) (102, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_transform', 'vocab_layer_norm', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "\n",
      " THESE ARE THE LAYERS\n",
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_meta (InputLayer)         [(None, 1, 8)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_idx (InputLayer)          [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1, 64)        10496       input_meta[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_3 (TFDisti ((None, 150, 768),)  66362880    input_idx[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sent_attention1 (AttentionLayer [(None, 64), (None,  528         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 768)          0           tf_distil_bert_model_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)           (None, 64)           0           sent_attention1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           49216       global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 4)            260         dropout_116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 4)            260         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8)            0           dense_14[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 4)            36          concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 66,423,676\n",
      "Trainable params: 50,300\n",
      "Non-trainable params: 66,373,376\n",
      "__________________________________________________________________________________________________\n",
      "Output Labels\n",
      "-------------------\n",
      "(406,) (102,)\n",
      "(406, 4) 406\n",
      "(102, 4) 102\n",
      "12/12 [==============================] - 4s 352ms/step - loss: 1.3744 - binary_accuracy: 0.7500 - categorical_accuracy: 0.3479 - val_loss: 1.3889 - val_binary_accuracy: 0.7500 - val_categorical_accuracy: 0.2927\n",
      "[]\n",
      "4/4 [==============================] - 0s 94ms/step\n",
      "ACCURACY:\n",
      "0.4019607843137255\n",
      "\n",
      " [[41 20 36  5]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]] \n",
      "\n",
      "Inside get_metadata_features\n",
      "Meta data\n",
      "------------------\n",
      "Training set\n",
      "------------------\n",
      "[[[0.0 6.0 0 ... 1 1 3]]\n",
      "\n",
      " [[0.0 5.0 0 ... 1 1 2]]\n",
      "\n",
      " [[0.0 14.0 0 ... 1 1 2]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.0 6.0 0 ... 10 2 3]]\n",
      "\n",
      " [[0.0 12.0 0 ... 1 2 3]]\n",
      "\n",
      " [[0.0 6.0 0 ... 1 2 1]]]\n",
      "(406, 1, 8)\n",
      "Meta data\n",
      "------------------\n",
      "Test set\n",
      "------------------\n",
      "[[[0.0 14.0 0 1 1 1 2 1]]\n",
      "\n",
      " [[0.0 13.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 0 2 1 5 3]]\n",
      "\n",
      " [[0.0 7.0 0 0 1 1 11 1]]\n",
      "\n",
      " [[0.0 7.0 0 0 0 1 2 2]]\n",
      "\n",
      " [[0.0 13.0 0 1 2 10 2 3]]\n",
      "\n",
      " [[0.0 10.0 0 1 2 10 2 2]]\n",
      "\n",
      " [[0.0 9.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 3.0 0 1 2 10 10 2]]\n",
      "\n",
      " [[0.0 15.0 0 0 0 1 1 3]]\n",
      "\n",
      " [[0.0 53.0 0 0 0 1 1 2]]\n",
      "\n",
      " [[0.0 12.0 0 0 1 1 9 4]]\n",
      "\n",
      " [[0.0 12.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 11.0 0 1 1 6 2 3]]\n",
      "\n",
      " [[0.0 7.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 43.0 0 0 2 1 11 3]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 7.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 17.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 7.0 0 0 0 1 2 2]]\n",
      "\n",
      " [[0.0 107.0 0 0 1 1 2 4]]\n",
      "\n",
      " [[0.0 13.0 0 0 2 1 2 2]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 7.0 0 0 1 1 11 3]]\n",
      "\n",
      " [[0.0 51.0 0 1 2 1 2 1]]\n",
      "\n",
      " [[0.0 5.0 0 1 1 10 10 3]]\n",
      "\n",
      " [[0.0 9.0 0 1 1 6 2 1]]\n",
      "\n",
      " [[0.0 9.0 0 1 1 1 2 3]]\n",
      "\n",
      " [[0.0 20.0 0 0 1 1 11 2]]\n",
      "\n",
      " [[0.0 8.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 59.0 0 1 2 10 2 3]]\n",
      "\n",
      " [[0.0 27.0 0 1 1 10 2 4]]\n",
      "\n",
      " [[0.0 58.0 0 0 2 6 2 2]]\n",
      "\n",
      " [[0.0 4.0 0 1 1 11 2 3]]\n",
      "\n",
      " [[0.0 3.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 0 0 1 1 1]]\n",
      "\n",
      " [[0.0 4.0 0 1 2 1 1 2]]\n",
      "\n",
      " [[0.0 5.0 0 0 2 1 4 1]]\n",
      "\n",
      " [[0.0 7.0 0 1 2 10 2 2]]\n",
      "\n",
      " [[0.0 27.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 5.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 29.0 0 1 1 1 2 3]]\n",
      "\n",
      " [[0.0 12.0 0 0 1 1 2 1]]\n",
      "\n",
      " [[0.0 25.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 59.0 0 1 2 10 2 3]]\n",
      "\n",
      " [[0.0 4.0 0 0 0 1 1 1]]\n",
      "\n",
      " [[0.0 46.0 0 1 1 1 2 3]]\n",
      "\n",
      " [[0.0 18.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 34.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 6.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 6.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 40.0 0 1 2 10 2 4]]\n",
      "\n",
      " [[0.0 18.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 25.0 0 1 1 10 2 2]]\n",
      "\n",
      " [[0.0 88.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 5.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 9.0 0 0 0 1 1 2]]\n",
      "\n",
      " [[0.0 12.0 0 0 0 1 1 3]]\n",
      "\n",
      " [[0.0 28.0 0 0 2 10 2 3]]\n",
      "\n",
      " [[0.0 6.0 0 1 1 10 10 1]]\n",
      "\n",
      " [[0.0 7.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 25.0 0 0 2 1 2 4]]\n",
      "\n",
      " [[0.0 14.0 0 1 1 10 2 4]]\n",
      "\n",
      " [[0.0 17.0 0 1 2 1 5 2]]\n",
      "\n",
      " [[0.0 59.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 14.0 0 1 1 1 1 1]]\n",
      "\n",
      " [[0.0 6.0 0 1 1 10 10 1]]\n",
      "\n",
      " [[0.0 13.0 0 0 1 1 11 2]]\n",
      "\n",
      " [[0.0 8.0 0 0 2 6 2 2]]\n",
      "\n",
      " [[0.0 43.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 3.0 0 1 1 10 10 2]]\n",
      "\n",
      " [[0.0 57.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 20.0 0 1 1 10 2 2]]\n",
      "\n",
      " [[0.0 6.0 0 1 2 10 2 3]]\n",
      "\n",
      " [[0.0 30.0 0 1 1 10 10 3]]\n",
      "\n",
      " [[0.0 13.0 0 0 1 1 11 1]]\n",
      "\n",
      " [[0.0 17.0 0 1 1 10 2 4]]\n",
      "\n",
      " [[0.0 10.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 65.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 15.0 0 1 2 10 10 1]]\n",
      "\n",
      " [[0.0 10.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 12.0 0 1 1 10 2 2]]\n",
      "\n",
      " [[0.0 44.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 43.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 34.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 33.0 0 0 1 1 2 2]]\n",
      "\n",
      " [[0.0 51.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 88.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 4.0 0 1 2 10 2 3]]\n",
      "\n",
      " [[0.0 5.0 0 0 1 1 1 4]]\n",
      "\n",
      " [[0.0 7.0 0 1 2 1 1 2]]\n",
      "\n",
      " [[0.0 70.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 18.0 0 0 2 10 2 3]]\n",
      "\n",
      " [[0.0 13.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 4.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 11.0 0 0 0 6 2 3]]\n",
      "\n",
      " [[0.0 7.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 31.0 0 0 1 10 2 3]]\n",
      "\n",
      " [[0.0 24.0 0 0 2 1 2 1]]]\n",
      "(102, 1, 8)\n",
      "Output Labels\n",
      "------------------\n",
      "(406, 1) (102, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_transform', 'vocab_layer_norm', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "\n",
      " THESE ARE THE LAYERS\n",
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_meta (InputLayer)         [(None, 1, 8)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_idx (InputLayer)          [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1, 64)        10496       input_meta[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_4 (TFDisti ((None, 150, 768),)  66362880    input_idx[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sent_attention1 (AttentionLayer [(None, 64), (None,  528         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 768)          0           tf_distil_bert_model_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)           (None, 64)           0           sent_attention1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 64)           49216       global_average_pooling1d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 4)            260         dropout_136[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 4)            260         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8)            0           dense_18[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 4)            36          concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 66,423,676\n",
      "Trainable params: 50,300\n",
      "Non-trainable params: 66,373,376\n",
      "__________________________________________________________________________________________________\n",
      "Output Labels\n",
      "-------------------\n",
      "(406,) (102,)\n",
      "(406, 4) 406\n",
      "(102, 4) 102\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.3502 - binary_accuracy: 0.7500 - categorical_accuracy: 0.3260WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f01b57fe268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "12/12 [==============================] - 4s 354ms/step - loss: 1.3502 - binary_accuracy: 0.7500 - categorical_accuracy: 0.3260 - val_loss: 1.3534 - val_binary_accuracy: 0.7500 - val_categorical_accuracy: 0.2927\n",
      "[]\n",
      "4/4 [==============================] - 0s 98ms/step\n",
      "ACCURACY:\n",
      "0.22549019607843138\n",
      "\n",
      " [[10  6  4  6]\n",
      " [16  1 16  1]\n",
      " [17 12 12  1]\n",
      " [ 0  0  0  0]] \n",
      "\n",
      "Inside get_metadata_features\n",
      "Meta data\n",
      "------------------\n",
      "Training set\n",
      "------------------\n",
      "[[[0.0 60.0 0 ... 8 2 3]]\n",
      "\n",
      " [[0.0 3.0 0 ... 10 10 2]]\n",
      "\n",
      " [[0.0 5.0 0 ... 1 1 1]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.0 9.0 0 ... 1 2 1]]\n",
      "\n",
      " [[0.0 11.0 0 ... 10 2 2]]\n",
      "\n",
      " [[0.0 8.0 0 ... 6 2 2]]]\n",
      "(406, 1, 8)\n",
      "Meta data\n",
      "------------------\n",
      "Test set\n",
      "------------------\n",
      "[[[0.0 15.0 0 0 1 1 2 1]]\n",
      "\n",
      " [[0.0 61.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 1 2 10 2 2]]\n",
      "\n",
      " [[0.0 7.0 0 0 2 10 10 3]]\n",
      "\n",
      " [[0.0 21.0 0 1 1 1 2 4]]\n",
      "\n",
      " [[0.0 14.0 0 0 2 11 11 3]]\n",
      "\n",
      " [[0.0 51.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 9.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 6.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 13.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 34.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 13.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 5.0 0 0 1 1 1 4]]\n",
      "\n",
      " [[0.0 4.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 17.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 20.0 0 1 2 10 2 2]]\n",
      "\n",
      " [[0.0 10.0 0 1 2 12 12 3]]\n",
      "\n",
      " [[0.0 7.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 14.0 0 1 1 1 2 2]]\n",
      "\n",
      " [[0.0 43.0 0 0 1 1 2 1]]\n",
      "\n",
      " [[0.0 5.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 4.0 0 0 1 1 2 4]]\n",
      "\n",
      " [[0.0 15.0 0 0 0 12 2 2]]\n",
      "\n",
      " [[0.0 10.0 0 1 1 10 2 2]]\n",
      "\n",
      " [[0.0 88.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 3.0 0 1 2 10 10 2]]\n",
      "\n",
      " [[0.0 27.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 2.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 65.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 9.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 14.0 0 1 1 10 2 4]]\n",
      "\n",
      " [[0.0 5.0 0 1 1 1 1 2]]\n",
      "\n",
      " [[0.0 8.0 0 0 0 1 2 2]]\n",
      "\n",
      " [[0.0 58.0 0 0 2 6 2 1]]\n",
      "\n",
      " [[0.0 18.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 25.0 0 0 0 1 1 0]]\n",
      "\n",
      " [[0.0 8.0 0 0 2 10 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 40.0 0 0 2 6 11 3]]\n",
      "\n",
      " [[0.0 33.0 0 0 1 1 2 2]]\n",
      "\n",
      " [[0.0 26.0 0 1 2 10 10 1]]\n",
      "\n",
      " [[0.0 44.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 25.0 0 0 2 1 2 4]]\n",
      "\n",
      " [[0.0 17.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 50.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 30.0 0 1 1 1 5 1]]\n",
      "\n",
      " [[0.0 4.0 0 1 2 12 12 3]]\n",
      "\n",
      " [[0.0 10.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 12.0 0 0 1 1 2 1]]\n",
      "\n",
      " [[0.0 15.0 0 0 0 1 1 1]]\n",
      "\n",
      " [[0.0 34.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 14.0 0 0 1 1 2 3]]\n",
      "\n",
      " [[0.0 10.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 6.0 0 1 1 10 10 1]]\n",
      "\n",
      " [[0.0 5.0 0 1 1 10 10 1]]\n",
      "\n",
      " [[0.0 18.0 0 1 2 9 2 1]]\n",
      "\n",
      " [[0.0 9.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 37.0 0 0 2 1 2 2]]\n",
      "\n",
      " [[0.0 5.0 0 1 1 10 2 2]]\n",
      "\n",
      " [[0.0 19.0 0 1 2 6 4 3]]\n",
      "\n",
      " [[0.0 9.0 0 1 1 6 2 1]]\n",
      "\n",
      " [[0.0 11.0 0 0 0 6 2 3]]\n",
      "\n",
      " [[0.0 4.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 3.0 0 1 2 10 2 3]]\n",
      "\n",
      " [[0.0 15.0 0 1 1 10 4 2]]\n",
      "\n",
      " [[0.0 25.0 0 0 0 1 2 4]]\n",
      "\n",
      " [[0.0 25.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 20.0 0 0 1 1 11 2]]\n",
      "\n",
      " [[0.0 15.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 43.0 0 1 2 1 5 3]]\n",
      "\n",
      " [[0.0 8.0 0 1 2 1 9 2]]\n",
      "\n",
      " [[0.0 14.0 0 0 0 1 2 2]]\n",
      "\n",
      " [[0.0 17.0 0 1 1 9 9 3]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 10 2 3]]\n",
      "\n",
      " [[0.0 27.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 43.0 0 0 2 1 11 3]]\n",
      "\n",
      " [[0.0 10.0 0 0 0 6 6 2]]\n",
      "\n",
      " [[0.0 26.0 0 0 2 1 2 3]]\n",
      "\n",
      " [[0.0 5.0 0 0 0 1 1 3]]\n",
      "\n",
      " [[0.0 9.0 0 1 1 1 2 1]]\n",
      "\n",
      " [[0.0 79.0 0 1 1 9 9 2]]\n",
      "\n",
      " [[0.0 12.0 0 1 1 1 1 3]]\n",
      "\n",
      " [[0.0 13.0 0 1 2 1 2 3]]\n",
      "\n",
      " [[0.0 45.0 0 0 1 1 2 1]]\n",
      "\n",
      " [[0.0 9.0 0 1 2 1 2 1]]\n",
      "\n",
      " [[0.0 25.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 5.0 0 1 2 10 10 1]]\n",
      "\n",
      " [[0.0 66.0 0 0 1 6 2 4]]\n",
      "\n",
      " [[0.0 21.0 0 0 0 1 2 1]]\n",
      "\n",
      " [[0.0 27.0 0 1 1 10 2 4]]\n",
      "\n",
      " [[0.0 43.0 0 1 1 10 2 1]]\n",
      "\n",
      " [[0.0 57.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 5.0 0 1 1 10 10 1]]\n",
      "\n",
      " [[0.0 7.0 0 1 1 1 2 2]]\n",
      "\n",
      " [[0.0 10.0 0 1 2 10 2 1]]\n",
      "\n",
      " [[0.0 10.0 0 0 0 1 2 3]]\n",
      "\n",
      " [[0.0 55.0 0 0 1 1 2 1]]\n",
      "\n",
      " [[0.0 4.0 0 0 0 1 1 2]]\n",
      "\n",
      " [[0.0 8.0 0 0 2 1 2 1]]\n",
      "\n",
      " [[0.0 11.0 0 1 1 6 2 3]]\n",
      "\n",
      " [[0.0 19.0 0 1 1 1 4 1]]]\n",
      "(102, 1, 8)\n",
      "Output Labels\n",
      "------------------\n",
      "(406, 1) (102, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_transform', 'vocab_layer_norm', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "\n",
      " THESE ARE THE LAYERS\n",
      "Model: \"functional_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_meta (InputLayer)         [(None, 1, 8)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_idx (InputLayer)          [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1, 64)        10496       input_meta[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_5 (TFDisti ((None, 150, 768),)  66362880    input_idx[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sent_attention1 (AttentionLayer [(None, 64), (None,  528         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 768)          0           tf_distil_bert_model_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_156 (Dropout)           (None, 64)           0           sent_attention1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 64)           49216       global_average_pooling1d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 4)            260         dropout_156[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 4)            260         dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 8)            0           dense_22[0][0]                   \n",
      "                                                                 dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 4)            36          concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 66,423,676\n",
      "Trainable params: 50,300\n",
      "Non-trainable params: 66,373,376\n",
      "__________________________________________________________________________________________________\n",
      "Output Labels\n",
      "-------------------\n",
      "(406,) (102,)\n",
      "(406, 4) 406\n",
      "(102, 4) 102\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.4598 - binary_accuracy: 0.7500 - categorical_accuracy: 0.2822WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f01ae081840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.4598 - binary_accuracy: 0.7500 - categorical_accuracy: 0.2822 - val_loss: 1.4256 - val_binary_accuracy: 0.7500 - val_categorical_accuracy: 0.3171\n",
      "[]\n",
      "4/4 [==============================] - 0s 97ms/step\n",
      "ACCURACY:\n",
      "0.21568627450980393\n",
      "\n",
      " [[ 0  0  0  0]\n",
      " [36 17 31  7]\n",
      " [ 4  1  5  1]\n",
      " [ 0  0  0  0]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "tf_config = tf.compat.v1.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "tf_config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "tf_config.allow_soft_placement = True\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Bidirectional, GlobalMaxPool1D, GlobalAveragePooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, model_from_json\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# checkpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.layers import Attention\n",
    "\n",
    "\"\"\"\n",
    "Required for NLP model\n",
    "\"\"\"\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()   \n",
    "\n",
    "# set parameters for word embeddings\n",
    "embed_size = 100 # how big is each word vector\n",
    "vocab_size = 25000 # how many unique words to use (i.e num rows in embedding vector) max\n",
    "input_length = 100 # max number of words in the input \n",
    "\n",
    "#set parameters for bilstm\n",
    "BATCH_SIZE=32\n",
    "EPOCHS=1 #300\n",
    "\n",
    "#EMBEDDING_FILE='glove.6B.100d.txt'    \n",
    "\n",
    "file = open('/content/drive/My Drive/Python Notebook/SCS_CONVEX/output/Search Tasks/meta-bert-attn/bilstm_meta_bert_attn_op.txt','w') #overwrites previous\n",
    "file.close()\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    df_prediction = pd.DataFrame()\n",
    "    df_accuracy =  pd.DataFrame()\n",
    "    file = open('/content/drive/My Drive/Python Notebook/SCS_CONVEX/output/Search Tasks/meta-bert-attn/bilstm_meta_bert_attn_op.txt','a') #append mode \n",
    "    \"\"\"\n",
    "    Change the range before executing\n",
    "    \"\"\"\n",
    "    for i in range(5,11):\n",
    "        outputname = 'meta_bert_attn'+ str(i)        \n",
    "        predictions, acc, conf_matrix = execute_bilstm_meta_bert_channel(i)\n",
    "        df_prediction[outputname] = predictions\n",
    "        df_accuracy[i] = [acc]\n",
    "        file.write(\"\\nIteration:\" + str(i) + \"\\nCategorical Accuracy:\" + str(acc) + \n",
    "                    \"\\nConfusion Matrix:\\n\" + str(conf_matrix) + \"\\n\\n\")\n",
    "        df_prediction.to_csv('/content/drive/My Drive/Python Notebook/SCS_CONVEX/output/Search Tasks/meta-bert-attn/predictions_bilstm_meta_bert_attn_' + str(i) + '.csv')    \n",
    "        df_accuracy.to_csv('/content/drive/My Drive/Python Notebook/SCS_CONVEX/output/Search Tasks/meta-bert-attn/accuracy_bilstm_meta_bert_attn_' + str(i) + '.csv')    \n",
    "    \n",
    "    df_prediction.to_csv('/content/drive/My Drive/Python Notebook/SCS_CONVEX/output/Search Tasks/meta-bert-attn/predictions_bilstm_meta_bert_attn.csv')    \n",
    "    df_accuracy.to_csv('/content/drive/My Drive/Python Notebook/SCS_CONVEX/output/Search Tasks/meta-bert-attn/accuracy_bilstm_meta_bert_attn.csv')    \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NeapZe3j6XUn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMtLInPjccW6KqFykKtFctY",
   "collapsed_sections": [
    "7qHEd58YoMdL",
    "g9dNbyTVomQB"
   ],
   "name": "Search_Task_meta_bert_attn_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0116bcbc437945248db742e3e8449119": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08225350738f4eda80b04e7acd78ab6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "16ae2bcc93254828bb381680db1e0ec9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bf09a37e050409089d1bdb16d026e68",
      "max": 363423424,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4b2ce0e2377a48ae9c467ff55d145015",
      "value": 363423424
     }
    },
    "16d2cb6bd9694f108856ebbd50f7e87f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa9c7ce6e1f6462186db4faa5d239f74",
       "IPY_MODEL_453b861e1ca84482b2f675a78aa8b963"
      ],
      "layout": "IPY_MODEL_458ca1c7330b467d91046cdb235396f9"
     }
    },
    "1936274243f5452ab867c6a4ade1a694": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33dc31d39c2b4c3ea1034f401836d245",
      "placeholder": "​",
      "style": "IPY_MODEL_461117018af046158e4d59bf95661b86",
      "value": " 232k/232k [00:00&lt;00:00, 259kB/s]"
     }
    },
    "33dc31d39c2b4c3ea1034f401836d245": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a817b84538b495aa33df8d8ab830d48": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "453b861e1ca84482b2f675a78aa8b963": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b37793c0f9547f58012dbc5e2e933d4",
      "placeholder": "​",
      "style": "IPY_MODEL_a4acee8ccfaa4226874f765ae468b01d",
      "value": " 442/442 [00:00&lt;00:00, 1.13kB/s]"
     }
    },
    "458ca1c7330b467d91046cdb235396f9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "461117018af046158e4d59bf95661b86": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b2ce0e2377a48ae9c467ff55d145015": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4b9de3dec8f74577ba87e10253f40a00": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_59d7ef87be104cf0aeee435a179ef4c7",
       "IPY_MODEL_1936274243f5452ab867c6a4ade1a694"
      ],
      "layout": "IPY_MODEL_3a817b84538b495aa33df8d8ab830d48"
     }
    },
    "59d7ef87be104cf0aeee435a179ef4c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af4e33765b3a46be91f13bba4e266ddc",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_64bf32cba4f342c486e74d03f03b0724",
      "value": 231508
     }
    },
    "5bf09a37e050409089d1bdb16d026e68": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64bf32cba4f342c486e74d03f03b0724": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6b37793c0f9547f58012dbc5e2e933d4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fda16b2d2bf478088b516948be38856": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a02b1e0fccae4eea9dbc22987ebedcd2",
      "placeholder": "​",
      "style": "IPY_MODEL_9a706da06583442d867ea30378f0a7fa",
      "value": " 363M/363M [00:21&lt;00:00, 17.3MB/s]"
     }
    },
    "91aa0aeca61d4f0f8854d605f02dd0ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a706da06583442d867ea30378f0a7fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a02b1e0fccae4eea9dbc22987ebedcd2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4acee8ccfaa4226874f765ae468b01d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa9c7ce6e1f6462186db4faa5d239f74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91aa0aeca61d4f0f8854d605f02dd0ac",
      "max": 442,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_08225350738f4eda80b04e7acd78ab6f",
      "value": 442
     }
    },
    "af4e33765b3a46be91f13bba4e266ddc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6d3c033fcff4b898a3da807cbc16c65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_16ae2bcc93254828bb381680db1e0ec9",
       "IPY_MODEL_8fda16b2d2bf478088b516948be38856"
      ],
      "layout": "IPY_MODEL_0116bcbc437945248db742e3e8449119"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
