{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Search_Task_BERT_modified_v1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNv42BDd3gPdu4TXTzd6KKS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6450933cd3e646b098f67a2d27ee20cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cb8606b35e6243af84fbcc3bb1b07185","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8e9ce1e6eff84e4babb761e7476e1cd1","IPY_MODEL_69292f4c4a6141c7927d04cf16f3672a"]}},"cb8606b35e6243af84fbcc3bb1b07185":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8e9ce1e6eff84e4babb761e7476e1cd1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d9fc46de63c64ce39b24646933784ce7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":442,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":442,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0c320450484f46dbb5b16c5202a9a79f"}},"69292f4c4a6141c7927d04cf16f3672a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4a9406488ad344e883ee4b4e71a524e8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 442/442 [00:21&lt;00:00, 21.0B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6ddbef437427480cac6f29e14020dc4c"}},"d9fc46de63c64ce39b24646933784ce7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0c320450484f46dbb5b16c5202a9a79f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a9406488ad344e883ee4b4e71a524e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6ddbef437427480cac6f29e14020dc4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"06cd9537a5e14fdca997ff3ad5606d28":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7bb4078ffe6e4617bdf6615885188242","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_180cbaf5f2b04cbfa54605f49898ec3e","IPY_MODEL_3ec6801409ff442cbd2c74e2fa311f8f"]}},"7bb4078ffe6e4617bdf6615885188242":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"180cbaf5f2b04cbfa54605f49898ec3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b2dfcee50de2476b99f47d5597bd6665","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":363423424,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":363423424,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_641f5673eb864d1883e02f329b551119"}},"3ec6801409ff442cbd2c74e2fa311f8f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_26b38fa90c8f4cdcb96950fa9a25c4b3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 363M/363M [00:05&lt;00:00, 64.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dc557229c6054571aaabe25913cbbe11"}},"b2dfcee50de2476b99f47d5597bd6665":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"641f5673eb864d1883e02f329b551119":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"26b38fa90c8f4cdcb96950fa9a25c4b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dc557229c6054571aaabe25913cbbe11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a3d6634b2dcf4d9f9712bf05d8b7e158":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_58a03600212b43cfa4a9d47e8de8746c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_262117a396ec49baa89cf42828f06ebe","IPY_MODEL_20db35051a034d3299bd7fd5da8cd92e"]}},"58a03600212b43cfa4a9d47e8de8746c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"262117a396ec49baa89cf42828f06ebe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d5b4880cca154c6983808868b27bf77d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d20f58c3c95949778ba755b3c8a5e566"}},"20db35051a034d3299bd7fd5da8cd92e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_958d3b9281bf4be7ae5bd8a502ee048d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 783kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a01559127321409b889cc511821ac3a3"}},"d5b4880cca154c6983808868b27bf77d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d20f58c3c95949778ba755b3c8a5e566":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"958d3b9281bf4be7ae5bd8a502ee048d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a01559127321409b889cc511821ac3a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"nZwoKwPKn9mG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1597353849280,"user_tz":-330,"elapsed":29036,"user":{"displayName":"Satanu Ghosh","photoUrl":"","userId":"04517623213450830512"}},"outputId":"ca02e71d-18c3-4f5b-840d-e8e318af9a2a"},"source":["from google.colab import drive\n","drive.mount('/content/drive',  force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L_s-cnCRyJPI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":615},"executionInfo":{"status":"ok","timestamp":1597353861755,"user_tz":-330,"elapsed":9194,"user":{"displayName":"Satanu Ghosh","photoUrl":"","userId":"04517623213450830512"}},"outputId":"706c9bdb-a343-445a-8168-6491f73790c6"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 5.3MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 24.8MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 52.4MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 55.5MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=afa796901c255fee6f28f7cd293ae662c78d5d04279209838bb674319fa40323\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QsiIETlkpTyc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597353867522,"user_tz":-330,"elapsed":13645,"user":{"displayName":"Satanu Ghosh","photoUrl":"","userId":"04517623213450830512"}}},"source":["import transformers\n","import numpy as np\n","import json\n","import pandas as pd\n","import re\n","import io"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"PiHEFwJyyPxx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1597353867526,"user_tz":-330,"elapsed":10453,"user":{"displayName":"Satanu Ghosh","photoUrl":"","userId":"04517623213450830512"}},"outputId":"23d72233-bff8-44cb-df7f-0aa0df792faf"},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ydoZ8nKEyR0M","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597353878074,"user_tz":-330,"elapsed":1381,"user":{"displayName":"Satanu Ghosh","photoUrl":"","userId":"04517623213450830512"}}},"source":["from tensorflow.keras import models, layers, preprocessing as kprocessing\n","from tensorflow.keras import backend as K\n","import sklearn.metrics as metrics"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q2hqj7vPyVLN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":220,"referenced_widgets":["6450933cd3e646b098f67a2d27ee20cb","cb8606b35e6243af84fbcc3bb1b07185","8e9ce1e6eff84e4babb761e7476e1cd1","69292f4c4a6141c7927d04cf16f3672a","d9fc46de63c64ce39b24646933784ce7","0c320450484f46dbb5b16c5202a9a79f","4a9406488ad344e883ee4b4e71a524e8","6ddbef437427480cac6f29e14020dc4c","06cd9537a5e14fdca997ff3ad5606d28","7bb4078ffe6e4617bdf6615885188242","180cbaf5f2b04cbfa54605f49898ec3e","3ec6801409ff442cbd2c74e2fa311f8f","b2dfcee50de2476b99f47d5597bd6665","641f5673eb864d1883e02f329b551119","26b38fa90c8f4cdcb96950fa9a25c4b3","dc557229c6054571aaabe25913cbbe11"]},"executionInfo":{"status":"ok","timestamp":1597353904651,"user_tz":-330,"elapsed":25265,"user":{"displayName":"Satanu Ghosh","photoUrl":"","userId":"04517623213450830512"}},"outputId":"9d3c1c8b-1f92-4974-b82b-3b3d2fd42404"},"source":["nlp = transformers.TFBertModel.from_pretrained('distilbert-base-uncased')"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6450933cd3e646b098f67a2d27ee20cb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06cd9537a5e14fdca997ff3ad5606d28","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=363423424.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFBertModel: ['vocab_projector', 'vocab_transform', 'vocab_layer_norm', 'activation_13', 'distilbert']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of TFBertModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['bert']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"dgTtdCAIyYy2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["a3d6634b2dcf4d9f9712bf05d8b7e158","58a03600212b43cfa4a9d47e8de8746c","262117a396ec49baa89cf42828f06ebe","20db35051a034d3299bd7fd5da8cd92e","d5b4880cca154c6983808868b27bf77d","d20f58c3c95949778ba755b3c8a5e566","958d3b9281bf4be7ae5bd8a502ee048d","a01559127321409b889cc511821ac3a3"]},"executionInfo":{"status":"ok","timestamp":1597353905350,"user_tz":-330,"elapsed":14191,"user":{"displayName":"Satanu Ghosh","photoUrl":"","userId":"04517623213450830512"}},"outputId":"9ca7ac96-22c4-4844-b0a0-f4b9a63f4a27"},"source":["tokenizer = transformers.AutoTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3d6634b2dcf4d9f9712bf05d8b7e158","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bVYbsz1NoaAl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597358239635,"user_tz":-330,"elapsed":1442,"user":{"displayName":"Satanu Ghosh","photoUrl":"","userId":"04517623213450830512"}}},"source":["def load_files(i):\n","\n","    df_X_train= pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/search/X_train_' + str(i) + '.pkl')\n","    df_X_test= pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/search/X_test_' + str(i) + '.pkl')\n","    df_Y_train=pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/search/Y_train_' + str(i) + '.pkl')\n","    df_Y_test=pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/search/Y_test_' + str(i) + '.pkl')\n","    df_train = pd.concat([df_X_train,df_Y_train], axis=1)\n","    df_test = pd.concat([df_X_test,df_Y_test], axis=1)\n","\n","    #print(list(df_train.columns))\n","\n","    df_train = df_train[[\"Search_acts\",\"Previous_User_Utterance\"]]\n","    df_train = df_train.rename(columns={\"Search_acts\":\"y\", \"Previous_User_Utterance\":\"text\"})\n","\n","    \n","\n","    df_test = df_test[[\"Search_acts\",\"Previous_User_Utterance\"]]\n","    df_test = df_test.rename(columns={\"Search_acts\":\"y\", \"Previous_User_Utterance\":\"text\"})\n","\n","    return df_train,df_test,df_Y_train,df_Y_test"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fe1fa6dZyZbe","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597358242434,"user_tz":-330,"elapsed":1536,"user":{"displayName":"Satanu Ghosh","photoUrl":"","userId":"04517623213450830512"}}},"source":["def generate_maskid(training, test):\n","  #print(training['text'])\n","  corpus_train = training['text']\n","  corpus_test = test['text']\n","  #the length of the feature vector is 150\n","  maxlen = 150\n","\n","  #add special tokens\n","  maxqnans = np.int((maxlen-20)/2)\n","  corpus_tokenized_train = [\"[CLS] \"+\n","              \" \".join(tokenizer.tokenize(re.sub(r'[^\\w\\s]+|\\n', '', \n","              str(txt).lower().strip()))[:maxqnans])+\n","              \" [SEP] \" for txt in corpus_train]\n","  corpus_tokenized_test = [\"[CLS] \"+\n","              \" \".join(tokenizer.tokenize(re.sub(r'[^\\w\\s]+|\\n', '', \n","              str(txt).lower().strip()))[:maxqnans])+\n","              \" [SEP] \" for txt in corpus_test]\n","  #generate masks\n","  masks_train = [[1]*len(txt.split(\" \")) + [0]*(maxlen - len(txt.split(\" \"))) for txt in corpus_tokenized_train]\n","  masks_test = [[1]*len(txt.split(\" \")) + [0]*(maxlen - len(txt.split(\" \"))) for txt in corpus_tokenized_test]\n","\n","  #padding\n","  txt2seq_train = [txt + \" [PAD]\"*(maxlen-len(txt.split(\" \"))-2) if len(txt.split(\" \")) != (maxlen) else txt for txt in corpus_tokenized_train]\n","  txt2seq_test = [txt + \" [PAD]\"*(maxlen-len(txt.split(\" \"))-2) if len(txt.split(\" \")) != (maxlen) else txt for txt in corpus_tokenized_test]\n","\n","  #generate idx\n","  idx_train = [tokenizer.encode(seq.split(\" \")) for seq in txt2seq_train]\n","  idx_test = [tokenizer.encode(seq.split(\" \")) for seq in txt2seq_test]      \n","\n","  ## feature matrix\n","  X_train = [np.asarray(idx_train, dtype='int32'), \n","            np.asarray(masks_train, dtype='int32')]\n","  X_test = [np.asarray(idx_test, dtype='int32'), \n","            np.asarray(masks_test, dtype='int32')]\n","  i = 0\n","  #print(\"txt: \", training[\"text\"].iloc[0])\n","  #print(\"tokenized:\", [tokenizer.convert_ids_to_tokens(idx) for idx in X_train[0][i].tolist()])\n","  #print(\"idx: \", X_train[0][i])\n","  #print(\"mask: \", X_train[1][i])\n","  return X_train, X_test\n"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"-hW5atNb_OXe","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597358245019,"user_tz":-330,"elapsed":1066,"user":{"displayName":"Satanu Ghosh","photoUrl":"","userId":"04517623213450830512"}}},"source":["def model_generate(y_train):\n","\n","  ## inputs\n","  idx = layers.Input((150), dtype=\"int32\", name=\"input_idx\")\n","  masks = layers.Input((150), dtype=\"int32\", name=\"input_masks\")\n","  ## pre-trained bert with config\n","  config = transformers.DistilBertConfig(dropout=0.2,attention_dropout=0.2)\n","  config.output_hidden_states = False\n","  nlp = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config)\n","  bert_out = nlp(idx, attention_mask=masks)[0]\n","  ## fine-tuning\n","  x = layers.GlobalAveragePooling1D()(bert_out)\n","  x = layers.Dense(64, activation=\"relu\")(x)\n","  #x = layers.Dense(32, activation=\"relu\")(x)\n","  y_out = layers.Dense(len(np.unique(y_train)), activation='softmax')(x)\n","\n","  #nlp2 = transformers.TFDistilBertModel.from_pretrained('distilroberta-base', config=config)\n","  #bert_out2 = nlp2(idx, attention_mask=masks)[0]\n","  #x2 = layers.GlobalAveragePooling1D()(bert_out2)\n","  #x2 = layers.Dense(32, activation=\"relu\")(x2)\n","  #y_out = layers.Dense(len(np.unique(y_train)), activation='softmax')(x2)\n","\n","\n","\n","  ## compile\n","  model = models.Model([idx, masks], y_out)\n","  for layer in model.layers[:3]:\n","      layer.trainable = False\n","  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  model.summary()\n","\n","  return model"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"WD18HoKMA0i7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597358246281,"user_tz":-330,"elapsed":760,"user":{"displayName":"Satanu Ghosh","photoUrl":"","userId":"04517623213450830512"}}},"source":["def model_train(X_train, y_train, model):\n","\n","  ## encode y\n","  dic_y_mapping = {n:label for n,label in enumerate(np.unique(y_train))}\n","  print(dic_y_mapping)\n","  inverse_dic = {v:k for k,v in dic_y_mapping.items()}\n","  print(inverse_dic)\n","  y_train2 = np.array([inverse_dic[y] for y in y_train])\n","  ## train\n","  training = model.fit(x=X_train, y=y_train2, batch_size=32, epochs=300, shuffle=True, verbose=1, validation_split=0.3)\n","\n","  training_acc = training.history['accuracy']\n","  training_loss = training.history['loss']\n","  #print(acc)\n","  #loss, accuracy = model.evaluate(x=X_test, y=y_test, batch_size=32, verbose=1)\n","  return training_acc, training_loss\n","  #loss, accuracy = model.evaluate(x=X_train, y=y_train, batch_size=32, verbose=1)"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"1SdtopVqGXKC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597358247637,"user_tz":-330,"elapsed":825,"user":{"displayName":"Satanu Ghosh","photoUrl":"","userId":"04517623213450830512"}}},"source":["def test_classification(X_test, y_test, y_train):\n","\n","  dic_y_mapping = {n:label for n,label in enumerate(np.unique(y_train))}\n","  #print(np.unique(y_test))\n","  predicted_prob = model.predict(X_test)\n","  #print(predicted_prob)\n","  predicted = [dic_y_mapping[np.argmax(pred)] for pred in predicted_prob]\n","\n","  return predicted, predicted_prob"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"o01rCHBrKial","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597358249056,"user_tz":-330,"elapsed":782,"user":{"displayName":"Satanu Ghosh","photoUrl":"","userId":"04517623213450830512"}}},"source":["def result_visualization(y_test, predicted, predicted_prob,y_train):\n","\n","  classes = np.unique(y_test)\n","  y_test_array = pd.get_dummies(y_test, drop_first=False).values\n","      \n","  ## Accuracy, Precision, Recall\n","  accuracy = metrics.accuracy_score(y_test, predicted)\n","  #auc = metrics.roc_auc_score(y_train, predicted_prob, \n","  #                            multi_class=\"ovr\")\n","  details = metrics.classification_report(y_test, predicted)\n","  print(\"Accuracy:\",  accuracy)\n","  #print(\"Auc:\", round(auc,2))\n","  print(\"Detail:\")\n","  print(metrics.classification_report(y_test, predicted))\n","      \n","  ## Plot confusion matrix\n","  cm = metrics.confusion_matrix(y_test, predicted)\n","  fig, ax = plt.subplots()\n","  sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n","              cbar=False)\n","  ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n","        yticklabels=classes, title=\"Confusion matrix\")\n","  plt.yticks(rotation=0)\n","\n","  #fig, ax = plt.subplots(nrows=1, ncols=2)\n","  ## Plot roc\n","  #for i in range(len(classes)):\n","   #   fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  \n","   #                         predicted_prob[:,i])\n","   #   ax[0].plot(fpr, tpr, lw=3, \n","   #             label='{0} (area={1:0.2f})'.format(classes[i], \n","   #                             metrics.auc(fpr, tpr))\n","   #            )\n","  #ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n","  #ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n","   #         xlabel='False Positive Rate', \n","   #         ylabel=\"True Positive Rate (Recall)\", \n","   #         title=\"Receiver operating characteristic\")\n","  #ax[0].legend(loc=\"lower right\")\n","  #ax[0].grid(True)\n","      \n","  ## Plot precision-recall curve\n","  #for i in range(len(classes)):\n","  #    precision, recall, thresholds = metrics.precision_recall_curve(\n","  #                y_test_array[:,i], predicted_prob[:,i])\n","  #             label='{0} (area={1:0.2f})'.format(classes[i], \n","  #                                  metrics.auc(recall, precision))\n","  #             )\n","  #ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n","  #          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n","  #ax[1].legend(loc=\"best\")\n","  #ax[1].grid(True)\n","  plt.show()\n","\n","  return accuracy, details, cm"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"KdvYG8UJozLa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597359730652,"user_tz":-330,"elapsed":1396890,"user":{"displayName":"Satanu Ghosh","photoUrl":"","userId":"04517623213450830512"}},"outputId":"3125a29c-5f70-4506-84aa-b3063e3b695e"},"source":["\n","file = open('/content/drive/My Drive/Python Notebook/SCS_CONVEX/output/BERT/bert_op.txt','w')\n","file.close()\n","\n","\n","if __name__ == '__main__':\n","  \n","  df_prediction = pd.DataFrame()\n","  df_accuracy =  pd.DataFrame()\n","  file = open('/content/drive/My Drive/Python Notebook/SCS_CONVEX/output/Search Tasks/BERT/bert_op.txt','w')\n","  \n","  for i in range(1,3):\n","\n","    df_train,df_test,df_Y_train,df_Y_test = load_files(i)\n","    y_train = df_Y_train['Search_acts'].to_list()\n","    y_test = df_Y_test['Search_acts'].to_list()\n","    X_train, X_test = generate_maskid(df_train,df_test)\n","    model = model_generate(y_train)\n","    training_acc, training_loss = model_train(X_train,y_train, model)\n","    predicted, predicted_prob = test_classification(X_test,y_test,y_train)\n","    #loss, categorical_accuracy = trained_model.evaluate(x=X_test, y=y_test, batch_size=32, verbose=1)\n","    test_acc, details, conf_mat = result_visualization(y_test, predicted, predicted_prob,y_train)\n","    \n","\n","    outputname = 'bert_'+ str(i)\n","    df_prediction[outputname] = predicted\n","    df_accuracy[i] = [test_acc]\n","    file.write(\"\\nIteration:\" + str(i) + \"\\nCategorical Accuracy:\" + str(test_acc) + \n","                    \"\\nConfusion Matrix:\\n\" + str(conf_mat) + \"\\n\\n\")\n","\n","\n","  df_prediction.to_csv('/content/drive/My Drive/Python Notebook/SCS_CONVEX/output/Search Tasks/BERT/bert_predictions.csv')    \n","  df_accuracy.to_csv('/content/drive/My Drive/Python Notebook/SCS_CONVEX/output/Search Tasks/BERT/bert_accuracy.csv')    \n","  file.close()\n","\n"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'vocab_layer_norm', 'activation_13', 'vocab_transform']\n","- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"functional_15\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_idx (InputLayer)          [(None, 150)]        0                                            \n","__________________________________________________________________________________________________\n","input_masks (InputLayer)        [(None, 150)]        0                                            \n","__________________________________________________________________________________________________\n","tf_distil_bert_model_7 (TFDisti ((None, 150, 768),)  66362880    input_idx[0][0]                  \n","                                                                 input_masks[0][0]                \n","__________________________________________________________________________________________________\n","global_average_pooling1d_7 (Glo (None, 768)          0           tf_distil_bert_model_7[0][0]     \n","__________________________________________________________________________________________________\n","dense_14 (Dense)                (None, 64)           49216       global_average_pooling1d_7[0][0] \n","__________________________________________________________________________________________________\n","dense_15 (Dense)                (None, 4)            260         dense_14[0][0]                   \n","==================================================================================================\n","Total params: 66,412,356\n","Trainable params: 49,476\n","Non-trainable params: 66,362,880\n","__________________________________________________________________________________________________\n","{0: 'SR1', 1: 'SR2', 2: 'SR3', 3: 'SR4'}\n","{'SR1': 0, 'SR2': 1, 'SR3': 2, 'SR4': 3}\n","Epoch 1/300\n","9/9 [==============================] - 3s 342ms/step - loss: 1.3026 - accuracy: 0.3451 - val_loss: 1.2454 - val_accuracy: 0.4180\n","Epoch 2/300\n","9/9 [==============================] - 2s 217ms/step - loss: 1.1947 - accuracy: 0.4296 - val_loss: 1.2515 - val_accuracy: 0.3852\n","Epoch 3/300\n","9/9 [==============================] - 2s 217ms/step - loss: 1.1452 - accuracy: 0.4648 - val_loss: 1.2542 - val_accuracy: 0.4262\n","Epoch 4/300\n","9/9 [==============================] - 2s 217ms/step - loss: 1.1265 - accuracy: 0.4507 - val_loss: 1.2634 - val_accuracy: 0.3361\n","Epoch 5/300\n","9/9 [==============================] - 2s 218ms/step - loss: 1.0998 - accuracy: 0.4965 - val_loss: 1.2780 - val_accuracy: 0.3770\n","Epoch 6/300\n","9/9 [==============================] - 2s 217ms/step - loss: 1.0666 - accuracy: 0.4859 - val_loss: 1.3058 - val_accuracy: 0.3033\n","Epoch 7/300\n","9/9 [==============================] - 2s 218ms/step - loss: 1.0382 - accuracy: 0.5176 - val_loss: 1.2918 - val_accuracy: 0.3607\n","Epoch 8/300\n","9/9 [==============================] - 2s 218ms/step - loss: 1.0214 - accuracy: 0.5035 - val_loss: 1.3116 - val_accuracy: 0.3033\n","Epoch 9/300\n","9/9 [==============================] - 2s 218ms/step - loss: 1.0049 - accuracy: 0.5493 - val_loss: 1.3310 - val_accuracy: 0.2787\n","Epoch 10/300\n","9/9 [==============================] - 2s 219ms/step - loss: 0.9824 - accuracy: 0.5423 - val_loss: 1.3075 - val_accuracy: 0.3689\n","Epoch 11/300\n","9/9 [==============================] - 2s 219ms/step - loss: 0.9808 - accuracy: 0.5493 - val_loss: 1.3431 - val_accuracy: 0.3197\n","Epoch 12/300\n","9/9 [==============================] - 2s 219ms/step - loss: 0.9663 - accuracy: 0.5387 - val_loss: 1.3546 - val_accuracy: 0.3115\n","Epoch 13/300\n","9/9 [==============================] - 2s 220ms/step - loss: 0.9673 - accuracy: 0.5739 - val_loss: 1.3700 - val_accuracy: 0.3033\n","Epoch 14/300\n","9/9 [==============================] - 2s 220ms/step - loss: 0.9453 - accuracy: 0.5634 - val_loss: 1.3615 - val_accuracy: 0.3033\n","Epoch 15/300\n","9/9 [==============================] - 2s 219ms/step - loss: 0.9518 - accuracy: 0.5563 - val_loss: 1.3460 - val_accuracy: 0.3115\n","Epoch 16/300\n","9/9 [==============================] - 2s 221ms/step - loss: 0.9244 - accuracy: 0.5915 - val_loss: 1.3947 - val_accuracy: 0.2623\n","Epoch 17/300\n","9/9 [==============================] - 2s 220ms/step - loss: 0.9122 - accuracy: 0.5704 - val_loss: 1.3847 - val_accuracy: 0.3197\n","Epoch 18/300\n","9/9 [==============================] - 2s 219ms/step - loss: 0.9068 - accuracy: 0.5528 - val_loss: 1.3963 - val_accuracy: 0.3115\n","Epoch 19/300\n","9/9 [==============================] - 2s 221ms/step - loss: 0.8863 - accuracy: 0.6021 - val_loss: 1.4185 - val_accuracy: 0.2623\n","Epoch 20/300\n","9/9 [==============================] - 2s 221ms/step - loss: 0.8747 - accuracy: 0.5915 - val_loss: 1.4133 - val_accuracy: 0.2705\n","Epoch 21/300\n","9/9 [==============================] - 2s 221ms/step - loss: 0.8673 - accuracy: 0.6162 - val_loss: 1.4383 - val_accuracy: 0.2705\n","Epoch 22/300\n","9/9 [==============================] - 2s 223ms/step - loss: 0.8716 - accuracy: 0.6127 - val_loss: 1.4176 - val_accuracy: 0.3115\n","Epoch 23/300\n","9/9 [==============================] - 2s 222ms/step - loss: 0.8662 - accuracy: 0.5845 - val_loss: 1.4340 - val_accuracy: 0.3033\n","Epoch 24/300\n","9/9 [==============================] - 2s 224ms/step - loss: 0.8551 - accuracy: 0.6056 - val_loss: 1.4500 - val_accuracy: 0.3197\n","Epoch 25/300\n","9/9 [==============================] - 2s 223ms/step - loss: 0.8650 - accuracy: 0.5915 - val_loss: 1.4505 - val_accuracy: 0.3033\n","Epoch 26/300\n","9/9 [==============================] - 2s 224ms/step - loss: 0.8569 - accuracy: 0.5704 - val_loss: 1.4508 - val_accuracy: 0.2623\n","Epoch 27/300\n","9/9 [==============================] - 2s 225ms/step - loss: 0.8334 - accuracy: 0.5880 - val_loss: 1.4694 - val_accuracy: 0.3033\n","Epoch 28/300\n","9/9 [==============================] - 2s 224ms/step - loss: 0.8214 - accuracy: 0.6197 - val_loss: 1.4729 - val_accuracy: 0.2623\n","Epoch 29/300\n","9/9 [==============================] - 2s 225ms/step - loss: 0.8176 - accuracy: 0.6021 - val_loss: 1.4942 - val_accuracy: 0.2705\n","Epoch 30/300\n","9/9 [==============================] - 2s 227ms/step - loss: 0.8076 - accuracy: 0.5951 - val_loss: 1.5077 - val_accuracy: 0.2705\n","Epoch 31/300\n","9/9 [==============================] - 2s 226ms/step - loss: 0.8120 - accuracy: 0.6232 - val_loss: 1.4843 - val_accuracy: 0.2869\n","Epoch 32/300\n","9/9 [==============================] - 2s 227ms/step - loss: 0.8093 - accuracy: 0.6092 - val_loss: 1.5315 - val_accuracy: 0.2705\n","Epoch 33/300\n","9/9 [==============================] - 2s 228ms/step - loss: 0.7891 - accuracy: 0.6373 - val_loss: 1.5223 - val_accuracy: 0.2623\n","Epoch 34/300\n","9/9 [==============================] - 2s 227ms/step - loss: 0.8005 - accuracy: 0.6373 - val_loss: 1.5013 - val_accuracy: 0.2705\n","Epoch 35/300\n","9/9 [==============================] - 2s 227ms/step - loss: 0.7888 - accuracy: 0.6303 - val_loss: 1.5345 - val_accuracy: 0.2787\n","Epoch 36/300\n","9/9 [==============================] - 2s 228ms/step - loss: 0.7908 - accuracy: 0.6620 - val_loss: 1.5407 - val_accuracy: 0.3115\n","Epoch 37/300\n","9/9 [==============================] - 2s 227ms/step - loss: 0.7648 - accuracy: 0.6690 - val_loss: 1.5464 - val_accuracy: 0.3115\n","Epoch 38/300\n","9/9 [==============================] - 2s 228ms/step - loss: 0.7559 - accuracy: 0.6761 - val_loss: 1.5840 - val_accuracy: 0.3033\n","Epoch 39/300\n","9/9 [==============================] - 2s 228ms/step - loss: 0.7442 - accuracy: 0.6585 - val_loss: 1.5564 - val_accuracy: 0.3197\n","Epoch 40/300\n","9/9 [==============================] - 2s 229ms/step - loss: 0.7820 - accuracy: 0.5915 - val_loss: 1.5931 - val_accuracy: 0.3033\n","Epoch 41/300\n","9/9 [==============================] - 2s 229ms/step - loss: 0.7620 - accuracy: 0.6338 - val_loss: 1.5554 - val_accuracy: 0.3197\n","Epoch 42/300\n","9/9 [==============================] - 2s 228ms/step - loss: 0.7499 - accuracy: 0.6479 - val_loss: 1.5987 - val_accuracy: 0.3197\n","Epoch 43/300\n","9/9 [==============================] - 2s 227ms/step - loss: 0.7290 - accuracy: 0.6549 - val_loss: 1.5989 - val_accuracy: 0.3279\n","Epoch 44/300\n","9/9 [==============================] - 2s 230ms/step - loss: 0.7619 - accuracy: 0.6549 - val_loss: 1.6003 - val_accuracy: 0.2951\n","Epoch 45/300\n","9/9 [==============================] - 2s 230ms/step - loss: 0.7489 - accuracy: 0.6373 - val_loss: 1.6093 - val_accuracy: 0.2705\n","Epoch 46/300\n","9/9 [==============================] - 2s 228ms/step - loss: 0.7502 - accuracy: 0.6479 - val_loss: 1.6149 - val_accuracy: 0.2951\n","Epoch 47/300\n","9/9 [==============================] - 2s 229ms/step - loss: 0.7515 - accuracy: 0.6303 - val_loss: 1.6114 - val_accuracy: 0.3033\n","Epoch 48/300\n","9/9 [==============================] - 2s 230ms/step - loss: 0.7227 - accuracy: 0.6901 - val_loss: 1.6304 - val_accuracy: 0.3033\n","Epoch 49/300\n","9/9 [==============================] - 2s 230ms/step - loss: 0.7452 - accuracy: 0.6408 - val_loss: 1.6508 - val_accuracy: 0.3033\n","Epoch 50/300\n","9/9 [==============================] - 2s 229ms/step - loss: 0.7330 - accuracy: 0.6761 - val_loss: 1.6267 - val_accuracy: 0.2705\n","Epoch 51/300\n","9/9 [==============================] - 2s 230ms/step - loss: 0.7338 - accuracy: 0.6479 - val_loss: 1.7030 - val_accuracy: 0.2787\n","Epoch 52/300\n","9/9 [==============================] - 2s 230ms/step - loss: 0.7386 - accuracy: 0.6127 - val_loss: 1.6502 - val_accuracy: 0.2951\n","Epoch 53/300\n","9/9 [==============================] - 2s 229ms/step - loss: 0.7130 - accuracy: 0.6444 - val_loss: 1.6581 - val_accuracy: 0.2787\n","Epoch 54/300\n","9/9 [==============================] - 2s 227ms/step - loss: 0.7070 - accuracy: 0.6514 - val_loss: 1.7056 - val_accuracy: 0.2787\n","Epoch 55/300\n","9/9 [==============================] - 2s 228ms/step - loss: 0.6977 - accuracy: 0.6937 - val_loss: 1.6798 - val_accuracy: 0.3279\n","Epoch 56/300\n","9/9 [==============================] - 2s 226ms/step - loss: 0.6944 - accuracy: 0.6866 - val_loss: 1.6635 - val_accuracy: 0.3361\n","Epoch 57/300\n","9/9 [==============================] - 2s 228ms/step - loss: 0.7278 - accuracy: 0.6549 - val_loss: 1.7263 - val_accuracy: 0.3197\n","Epoch 58/300\n","9/9 [==============================] - 2s 227ms/step - loss: 0.7032 - accuracy: 0.6338 - val_loss: 1.6989 - val_accuracy: 0.2869\n","Epoch 59/300\n","9/9 [==============================] - 2s 229ms/step - loss: 0.7065 - accuracy: 0.6514 - val_loss: 1.7127 - val_accuracy: 0.3033\n","Epoch 60/300\n","9/9 [==============================] - 2s 229ms/step - loss: 0.7206 - accuracy: 0.6444 - val_loss: 1.7338 - val_accuracy: 0.3279\n","Epoch 61/300\n","9/9 [==============================] - 2s 229ms/step - loss: 0.6922 - accuracy: 0.6514 - val_loss: 1.6826 - val_accuracy: 0.2705\n","Epoch 62/300\n","9/9 [==============================] - 2s 230ms/step - loss: 0.6843 - accuracy: 0.6620 - val_loss: 1.7645 - val_accuracy: 0.3361\n","Epoch 63/300\n","9/9 [==============================] - 2s 229ms/step - loss: 0.6806 - accuracy: 0.6761 - val_loss: 1.7486 - val_accuracy: 0.2787\n","Epoch 64/300\n","9/9 [==============================] - 2s 229ms/step - loss: 0.7106 - accuracy: 0.6338 - val_loss: 1.7113 - val_accuracy: 0.2787\n","Epoch 65/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6899 - accuracy: 0.6549 - val_loss: 1.7765 - val_accuracy: 0.3033\n","Epoch 66/300\n","9/9 [==============================] - 2s 231ms/step - loss: 0.6882 - accuracy: 0.6620 - val_loss: 1.7756 - val_accuracy: 0.2869\n","Epoch 67/300\n","9/9 [==============================] - 2s 232ms/step - loss: 0.6764 - accuracy: 0.6761 - val_loss: 1.7333 - val_accuracy: 0.3115\n","Epoch 68/300\n","9/9 [==============================] - 2s 232ms/step - loss: 0.6703 - accuracy: 0.6655 - val_loss: 1.7661 - val_accuracy: 0.2951\n","Epoch 69/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6585 - accuracy: 0.6620 - val_loss: 1.8153 - val_accuracy: 0.2951\n","Epoch 70/300\n","9/9 [==============================] - 2s 231ms/step - loss: 0.6625 - accuracy: 0.6937 - val_loss: 1.7517 - val_accuracy: 0.3115\n","Epoch 71/300\n","9/9 [==============================] - 2s 231ms/step - loss: 0.6957 - accuracy: 0.6444 - val_loss: 1.8201 - val_accuracy: 0.3197\n","Epoch 72/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6716 - accuracy: 0.6761 - val_loss: 1.7984 - val_accuracy: 0.2951\n","Epoch 73/300\n","9/9 [==============================] - 2s 232ms/step - loss: 0.6450 - accuracy: 0.6866 - val_loss: 1.7971 - val_accuracy: 0.2869\n","Epoch 74/300\n","9/9 [==============================] - 2s 232ms/step - loss: 0.6844 - accuracy: 0.6232 - val_loss: 1.8024 - val_accuracy: 0.2787\n","Epoch 75/300\n","9/9 [==============================] - 2s 232ms/step - loss: 0.6433 - accuracy: 0.6901 - val_loss: 1.8377 - val_accuracy: 0.2869\n","Epoch 76/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6603 - accuracy: 0.6655 - val_loss: 1.8084 - val_accuracy: 0.3197\n","Epoch 77/300\n","9/9 [==============================] - 2s 232ms/step - loss: 0.6331 - accuracy: 0.7113 - val_loss: 1.8789 - val_accuracy: 0.2869\n","Epoch 78/300\n","9/9 [==============================] - 2s 232ms/step - loss: 0.6738 - accuracy: 0.6479 - val_loss: 1.8683 - val_accuracy: 0.3115\n","Epoch 79/300\n","9/9 [==============================] - 2s 232ms/step - loss: 0.6446 - accuracy: 0.7077 - val_loss: 1.8088 - val_accuracy: 0.2951\n","Epoch 80/300\n","9/9 [==============================] - 2s 232ms/step - loss: 0.6620 - accuracy: 0.6655 - val_loss: 1.8970 - val_accuracy: 0.3279\n","Epoch 81/300\n","9/9 [==============================] - 2s 232ms/step - loss: 0.6628 - accuracy: 0.6585 - val_loss: 1.8666 - val_accuracy: 0.3115\n","Epoch 82/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6398 - accuracy: 0.6796 - val_loss: 1.8813 - val_accuracy: 0.3197\n","Epoch 83/300\n","9/9 [==============================] - 2s 232ms/step - loss: 0.6554 - accuracy: 0.6866 - val_loss: 1.8332 - val_accuracy: 0.3115\n","Epoch 84/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6474 - accuracy: 0.6831 - val_loss: 1.8643 - val_accuracy: 0.2705\n","Epoch 85/300\n","9/9 [==============================] - 2s 232ms/step - loss: 0.6366 - accuracy: 0.6655 - val_loss: 1.9019 - val_accuracy: 0.2869\n","Epoch 86/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6189 - accuracy: 0.7077 - val_loss: 1.8928 - val_accuracy: 0.3197\n","Epoch 87/300\n","9/9 [==============================] - 2s 231ms/step - loss: 0.6294 - accuracy: 0.6901 - val_loss: 1.8910 - val_accuracy: 0.2869\n","Epoch 88/300\n","9/9 [==============================] - 2s 231ms/step - loss: 0.6392 - accuracy: 0.6831 - val_loss: 1.8775 - val_accuracy: 0.2869\n","Epoch 89/300\n","9/9 [==============================] - 2s 232ms/step - loss: 0.6351 - accuracy: 0.6866 - val_loss: 1.9206 - val_accuracy: 0.3279\n","Epoch 90/300\n","9/9 [==============================] - 2s 232ms/step - loss: 0.6425 - accuracy: 0.6901 - val_loss: 1.9035 - val_accuracy: 0.3115\n","Epoch 91/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6486 - accuracy: 0.6937 - val_loss: 1.9147 - val_accuracy: 0.3279\n","Epoch 92/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6241 - accuracy: 0.6901 - val_loss: 1.9374 - val_accuracy: 0.3361\n","Epoch 93/300\n","9/9 [==============================] - 2s 232ms/step - loss: 0.6366 - accuracy: 0.6866 - val_loss: 1.8914 - val_accuracy: 0.3197\n","Epoch 94/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6584 - accuracy: 0.6690 - val_loss: 1.9574 - val_accuracy: 0.3279\n","Epoch 95/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6287 - accuracy: 0.6620 - val_loss: 1.9293 - val_accuracy: 0.3279\n","Epoch 96/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6482 - accuracy: 0.6761 - val_loss: 1.9551 - val_accuracy: 0.2623\n","Epoch 97/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6119 - accuracy: 0.6761 - val_loss: 1.8955 - val_accuracy: 0.3197\n","Epoch 98/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6104 - accuracy: 0.7007 - val_loss: 1.9361 - val_accuracy: 0.3361\n","Epoch 99/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6563 - accuracy: 0.6655 - val_loss: 2.0149 - val_accuracy: 0.3279\n","Epoch 100/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6241 - accuracy: 0.6690 - val_loss: 1.9277 - val_accuracy: 0.2705\n","Epoch 101/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6100 - accuracy: 0.6972 - val_loss: 1.9859 - val_accuracy: 0.2869\n","Epoch 102/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6106 - accuracy: 0.6901 - val_loss: 1.9772 - val_accuracy: 0.3197\n","Epoch 103/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6330 - accuracy: 0.6831 - val_loss: 1.9666 - val_accuracy: 0.3279\n","Epoch 104/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6349 - accuracy: 0.6831 - val_loss: 2.0207 - val_accuracy: 0.2705\n","Epoch 105/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5989 - accuracy: 0.7042 - val_loss: 1.9492 - val_accuracy: 0.3279\n","Epoch 106/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6173 - accuracy: 0.6655 - val_loss: 2.0065 - val_accuracy: 0.2787\n","Epoch 107/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6140 - accuracy: 0.7042 - val_loss: 1.9751 - val_accuracy: 0.3115\n","Epoch 108/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6439 - accuracy: 0.6866 - val_loss: 2.0201 - val_accuracy: 0.3279\n","Epoch 109/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6455 - accuracy: 0.6690 - val_loss: 1.9864 - val_accuracy: 0.2787\n","Epoch 110/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6082 - accuracy: 0.6761 - val_loss: 1.9917 - val_accuracy: 0.3361\n","Epoch 111/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6106 - accuracy: 0.7077 - val_loss: 2.0166 - val_accuracy: 0.2951\n","Epoch 112/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6538 - accuracy: 0.6866 - val_loss: 2.0006 - val_accuracy: 0.3197\n","Epoch 113/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6047 - accuracy: 0.7007 - val_loss: 2.0338 - val_accuracy: 0.2869\n","Epoch 114/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5891 - accuracy: 0.7042 - val_loss: 1.9896 - val_accuracy: 0.3197\n","Epoch 115/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5959 - accuracy: 0.6690 - val_loss: 2.0596 - val_accuracy: 0.3279\n","Epoch 116/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6206 - accuracy: 0.6761 - val_loss: 2.0121 - val_accuracy: 0.2869\n","Epoch 117/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6183 - accuracy: 0.6549 - val_loss: 2.0709 - val_accuracy: 0.2787\n","Epoch 118/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6321 - accuracy: 0.6690 - val_loss: 2.0003 - val_accuracy: 0.2869\n","Epoch 119/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5816 - accuracy: 0.7218 - val_loss: 2.0996 - val_accuracy: 0.2951\n","Epoch 120/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6527 - accuracy: 0.6690 - val_loss: 2.0175 - val_accuracy: 0.3197\n","Epoch 121/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6138 - accuracy: 0.7007 - val_loss: 2.0827 - val_accuracy: 0.2787\n","Epoch 122/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6084 - accuracy: 0.6761 - val_loss: 2.1016 - val_accuracy: 0.3279\n","Epoch 123/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6071 - accuracy: 0.6761 - val_loss: 2.0487 - val_accuracy: 0.2869\n","Epoch 124/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6325 - accuracy: 0.6514 - val_loss: 2.0601 - val_accuracy: 0.2951\n","Epoch 125/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6074 - accuracy: 0.6831 - val_loss: 2.0774 - val_accuracy: 0.2705\n","Epoch 126/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6132 - accuracy: 0.6690 - val_loss: 2.0551 - val_accuracy: 0.3279\n","Epoch 127/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6205 - accuracy: 0.6620 - val_loss: 2.1185 - val_accuracy: 0.2869\n","Epoch 128/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6076 - accuracy: 0.6620 - val_loss: 2.0742 - val_accuracy: 0.2787\n","Epoch 129/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6077 - accuracy: 0.6655 - val_loss: 2.1056 - val_accuracy: 0.3279\n","Epoch 130/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5912 - accuracy: 0.7218 - val_loss: 2.0823 - val_accuracy: 0.2787\n","Epoch 131/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6115 - accuracy: 0.6972 - val_loss: 2.1549 - val_accuracy: 0.2869\n","Epoch 132/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6070 - accuracy: 0.6866 - val_loss: 2.1090 - val_accuracy: 0.2787\n","Epoch 133/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6011 - accuracy: 0.6831 - val_loss: 2.1344 - val_accuracy: 0.2705\n","Epoch 134/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5962 - accuracy: 0.6937 - val_loss: 2.1192 - val_accuracy: 0.2787\n","Epoch 135/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6057 - accuracy: 0.6620 - val_loss: 2.1106 - val_accuracy: 0.2951\n","Epoch 136/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6233 - accuracy: 0.6937 - val_loss: 2.0481 - val_accuracy: 0.3115\n","Epoch 137/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5881 - accuracy: 0.6866 - val_loss: 2.1522 - val_accuracy: 0.2869\n","Epoch 138/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5831 - accuracy: 0.6831 - val_loss: 2.0441 - val_accuracy: 0.3361\n","Epoch 139/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5920 - accuracy: 0.6972 - val_loss: 2.0880 - val_accuracy: 0.3115\n","Epoch 140/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6246 - accuracy: 0.6761 - val_loss: 2.1337 - val_accuracy: 0.3279\n","Epoch 141/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6010 - accuracy: 0.6655 - val_loss: 2.1332 - val_accuracy: 0.2951\n","Epoch 142/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6044 - accuracy: 0.6866 - val_loss: 2.0329 - val_accuracy: 0.3361\n","Epoch 143/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5944 - accuracy: 0.6866 - val_loss: 2.1492 - val_accuracy: 0.3033\n","Epoch 144/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5788 - accuracy: 0.6901 - val_loss: 2.0948 - val_accuracy: 0.2951\n","Epoch 145/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.5957 - accuracy: 0.6725 - val_loss: 2.1403 - val_accuracy: 0.3197\n","Epoch 146/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6074 - accuracy: 0.6620 - val_loss: 2.0969 - val_accuracy: 0.3525\n","Epoch 147/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5758 - accuracy: 0.7077 - val_loss: 2.1415 - val_accuracy: 0.2869\n","Epoch 148/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5949 - accuracy: 0.6761 - val_loss: 2.1409 - val_accuracy: 0.2787\n","Epoch 149/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5925 - accuracy: 0.6725 - val_loss: 2.1195 - val_accuracy: 0.3443\n","Epoch 150/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5696 - accuracy: 0.6972 - val_loss: 2.1665 - val_accuracy: 0.2869\n","Epoch 151/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5922 - accuracy: 0.7007 - val_loss: 2.1221 - val_accuracy: 0.3033\n","Epoch 152/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5764 - accuracy: 0.6761 - val_loss: 2.1891 - val_accuracy: 0.2869\n","Epoch 153/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5758 - accuracy: 0.7042 - val_loss: 2.2070 - val_accuracy: 0.2869\n","Epoch 154/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5764 - accuracy: 0.6972 - val_loss: 2.1894 - val_accuracy: 0.3033\n","Epoch 155/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5805 - accuracy: 0.7007 - val_loss: 2.1970 - val_accuracy: 0.3361\n","Epoch 156/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5706 - accuracy: 0.6831 - val_loss: 2.1605 - val_accuracy: 0.3279\n","Epoch 157/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5701 - accuracy: 0.7113 - val_loss: 2.1896 - val_accuracy: 0.3197\n","Epoch 158/300\n","9/9 [==============================] - 2s 239ms/step - loss: 0.6072 - accuracy: 0.6831 - val_loss: 2.2161 - val_accuracy: 0.3361\n","Epoch 159/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5623 - accuracy: 0.7042 - val_loss: 2.2154 - val_accuracy: 0.3361\n","Epoch 160/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.5707 - accuracy: 0.6972 - val_loss: 2.2869 - val_accuracy: 0.2623\n","Epoch 161/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.6059 - accuracy: 0.6373 - val_loss: 2.2224 - val_accuracy: 0.3525\n","Epoch 162/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.6025 - accuracy: 0.6690 - val_loss: 2.1998 - val_accuracy: 0.3443\n","Epoch 163/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.5600 - accuracy: 0.6831 - val_loss: 2.1755 - val_accuracy: 0.3443\n","Epoch 164/300\n","9/9 [==============================] - 2s 239ms/step - loss: 0.5921 - accuracy: 0.6937 - val_loss: 2.2397 - val_accuracy: 0.3361\n","Epoch 165/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6096 - accuracy: 0.6655 - val_loss: 2.2185 - val_accuracy: 0.3197\n","Epoch 166/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5942 - accuracy: 0.6796 - val_loss: 2.3055 - val_accuracy: 0.3115\n","Epoch 167/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5933 - accuracy: 0.6725 - val_loss: 2.1626 - val_accuracy: 0.3361\n","Epoch 168/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5702 - accuracy: 0.7007 - val_loss: 2.2123 - val_accuracy: 0.3361\n","Epoch 169/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5745 - accuracy: 0.6901 - val_loss: 2.2250 - val_accuracy: 0.3033\n","Epoch 170/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5974 - accuracy: 0.6725 - val_loss: 2.1705 - val_accuracy: 0.3361\n","Epoch 171/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5910 - accuracy: 0.6796 - val_loss: 2.2132 - val_accuracy: 0.3443\n","Epoch 172/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5754 - accuracy: 0.6796 - val_loss: 2.2599 - val_accuracy: 0.2869\n","Epoch 173/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5824 - accuracy: 0.6831 - val_loss: 2.2188 - val_accuracy: 0.3525\n","Epoch 174/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5934 - accuracy: 0.6373 - val_loss: 2.2394 - val_accuracy: 0.3525\n","Epoch 175/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5858 - accuracy: 0.7077 - val_loss: 2.2328 - val_accuracy: 0.3361\n","Epoch 176/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5944 - accuracy: 0.7077 - val_loss: 2.2263 - val_accuracy: 0.3279\n","Epoch 177/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5552 - accuracy: 0.6937 - val_loss: 2.2367 - val_accuracy: 0.3279\n","Epoch 178/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5823 - accuracy: 0.6866 - val_loss: 2.2487 - val_accuracy: 0.3443\n","Epoch 179/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5752 - accuracy: 0.6901 - val_loss: 2.2851 - val_accuracy: 0.3115\n","Epoch 180/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5885 - accuracy: 0.6831 - val_loss: 2.2692 - val_accuracy: 0.2705\n","Epoch 181/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5977 - accuracy: 0.6937 - val_loss: 2.2553 - val_accuracy: 0.2705\n","Epoch 182/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5690 - accuracy: 0.6655 - val_loss: 2.2836 - val_accuracy: 0.2787\n","Epoch 183/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.5760 - accuracy: 0.6866 - val_loss: 2.2643 - val_accuracy: 0.3197\n","Epoch 184/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5638 - accuracy: 0.6937 - val_loss: 2.2679 - val_accuracy: 0.3033\n","Epoch 185/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5709 - accuracy: 0.6796 - val_loss: 2.2975 - val_accuracy: 0.3115\n","Epoch 186/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5722 - accuracy: 0.6866 - val_loss: 2.2519 - val_accuracy: 0.3197\n","Epoch 187/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.5694 - accuracy: 0.7007 - val_loss: 2.2737 - val_accuracy: 0.3361\n","Epoch 188/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5989 - accuracy: 0.6620 - val_loss: 2.3182 - val_accuracy: 0.3197\n","Epoch 189/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5720 - accuracy: 0.7077 - val_loss: 2.2712 - val_accuracy: 0.3361\n","Epoch 190/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6215 - accuracy: 0.6620 - val_loss: 2.2812 - val_accuracy: 0.3279\n","Epoch 191/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5695 - accuracy: 0.6796 - val_loss: 2.2599 - val_accuracy: 0.2787\n","Epoch 192/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5592 - accuracy: 0.6972 - val_loss: 2.1989 - val_accuracy: 0.3279\n","Epoch 193/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5806 - accuracy: 0.6831 - val_loss: 2.2603 - val_accuracy: 0.2869\n","Epoch 194/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5887 - accuracy: 0.6972 - val_loss: 2.2302 - val_accuracy: 0.3279\n","Epoch 195/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5804 - accuracy: 0.7007 - val_loss: 2.2897 - val_accuracy: 0.3197\n","Epoch 196/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5960 - accuracy: 0.6761 - val_loss: 2.2429 - val_accuracy: 0.2869\n","Epoch 197/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5948 - accuracy: 0.6761 - val_loss: 2.2535 - val_accuracy: 0.2869\n","Epoch 198/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5926 - accuracy: 0.6655 - val_loss: 2.2755 - val_accuracy: 0.2869\n","Epoch 199/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5732 - accuracy: 0.6549 - val_loss: 2.2247 - val_accuracy: 0.2869\n","Epoch 200/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.5905 - accuracy: 0.6690 - val_loss: 2.3031 - val_accuracy: 0.2787\n","Epoch 201/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5752 - accuracy: 0.6901 - val_loss: 2.2306 - val_accuracy: 0.2869\n","Epoch 202/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5405 - accuracy: 0.7218 - val_loss: 2.2826 - val_accuracy: 0.2951\n","Epoch 203/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5817 - accuracy: 0.7007 - val_loss: 2.3336 - val_accuracy: 0.3033\n","Epoch 204/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5613 - accuracy: 0.6901 - val_loss: 2.2305 - val_accuracy: 0.2951\n","Epoch 205/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5616 - accuracy: 0.6972 - val_loss: 2.2952 - val_accuracy: 0.3197\n","Epoch 206/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5741 - accuracy: 0.7077 - val_loss: 2.3318 - val_accuracy: 0.2869\n","Epoch 207/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5799 - accuracy: 0.7289 - val_loss: 2.2487 - val_accuracy: 0.3197\n","Epoch 208/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5674 - accuracy: 0.6761 - val_loss: 2.3001 - val_accuracy: 0.2869\n","Epoch 209/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5695 - accuracy: 0.6937 - val_loss: 2.3521 - val_accuracy: 0.2869\n","Epoch 210/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5884 - accuracy: 0.6620 - val_loss: 2.2860 - val_accuracy: 0.2705\n","Epoch 211/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6027 - accuracy: 0.6444 - val_loss: 2.2461 - val_accuracy: 0.3361\n","Epoch 212/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5424 - accuracy: 0.7183 - val_loss: 2.3292 - val_accuracy: 0.3033\n","Epoch 213/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5720 - accuracy: 0.6937 - val_loss: 2.2291 - val_accuracy: 0.2787\n","Epoch 214/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5654 - accuracy: 0.6972 - val_loss: 2.3270 - val_accuracy: 0.2951\n","Epoch 215/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5846 - accuracy: 0.6338 - val_loss: 2.3219 - val_accuracy: 0.3279\n","Epoch 216/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5575 - accuracy: 0.6972 - val_loss: 2.2823 - val_accuracy: 0.3279\n","Epoch 217/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5710 - accuracy: 0.6831 - val_loss: 2.3125 - val_accuracy: 0.3279\n","Epoch 218/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5478 - accuracy: 0.6866 - val_loss: 2.2898 - val_accuracy: 0.2869\n","Epoch 219/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5892 - accuracy: 0.6655 - val_loss: 2.3321 - val_accuracy: 0.2787\n","Epoch 220/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.5671 - accuracy: 0.6937 - val_loss: 2.3236 - val_accuracy: 0.2951\n","Epoch 221/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5752 - accuracy: 0.6690 - val_loss: 2.3269 - val_accuracy: 0.3115\n","Epoch 222/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5756 - accuracy: 0.6831 - val_loss: 2.3054 - val_accuracy: 0.2951\n","Epoch 223/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5646 - accuracy: 0.6831 - val_loss: 2.2770 - val_accuracy: 0.2869\n","Epoch 224/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5892 - accuracy: 0.6549 - val_loss: 2.3400 - val_accuracy: 0.3033\n","Epoch 225/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.5510 - accuracy: 0.6690 - val_loss: 2.3261 - val_accuracy: 0.3361\n","Epoch 226/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5745 - accuracy: 0.6549 - val_loss: 2.2688 - val_accuracy: 0.3115\n","Epoch 227/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.5593 - accuracy: 0.6761 - val_loss: 2.3750 - val_accuracy: 0.2869\n","Epoch 228/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5767 - accuracy: 0.6690 - val_loss: 2.2824 - val_accuracy: 0.3197\n","Epoch 229/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5608 - accuracy: 0.6831 - val_loss: 2.2741 - val_accuracy: 0.2951\n","Epoch 230/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5608 - accuracy: 0.7077 - val_loss: 2.3034 - val_accuracy: 0.3443\n","Epoch 231/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5709 - accuracy: 0.6725 - val_loss: 2.3141 - val_accuracy: 0.3033\n","Epoch 232/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5438 - accuracy: 0.6937 - val_loss: 2.2648 - val_accuracy: 0.2951\n","Epoch 233/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.5775 - accuracy: 0.7077 - val_loss: 2.2640 - val_accuracy: 0.2869\n","Epoch 234/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5614 - accuracy: 0.7183 - val_loss: 2.3498 - val_accuracy: 0.3033\n","Epoch 235/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5620 - accuracy: 0.7042 - val_loss: 2.2621 - val_accuracy: 0.3197\n","Epoch 236/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5657 - accuracy: 0.7042 - val_loss: 2.3831 - val_accuracy: 0.2705\n","Epoch 237/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5683 - accuracy: 0.6972 - val_loss: 2.3736 - val_accuracy: 0.3033\n","Epoch 238/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5627 - accuracy: 0.6901 - val_loss: 2.3820 - val_accuracy: 0.2869\n","Epoch 239/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5673 - accuracy: 0.6937 - val_loss: 2.3157 - val_accuracy: 0.2869\n","Epoch 240/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5577 - accuracy: 0.6620 - val_loss: 2.3796 - val_accuracy: 0.2951\n","Epoch 241/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5558 - accuracy: 0.7148 - val_loss: 2.3771 - val_accuracy: 0.2869\n","Epoch 242/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5660 - accuracy: 0.7077 - val_loss: 2.4042 - val_accuracy: 0.2951\n","Epoch 243/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5785 - accuracy: 0.6725 - val_loss: 2.3375 - val_accuracy: 0.2869\n","Epoch 244/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5699 - accuracy: 0.6549 - val_loss: 2.4070 - val_accuracy: 0.2869\n","Epoch 245/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5560 - accuracy: 0.6796 - val_loss: 2.3664 - val_accuracy: 0.2951\n","Epoch 246/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5653 - accuracy: 0.6761 - val_loss: 2.3673 - val_accuracy: 0.2869\n","Epoch 247/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5859 - accuracy: 0.6620 - val_loss: 2.3281 - val_accuracy: 0.2951\n","Epoch 248/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5746 - accuracy: 0.6585 - val_loss: 2.3201 - val_accuracy: 0.3443\n","Epoch 249/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5609 - accuracy: 0.6972 - val_loss: 2.3730 - val_accuracy: 0.3115\n","Epoch 250/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5548 - accuracy: 0.7148 - val_loss: 2.3465 - val_accuracy: 0.3197\n","Epoch 251/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5802 - accuracy: 0.7007 - val_loss: 2.3301 - val_accuracy: 0.3361\n","Epoch 252/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5610 - accuracy: 0.6761 - val_loss: 2.3207 - val_accuracy: 0.3443\n","Epoch 253/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5554 - accuracy: 0.7289 - val_loss: 2.4183 - val_accuracy: 0.3443\n","Epoch 254/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.5980 - accuracy: 0.6514 - val_loss: 2.3514 - val_accuracy: 0.3197\n","Epoch 255/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5548 - accuracy: 0.7183 - val_loss: 2.3717 - val_accuracy: 0.2951\n","Epoch 256/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5443 - accuracy: 0.7113 - val_loss: 2.3859 - val_accuracy: 0.3033\n","Epoch 257/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5523 - accuracy: 0.6901 - val_loss: 2.3698 - val_accuracy: 0.3115\n","Epoch 258/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5917 - accuracy: 0.6831 - val_loss: 2.3822 - val_accuracy: 0.3279\n","Epoch 259/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.5864 - accuracy: 0.6901 - val_loss: 2.3494 - val_accuracy: 0.3033\n","Epoch 260/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5591 - accuracy: 0.6972 - val_loss: 2.2964 - val_accuracy: 0.3525\n","Epoch 261/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.5782 - accuracy: 0.6514 - val_loss: 2.4103 - val_accuracy: 0.3361\n","Epoch 262/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5871 - accuracy: 0.6585 - val_loss: 2.2961 - val_accuracy: 0.3525\n","Epoch 263/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5533 - accuracy: 0.7148 - val_loss: 2.2643 - val_accuracy: 0.3115\n","Epoch 264/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5479 - accuracy: 0.7077 - val_loss: 2.3286 - val_accuracy: 0.2951\n","Epoch 265/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5641 - accuracy: 0.6866 - val_loss: 2.4014 - val_accuracy: 0.3033\n","Epoch 266/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5800 - accuracy: 0.6761 - val_loss: 2.3589 - val_accuracy: 0.3279\n","Epoch 267/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5801 - accuracy: 0.6761 - val_loss: 2.3602 - val_accuracy: 0.3279\n","Epoch 268/300\n","9/9 [==============================] - 2s 239ms/step - loss: 0.5552 - accuracy: 0.7007 - val_loss: 2.3707 - val_accuracy: 0.2787\n","Epoch 269/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.5862 - accuracy: 0.6585 - val_loss: 2.4083 - val_accuracy: 0.2869\n","Epoch 270/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.5769 - accuracy: 0.6796 - val_loss: 2.3447 - val_accuracy: 0.3033\n","Epoch 271/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5847 - accuracy: 0.6831 - val_loss: 2.4008 - val_accuracy: 0.3279\n","Epoch 272/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.5387 - accuracy: 0.6972 - val_loss: 2.4126 - val_accuracy: 0.2951\n","Epoch 273/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5655 - accuracy: 0.6585 - val_loss: 2.3595 - val_accuracy: 0.3361\n","Epoch 274/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5533 - accuracy: 0.7113 - val_loss: 2.4175 - val_accuracy: 0.3115\n","Epoch 275/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5851 - accuracy: 0.6690 - val_loss: 2.3820 - val_accuracy: 0.3033\n","Epoch 276/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5477 - accuracy: 0.7430 - val_loss: 2.3660 - val_accuracy: 0.3443\n","Epoch 277/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5587 - accuracy: 0.6725 - val_loss: 2.4419 - val_accuracy: 0.3197\n","Epoch 278/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5705 - accuracy: 0.6585 - val_loss: 2.3607 - val_accuracy: 0.3361\n","Epoch 279/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5588 - accuracy: 0.6479 - val_loss: 2.3282 - val_accuracy: 0.3279\n","Epoch 280/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5556 - accuracy: 0.6937 - val_loss: 2.4076 - val_accuracy: 0.3279\n","Epoch 281/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5472 - accuracy: 0.6972 - val_loss: 2.3773 - val_accuracy: 0.2951\n","Epoch 282/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5451 - accuracy: 0.7007 - val_loss: 2.3900 - val_accuracy: 0.3279\n","Epoch 283/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5621 - accuracy: 0.7359 - val_loss: 2.4480 - val_accuracy: 0.3033\n","Epoch 284/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5464 - accuracy: 0.6901 - val_loss: 2.3658 - val_accuracy: 0.3443\n","Epoch 285/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5460 - accuracy: 0.6655 - val_loss: 2.3680 - val_accuracy: 0.3279\n","Epoch 286/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5587 - accuracy: 0.7077 - val_loss: 2.3999 - val_accuracy: 0.2787\n","Epoch 287/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5695 - accuracy: 0.6831 - val_loss: 2.4422 - val_accuracy: 0.2951\n","Epoch 288/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5732 - accuracy: 0.6831 - val_loss: 2.3987 - val_accuracy: 0.2869\n","Epoch 289/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5529 - accuracy: 0.6761 - val_loss: 2.4077 - val_accuracy: 0.2951\n","Epoch 290/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5424 - accuracy: 0.7289 - val_loss: 2.4380 - val_accuracy: 0.2787\n","Epoch 291/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.5556 - accuracy: 0.7077 - val_loss: 2.3968 - val_accuracy: 0.2787\n","Epoch 292/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5524 - accuracy: 0.6655 - val_loss: 2.4214 - val_accuracy: 0.2869\n","Epoch 293/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5833 - accuracy: 0.6725 - val_loss: 2.4596 - val_accuracy: 0.2951\n","Epoch 294/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5389 - accuracy: 0.7218 - val_loss: 2.3647 - val_accuracy: 0.3033\n","Epoch 295/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5727 - accuracy: 0.6549 - val_loss: 2.3556 - val_accuracy: 0.3361\n","Epoch 296/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5511 - accuracy: 0.6831 - val_loss: 2.4539 - val_accuracy: 0.2869\n","Epoch 297/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5885 - accuracy: 0.6761 - val_loss: 2.4194 - val_accuracy: 0.2787\n","Epoch 298/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.5461 - accuracy: 0.7042 - val_loss: 2.3839 - val_accuracy: 0.2787\n","Epoch 299/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.5695 - accuracy: 0.6655 - val_loss: 2.4543 - val_accuracy: 0.3279\n","Epoch 300/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.5929 - accuracy: 0.6655 - val_loss: 2.4468 - val_accuracy: 0.3279\n","Accuracy: 0.30392156862745096\n","Detail:\n","              precision    recall  f1-score   support\n","\n","         SR1       0.35      0.22      0.27        37\n","         SR2       0.26      0.17      0.21        29\n","         SR3       0.33      0.65      0.44        26\n","         SR4       0.12      0.10      0.11        10\n","\n","    accuracy                           0.30       102\n","   macro avg       0.27      0.29      0.26       102\n","weighted avg       0.30      0.30      0.28       102\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'vocab_layer_norm', 'activation_13', 'vocab_transform']\n","- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"functional_17\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_idx (InputLayer)          [(None, 150)]        0                                            \n","__________________________________________________________________________________________________\n","input_masks (InputLayer)        [(None, 150)]        0                                            \n","__________________________________________________________________________________________________\n","tf_distil_bert_model_8 (TFDisti ((None, 150, 768),)  66362880    input_idx[0][0]                  \n","                                                                 input_masks[0][0]                \n","__________________________________________________________________________________________________\n","global_average_pooling1d_8 (Glo (None, 768)          0           tf_distil_bert_model_8[0][0]     \n","__________________________________________________________________________________________________\n","dense_16 (Dense)                (None, 64)           49216       global_average_pooling1d_8[0][0] \n","__________________________________________________________________________________________________\n","dense_17 (Dense)                (None, 4)            260         dense_16[0][0]                   \n","==================================================================================================\n","Total params: 66,412,356\n","Trainable params: 49,476\n","Non-trainable params: 66,362,880\n","__________________________________________________________________________________________________\n","{0: 'SR1', 1: 'SR2', 2: 'SR3', 3: 'SR4'}\n","{'SR1': 0, 'SR2': 1, 'SR3': 2, 'SR4': 3}\n","Epoch 1/300\n","9/9 [==============================] - 3s 360ms/step - loss: 1.3047 - accuracy: 0.3169 - val_loss: 1.2570 - val_accuracy: 0.3689\n","Epoch 2/300\n","9/9 [==============================] - 2s 233ms/step - loss: 1.2333 - accuracy: 0.4014 - val_loss: 1.2427 - val_accuracy: 0.3852\n","Epoch 3/300\n","9/9 [==============================] - 2s 233ms/step - loss: 1.2005 - accuracy: 0.4155 - val_loss: 1.2478 - val_accuracy: 0.3770\n","Epoch 4/300\n","9/9 [==============================] - 2s 232ms/step - loss: 1.1607 - accuracy: 0.4789 - val_loss: 1.2487 - val_accuracy: 0.3934\n","Epoch 5/300\n","9/9 [==============================] - 2s 233ms/step - loss: 1.1345 - accuracy: 0.4648 - val_loss: 1.2363 - val_accuracy: 0.4016\n","Epoch 6/300\n","9/9 [==============================] - 2s 233ms/step - loss: 1.1073 - accuracy: 0.4859 - val_loss: 1.2576 - val_accuracy: 0.3770\n","Epoch 7/300\n","9/9 [==============================] - 2s 233ms/step - loss: 1.0890 - accuracy: 0.5070 - val_loss: 1.2515 - val_accuracy: 0.3852\n","Epoch 8/300\n","9/9 [==============================] - 2s 233ms/step - loss: 1.0846 - accuracy: 0.4930 - val_loss: 1.2537 - val_accuracy: 0.3852\n","Epoch 9/300\n","9/9 [==============================] - 2s 234ms/step - loss: 1.0684 - accuracy: 0.5070 - val_loss: 1.2758 - val_accuracy: 0.3607\n","Epoch 10/300\n","9/9 [==============================] - 2s 234ms/step - loss: 1.0579 - accuracy: 0.5106 - val_loss: 1.2749 - val_accuracy: 0.3770\n","Epoch 11/300\n","9/9 [==============================] - 2s 233ms/step - loss: 1.0454 - accuracy: 0.5000 - val_loss: 1.2727 - val_accuracy: 0.4016\n","Epoch 12/300\n","9/9 [==============================] - 2s 233ms/step - loss: 1.0446 - accuracy: 0.5106 - val_loss: 1.3044 - val_accuracy: 0.3689\n","Epoch 13/300\n","9/9 [==============================] - 2s 234ms/step - loss: 1.0229 - accuracy: 0.5106 - val_loss: 1.2716 - val_accuracy: 0.4098\n","Epoch 14/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.9892 - accuracy: 0.5669 - val_loss: 1.3075 - val_accuracy: 0.3852\n","Epoch 15/300\n","9/9 [==============================] - 2s 232ms/step - loss: 1.0073 - accuracy: 0.5634 - val_loss: 1.3096 - val_accuracy: 0.3770\n","Epoch 16/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.9892 - accuracy: 0.5352 - val_loss: 1.2902 - val_accuracy: 0.4098\n","Epoch 17/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.9908 - accuracy: 0.5211 - val_loss: 1.3110 - val_accuracy: 0.3852\n","Epoch 18/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.9670 - accuracy: 0.5387 - val_loss: 1.3202 - val_accuracy: 0.3934\n","Epoch 19/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.9600 - accuracy: 0.5775 - val_loss: 1.3277 - val_accuracy: 0.3607\n","Epoch 20/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.9331 - accuracy: 0.6162 - val_loss: 1.3446 - val_accuracy: 0.3852\n","Epoch 21/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.9579 - accuracy: 0.5845 - val_loss: 1.3310 - val_accuracy: 0.4098\n","Epoch 22/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.9650 - accuracy: 0.5634 - val_loss: 1.3814 - val_accuracy: 0.3607\n","Epoch 23/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.9506 - accuracy: 0.5387 - val_loss: 1.3446 - val_accuracy: 0.3770\n","Epoch 24/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.9393 - accuracy: 0.5493 - val_loss: 1.3679 - val_accuracy: 0.3607\n","Epoch 25/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.9200 - accuracy: 0.5951 - val_loss: 1.3778 - val_accuracy: 0.3770\n","Epoch 26/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.9373 - accuracy: 0.5317 - val_loss: 1.3848 - val_accuracy: 0.3852\n","Epoch 27/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.9120 - accuracy: 0.5880 - val_loss: 1.3837 - val_accuracy: 0.3689\n","Epoch 28/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.9172 - accuracy: 0.5845 - val_loss: 1.3947 - val_accuracy: 0.3689\n","Epoch 29/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.9040 - accuracy: 0.5951 - val_loss: 1.3861 - val_accuracy: 0.4016\n","Epoch 30/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.9101 - accuracy: 0.5951 - val_loss: 1.4080 - val_accuracy: 0.3607\n","Epoch 31/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.8742 - accuracy: 0.6127 - val_loss: 1.4011 - val_accuracy: 0.3934\n","Epoch 32/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.8750 - accuracy: 0.6373 - val_loss: 1.4670 - val_accuracy: 0.3279\n","Epoch 33/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.8687 - accuracy: 0.5669 - val_loss: 1.4211 - val_accuracy: 0.3934\n","Epoch 34/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.8693 - accuracy: 0.5845 - val_loss: 1.4581 - val_accuracy: 0.3607\n","Epoch 35/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.8538 - accuracy: 0.6021 - val_loss: 1.4504 - val_accuracy: 0.3852\n","Epoch 36/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.8499 - accuracy: 0.6127 - val_loss: 1.4521 - val_accuracy: 0.3689\n","Epoch 37/300\n","9/9 [==============================] - 2s 239ms/step - loss: 0.8555 - accuracy: 0.6092 - val_loss: 1.4587 - val_accuracy: 0.3607\n","Epoch 38/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.8519 - accuracy: 0.6056 - val_loss: 1.4484 - val_accuracy: 0.3852\n","Epoch 39/300\n","9/9 [==============================] - 2s 240ms/step - loss: 0.8315 - accuracy: 0.6373 - val_loss: 1.4777 - val_accuracy: 0.3525\n","Epoch 40/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.8571 - accuracy: 0.6162 - val_loss: 1.4634 - val_accuracy: 0.3934\n","Epoch 41/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.8212 - accuracy: 0.5986 - val_loss: 1.4727 - val_accuracy: 0.3689\n","Epoch 42/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.8111 - accuracy: 0.6338 - val_loss: 1.4603 - val_accuracy: 0.3689\n","Epoch 43/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.8531 - accuracy: 0.6021 - val_loss: 1.4702 - val_accuracy: 0.3770\n","Epoch 44/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.8310 - accuracy: 0.6197 - val_loss: 1.4792 - val_accuracy: 0.3689\n","Epoch 45/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.8176 - accuracy: 0.6303 - val_loss: 1.4841 - val_accuracy: 0.3689\n","Epoch 46/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.8284 - accuracy: 0.6232 - val_loss: 1.5007 - val_accuracy: 0.3525\n","Epoch 47/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.8077 - accuracy: 0.5880 - val_loss: 1.5027 - val_accuracy: 0.3525\n","Epoch 48/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.8134 - accuracy: 0.6021 - val_loss: 1.5095 - val_accuracy: 0.3525\n","Epoch 49/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.8171 - accuracy: 0.6268 - val_loss: 1.5317 - val_accuracy: 0.3607\n","Epoch 50/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.8062 - accuracy: 0.6232 - val_loss: 1.5596 - val_accuracy: 0.3607\n","Epoch 51/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7927 - accuracy: 0.6232 - val_loss: 1.5381 - val_accuracy: 0.3443\n","Epoch 52/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.8161 - accuracy: 0.6021 - val_loss: 1.5562 - val_accuracy: 0.3443\n","Epoch 53/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.8084 - accuracy: 0.6338 - val_loss: 1.5607 - val_accuracy: 0.3689\n","Epoch 54/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.7815 - accuracy: 0.6514 - val_loss: 1.6114 - val_accuracy: 0.3361\n","Epoch 55/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.8152 - accuracy: 0.6021 - val_loss: 1.5274 - val_accuracy: 0.4016\n","Epoch 56/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.8209 - accuracy: 0.6232 - val_loss: 1.6135 - val_accuracy: 0.3361\n","Epoch 57/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.7860 - accuracy: 0.6303 - val_loss: 1.5447 - val_accuracy: 0.3770\n","Epoch 58/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.8071 - accuracy: 0.6197 - val_loss: 1.6137 - val_accuracy: 0.3361\n","Epoch 59/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.8093 - accuracy: 0.6092 - val_loss: 1.5367 - val_accuracy: 0.3934\n","Epoch 60/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7818 - accuracy: 0.6373 - val_loss: 1.5793 - val_accuracy: 0.3443\n","Epoch 61/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.7606 - accuracy: 0.6268 - val_loss: 1.5569 - val_accuracy: 0.3934\n","Epoch 62/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.7917 - accuracy: 0.6268 - val_loss: 1.5596 - val_accuracy: 0.3770\n","Epoch 63/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.7826 - accuracy: 0.6197 - val_loss: 1.5685 - val_accuracy: 0.3525\n","Epoch 64/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.7646 - accuracy: 0.6585 - val_loss: 1.5918 - val_accuracy: 0.3607\n","Epoch 65/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.7583 - accuracy: 0.6373 - val_loss: 1.5939 - val_accuracy: 0.3607\n","Epoch 66/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.7648 - accuracy: 0.6338 - val_loss: 1.5941 - val_accuracy: 0.3689\n","Epoch 67/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.7697 - accuracy: 0.6725 - val_loss: 1.6076 - val_accuracy: 0.3607\n","Epoch 68/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.7719 - accuracy: 0.6162 - val_loss: 1.6377 - val_accuracy: 0.3525\n","Epoch 69/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.8075 - accuracy: 0.5986 - val_loss: 1.6246 - val_accuracy: 0.3607\n","Epoch 70/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.7556 - accuracy: 0.6373 - val_loss: 1.6563 - val_accuracy: 0.3525\n","Epoch 71/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.7544 - accuracy: 0.6479 - val_loss: 1.6131 - val_accuracy: 0.3934\n","Epoch 72/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7459 - accuracy: 0.6549 - val_loss: 1.6492 - val_accuracy: 0.3525\n","Epoch 73/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.7573 - accuracy: 0.6514 - val_loss: 1.6289 - val_accuracy: 0.3934\n","Epoch 74/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7571 - accuracy: 0.6021 - val_loss: 1.6507 - val_accuracy: 0.3525\n","Epoch 75/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7433 - accuracy: 0.6761 - val_loss: 1.6718 - val_accuracy: 0.3443\n","Epoch 76/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.7488 - accuracy: 0.6514 - val_loss: 1.6560 - val_accuracy: 0.3689\n","Epoch 77/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.7543 - accuracy: 0.6479 - val_loss: 1.6888 - val_accuracy: 0.3443\n","Epoch 78/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7475 - accuracy: 0.6303 - val_loss: 1.7022 - val_accuracy: 0.3607\n","Epoch 79/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7638 - accuracy: 0.6373 - val_loss: 1.6684 - val_accuracy: 0.3770\n","Epoch 80/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.7420 - accuracy: 0.6303 - val_loss: 1.6725 - val_accuracy: 0.3689\n","Epoch 81/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.7546 - accuracy: 0.6408 - val_loss: 1.6551 - val_accuracy: 0.3689\n","Epoch 82/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7305 - accuracy: 0.6655 - val_loss: 1.6934 - val_accuracy: 0.3525\n","Epoch 83/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7155 - accuracy: 0.6796 - val_loss: 1.7144 - val_accuracy: 0.3361\n","Epoch 84/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7513 - accuracy: 0.6268 - val_loss: 1.6922 - val_accuracy: 0.3607\n","Epoch 85/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7521 - accuracy: 0.6197 - val_loss: 1.7027 - val_accuracy: 0.3689\n","Epoch 86/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.7357 - accuracy: 0.6268 - val_loss: 1.6908 - val_accuracy: 0.3852\n","Epoch 87/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7282 - accuracy: 0.6373 - val_loss: 1.7172 - val_accuracy: 0.3689\n","Epoch 88/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7330 - accuracy: 0.6268 - val_loss: 1.7442 - val_accuracy: 0.3443\n","Epoch 89/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.7434 - accuracy: 0.6585 - val_loss: 1.7180 - val_accuracy: 0.3689\n","Epoch 90/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.7101 - accuracy: 0.6514 - val_loss: 1.7229 - val_accuracy: 0.3689\n","Epoch 91/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.7579 - accuracy: 0.6092 - val_loss: 1.6956 - val_accuracy: 0.3770\n","Epoch 92/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.7133 - accuracy: 0.6479 - val_loss: 1.7063 - val_accuracy: 0.3443\n","Epoch 93/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.7270 - accuracy: 0.6303 - val_loss: 1.7070 - val_accuracy: 0.3607\n","Epoch 94/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.7318 - accuracy: 0.6408 - val_loss: 1.7443 - val_accuracy: 0.3361\n","Epoch 95/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.7054 - accuracy: 0.6549 - val_loss: 1.7085 - val_accuracy: 0.3770\n","Epoch 96/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.7208 - accuracy: 0.6479 - val_loss: 1.7682 - val_accuracy: 0.3525\n","Epoch 97/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.7282 - accuracy: 0.6408 - val_loss: 1.7697 - val_accuracy: 0.3361\n","Epoch 98/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6845 - accuracy: 0.6408 - val_loss: 1.7443 - val_accuracy: 0.3689\n","Epoch 99/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.7202 - accuracy: 0.6514 - val_loss: 1.8159 - val_accuracy: 0.3443\n","Epoch 100/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.7407 - accuracy: 0.6408 - val_loss: 1.7881 - val_accuracy: 0.3607\n","Epoch 101/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.7053 - accuracy: 0.6444 - val_loss: 1.7737 - val_accuracy: 0.3689\n","Epoch 102/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7302 - accuracy: 0.6162 - val_loss: 1.7725 - val_accuracy: 0.3689\n","Epoch 103/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.7268 - accuracy: 0.6162 - val_loss: 1.7970 - val_accuracy: 0.3607\n","Epoch 104/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6963 - accuracy: 0.6514 - val_loss: 1.7738 - val_accuracy: 0.3770\n","Epoch 105/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.7129 - accuracy: 0.6373 - val_loss: 1.7827 - val_accuracy: 0.3770\n","Epoch 106/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.7097 - accuracy: 0.6690 - val_loss: 1.7766 - val_accuracy: 0.3770\n","Epoch 107/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.7133 - accuracy: 0.6585 - val_loss: 1.7657 - val_accuracy: 0.3525\n","Epoch 108/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7527 - accuracy: 0.6021 - val_loss: 1.7722 - val_accuracy: 0.3689\n","Epoch 109/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.7061 - accuracy: 0.6585 - val_loss: 1.7730 - val_accuracy: 0.3525\n","Epoch 110/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.7152 - accuracy: 0.6232 - val_loss: 1.7854 - val_accuracy: 0.3525\n","Epoch 111/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6855 - accuracy: 0.6655 - val_loss: 1.8004 - val_accuracy: 0.3525\n","Epoch 112/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6807 - accuracy: 0.6268 - val_loss: 1.7780 - val_accuracy: 0.3689\n","Epoch 113/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.7153 - accuracy: 0.6232 - val_loss: 1.8648 - val_accuracy: 0.3443\n","Epoch 114/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6988 - accuracy: 0.6549 - val_loss: 1.8349 - val_accuracy: 0.3443\n","Epoch 115/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7100 - accuracy: 0.6268 - val_loss: 1.7823 - val_accuracy: 0.3607\n","Epoch 116/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6806 - accuracy: 0.6831 - val_loss: 1.8351 - val_accuracy: 0.3525\n","Epoch 117/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6939 - accuracy: 0.6408 - val_loss: 1.8240 - val_accuracy: 0.3525\n","Epoch 118/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6898 - accuracy: 0.6585 - val_loss: 1.8207 - val_accuracy: 0.3689\n","Epoch 119/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.7074 - accuracy: 0.6514 - val_loss: 1.8813 - val_accuracy: 0.3443\n","Epoch 120/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6860 - accuracy: 0.6514 - val_loss: 1.8282 - val_accuracy: 0.3689\n","Epoch 121/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.7229 - accuracy: 0.6197 - val_loss: 1.8063 - val_accuracy: 0.3443\n","Epoch 122/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6938 - accuracy: 0.6690 - val_loss: 1.8107 - val_accuracy: 0.3525\n","Epoch 123/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6859 - accuracy: 0.6408 - val_loss: 1.8225 - val_accuracy: 0.3525\n","Epoch 124/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7105 - accuracy: 0.6303 - val_loss: 1.7737 - val_accuracy: 0.3607\n","Epoch 125/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.7021 - accuracy: 0.6514 - val_loss: 1.8474 - val_accuracy: 0.3443\n","Epoch 126/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6928 - accuracy: 0.6514 - val_loss: 1.8400 - val_accuracy: 0.3689\n","Epoch 127/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6972 - accuracy: 0.6549 - val_loss: 1.8358 - val_accuracy: 0.3443\n","Epoch 128/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6609 - accuracy: 0.6620 - val_loss: 1.8128 - val_accuracy: 0.3607\n","Epoch 129/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6825 - accuracy: 0.6408 - val_loss: 1.8907 - val_accuracy: 0.3443\n","Epoch 130/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6922 - accuracy: 0.6268 - val_loss: 1.8571 - val_accuracy: 0.3770\n","Epoch 131/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.7022 - accuracy: 0.6585 - val_loss: 1.9295 - val_accuracy: 0.3525\n","Epoch 132/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6843 - accuracy: 0.6831 - val_loss: 1.8366 - val_accuracy: 0.3689\n","Epoch 133/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6921 - accuracy: 0.6444 - val_loss: 1.9199 - val_accuracy: 0.3525\n","Epoch 134/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.7084 - accuracy: 0.6338 - val_loss: 1.8491 - val_accuracy: 0.3607\n","Epoch 135/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6967 - accuracy: 0.6268 - val_loss: 1.9268 - val_accuracy: 0.3607\n","Epoch 136/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6741 - accuracy: 0.6479 - val_loss: 1.8577 - val_accuracy: 0.3770\n","Epoch 137/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6669 - accuracy: 0.6303 - val_loss: 1.8983 - val_accuracy: 0.3770\n","Epoch 138/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6783 - accuracy: 0.6690 - val_loss: 1.9049 - val_accuracy: 0.3361\n","Epoch 139/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6866 - accuracy: 0.6479 - val_loss: 1.8852 - val_accuracy: 0.3689\n","Epoch 140/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6893 - accuracy: 0.6303 - val_loss: 1.9023 - val_accuracy: 0.3607\n","Epoch 141/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.7019 - accuracy: 0.6303 - val_loss: 1.9313 - val_accuracy: 0.3689\n","Epoch 142/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6756 - accuracy: 0.6408 - val_loss: 1.9152 - val_accuracy: 0.3770\n","Epoch 143/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.7251 - accuracy: 0.6232 - val_loss: 1.9486 - val_accuracy: 0.3689\n","Epoch 144/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6923 - accuracy: 0.6338 - val_loss: 1.9181 - val_accuracy: 0.3689\n","Epoch 145/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.7121 - accuracy: 0.6162 - val_loss: 1.9333 - val_accuracy: 0.3443\n","Epoch 146/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.6887 - accuracy: 0.6197 - val_loss: 1.8866 - val_accuracy: 0.3852\n","Epoch 147/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6541 - accuracy: 0.6725 - val_loss: 1.8829 - val_accuracy: 0.3770\n","Epoch 148/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6575 - accuracy: 0.6514 - val_loss: 1.9161 - val_accuracy: 0.3607\n","Epoch 149/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6883 - accuracy: 0.6232 - val_loss: 1.8865 - val_accuracy: 0.3770\n","Epoch 150/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6888 - accuracy: 0.6479 - val_loss: 1.9034 - val_accuracy: 0.3689\n","Epoch 151/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6811 - accuracy: 0.6620 - val_loss: 1.9036 - val_accuracy: 0.3689\n","Epoch 152/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6580 - accuracy: 0.6761 - val_loss: 1.9095 - val_accuracy: 0.3689\n","Epoch 153/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6901 - accuracy: 0.6549 - val_loss: 1.9507 - val_accuracy: 0.3361\n","Epoch 154/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6697 - accuracy: 0.6761 - val_loss: 1.9057 - val_accuracy: 0.3852\n","Epoch 155/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6793 - accuracy: 0.6585 - val_loss: 1.9667 - val_accuracy: 0.3443\n","Epoch 156/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6527 - accuracy: 0.6796 - val_loss: 1.9552 - val_accuracy: 0.3689\n","Epoch 157/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6827 - accuracy: 0.6444 - val_loss: 1.9653 - val_accuracy: 0.3770\n","Epoch 158/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6574 - accuracy: 0.7007 - val_loss: 1.9710 - val_accuracy: 0.3852\n","Epoch 159/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6463 - accuracy: 0.6761 - val_loss: 1.9840 - val_accuracy: 0.3689\n","Epoch 160/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6754 - accuracy: 0.6479 - val_loss: 2.0082 - val_accuracy: 0.3689\n","Epoch 161/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.7013 - accuracy: 0.6162 - val_loss: 1.9562 - val_accuracy: 0.3770\n","Epoch 162/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.7065 - accuracy: 0.6373 - val_loss: 1.9692 - val_accuracy: 0.3607\n","Epoch 163/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6745 - accuracy: 0.6549 - val_loss: 1.9499 - val_accuracy: 0.3770\n","Epoch 164/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6749 - accuracy: 0.6303 - val_loss: 2.0174 - val_accuracy: 0.3525\n","Epoch 165/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6613 - accuracy: 0.6514 - val_loss: 1.9430 - val_accuracy: 0.3934\n","Epoch 166/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6537 - accuracy: 0.6655 - val_loss: 2.0008 - val_accuracy: 0.3689\n","Epoch 167/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6871 - accuracy: 0.6338 - val_loss: 1.9465 - val_accuracy: 0.3852\n","Epoch 168/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6893 - accuracy: 0.6303 - val_loss: 2.0185 - val_accuracy: 0.3607\n","Epoch 169/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6765 - accuracy: 0.6479 - val_loss: 1.9736 - val_accuracy: 0.3689\n","Epoch 170/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6948 - accuracy: 0.6303 - val_loss: 1.9704 - val_accuracy: 0.3689\n","Epoch 171/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6912 - accuracy: 0.6232 - val_loss: 1.9802 - val_accuracy: 0.3689\n","Epoch 172/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6777 - accuracy: 0.6127 - val_loss: 1.9696 - val_accuracy: 0.3689\n","Epoch 173/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6596 - accuracy: 0.6549 - val_loss: 1.9790 - val_accuracy: 0.3607\n","Epoch 174/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6684 - accuracy: 0.6373 - val_loss: 1.9378 - val_accuracy: 0.3934\n","Epoch 175/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6832 - accuracy: 0.6549 - val_loss: 1.9863 - val_accuracy: 0.3770\n","Epoch 176/300\n","9/9 [==============================] - 2s 240ms/step - loss: 0.6487 - accuracy: 0.6655 - val_loss: 2.0139 - val_accuracy: 0.3689\n","Epoch 177/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6410 - accuracy: 0.6585 - val_loss: 2.0027 - val_accuracy: 0.3770\n","Epoch 178/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6635 - accuracy: 0.6479 - val_loss: 2.0203 - val_accuracy: 0.3689\n","Epoch 179/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6557 - accuracy: 0.6444 - val_loss: 2.0838 - val_accuracy: 0.3525\n","Epoch 180/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6750 - accuracy: 0.6373 - val_loss: 2.0451 - val_accuracy: 0.3689\n","Epoch 181/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6745 - accuracy: 0.6514 - val_loss: 2.0654 - val_accuracy: 0.3689\n","Epoch 182/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6669 - accuracy: 0.6408 - val_loss: 2.0244 - val_accuracy: 0.3607\n","Epoch 183/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6940 - accuracy: 0.6021 - val_loss: 1.9992 - val_accuracy: 0.3770\n","Epoch 184/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6800 - accuracy: 0.6479 - val_loss: 2.0554 - val_accuracy: 0.3443\n","Epoch 185/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6582 - accuracy: 0.6620 - val_loss: 2.0250 - val_accuracy: 0.3689\n","Epoch 186/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6871 - accuracy: 0.6303 - val_loss: 2.0410 - val_accuracy: 0.3607\n","Epoch 187/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6797 - accuracy: 0.6197 - val_loss: 2.0361 - val_accuracy: 0.3689\n","Epoch 188/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6641 - accuracy: 0.6479 - val_loss: 2.0228 - val_accuracy: 0.3852\n","Epoch 189/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6754 - accuracy: 0.6373 - val_loss: 2.0791 - val_accuracy: 0.3525\n","Epoch 190/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6541 - accuracy: 0.6866 - val_loss: 2.0133 - val_accuracy: 0.3852\n","Epoch 191/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6659 - accuracy: 0.6197 - val_loss: 2.0910 - val_accuracy: 0.3770\n","Epoch 192/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6433 - accuracy: 0.6549 - val_loss: 2.0826 - val_accuracy: 0.3770\n","Epoch 193/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6775 - accuracy: 0.6268 - val_loss: 2.0699 - val_accuracy: 0.3525\n","Epoch 194/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6469 - accuracy: 0.6796 - val_loss: 2.0653 - val_accuracy: 0.3770\n","Epoch 195/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.6615 - accuracy: 0.6479 - val_loss: 2.0443 - val_accuracy: 0.3770\n","Epoch 196/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6682 - accuracy: 0.6866 - val_loss: 2.0639 - val_accuracy: 0.3607\n","Epoch 197/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6823 - accuracy: 0.6831 - val_loss: 2.0445 - val_accuracy: 0.3607\n","Epoch 198/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6555 - accuracy: 0.6620 - val_loss: 2.0435 - val_accuracy: 0.3689\n","Epoch 199/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6544 - accuracy: 0.6549 - val_loss: 2.0695 - val_accuracy: 0.3607\n","Epoch 200/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6667 - accuracy: 0.6620 - val_loss: 2.0550 - val_accuracy: 0.3689\n","Epoch 201/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6665 - accuracy: 0.6549 - val_loss: 2.0775 - val_accuracy: 0.3689\n","Epoch 202/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6368 - accuracy: 0.6655 - val_loss: 2.0527 - val_accuracy: 0.3852\n","Epoch 203/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6589 - accuracy: 0.6690 - val_loss: 2.1208 - val_accuracy: 0.3607\n","Epoch 204/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6524 - accuracy: 0.6585 - val_loss: 2.0830 - val_accuracy: 0.3770\n","Epoch 205/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6508 - accuracy: 0.6373 - val_loss: 2.0894 - val_accuracy: 0.3852\n","Epoch 206/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6318 - accuracy: 0.6725 - val_loss: 2.0697 - val_accuracy: 0.3770\n","Epoch 207/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6691 - accuracy: 0.6620 - val_loss: 2.1096 - val_accuracy: 0.3607\n","Epoch 208/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6480 - accuracy: 0.6585 - val_loss: 2.0916 - val_accuracy: 0.3607\n","Epoch 209/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6827 - accuracy: 0.6338 - val_loss: 2.0907 - val_accuracy: 0.3689\n","Epoch 210/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6786 - accuracy: 0.6725 - val_loss: 2.1068 - val_accuracy: 0.3689\n","Epoch 211/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6658 - accuracy: 0.6444 - val_loss: 2.0996 - val_accuracy: 0.3607\n","Epoch 212/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6709 - accuracy: 0.6268 - val_loss: 2.0598 - val_accuracy: 0.3770\n","Epoch 213/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6677 - accuracy: 0.6479 - val_loss: 2.0737 - val_accuracy: 0.3689\n","Epoch 214/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6602 - accuracy: 0.6444 - val_loss: 2.0776 - val_accuracy: 0.3770\n","Epoch 215/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6540 - accuracy: 0.6831 - val_loss: 2.0705 - val_accuracy: 0.3852\n","Epoch 216/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6325 - accuracy: 0.6549 - val_loss: 2.0709 - val_accuracy: 0.3689\n","Epoch 217/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6511 - accuracy: 0.6232 - val_loss: 2.0589 - val_accuracy: 0.3607\n","Epoch 218/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6406 - accuracy: 0.6655 - val_loss: 2.0775 - val_accuracy: 0.3770\n","Epoch 219/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6727 - accuracy: 0.6197 - val_loss: 2.1155 - val_accuracy: 0.3770\n","Epoch 220/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6889 - accuracy: 0.6232 - val_loss: 2.0492 - val_accuracy: 0.3770\n","Epoch 221/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6574 - accuracy: 0.6373 - val_loss: 2.1642 - val_accuracy: 0.3361\n","Epoch 222/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6498 - accuracy: 0.6585 - val_loss: 2.0917 - val_accuracy: 0.3689\n","Epoch 223/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6577 - accuracy: 0.6408 - val_loss: 2.1332 - val_accuracy: 0.3607\n","Epoch 224/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6701 - accuracy: 0.6338 - val_loss: 2.0904 - val_accuracy: 0.3852\n","Epoch 225/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6655 - accuracy: 0.6549 - val_loss: 2.1372 - val_accuracy: 0.3607\n","Epoch 226/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6358 - accuracy: 0.6549 - val_loss: 2.1055 - val_accuracy: 0.3607\n","Epoch 227/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6437 - accuracy: 0.6761 - val_loss: 2.1214 - val_accuracy: 0.3770\n","Epoch 228/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6760 - accuracy: 0.6479 - val_loss: 2.1438 - val_accuracy: 0.3525\n","Epoch 229/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6590 - accuracy: 0.6549 - val_loss: 2.1069 - val_accuracy: 0.3689\n","Epoch 230/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6598 - accuracy: 0.6092 - val_loss: 2.1175 - val_accuracy: 0.3689\n","Epoch 231/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6170 - accuracy: 0.6972 - val_loss: 2.1673 - val_accuracy: 0.3525\n","Epoch 232/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6805 - accuracy: 0.6056 - val_loss: 2.0803 - val_accuracy: 0.3689\n","Epoch 233/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6741 - accuracy: 0.6585 - val_loss: 2.1169 - val_accuracy: 0.3525\n","Epoch 234/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6270 - accuracy: 0.6514 - val_loss: 2.1208 - val_accuracy: 0.3689\n","Epoch 235/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6594 - accuracy: 0.6303 - val_loss: 2.1346 - val_accuracy: 0.3689\n","Epoch 236/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6181 - accuracy: 0.6937 - val_loss: 2.1280 - val_accuracy: 0.3607\n","Epoch 237/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6688 - accuracy: 0.6655 - val_loss: 2.1552 - val_accuracy: 0.3770\n","Epoch 238/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.6815 - accuracy: 0.6268 - val_loss: 2.1011 - val_accuracy: 0.3934\n","Epoch 239/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6533 - accuracy: 0.6620 - val_loss: 2.1078 - val_accuracy: 0.3770\n","Epoch 240/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6396 - accuracy: 0.6761 - val_loss: 2.1490 - val_accuracy: 0.3525\n","Epoch 241/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.6209 - accuracy: 0.6690 - val_loss: 2.1389 - val_accuracy: 0.3770\n","Epoch 242/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.6320 - accuracy: 0.6514 - val_loss: 2.1612 - val_accuracy: 0.3770\n","Epoch 243/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6549 - accuracy: 0.6479 - val_loss: 2.1198 - val_accuracy: 0.3689\n","Epoch 244/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6614 - accuracy: 0.6479 - val_loss: 2.1627 - val_accuracy: 0.3525\n","Epoch 245/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6415 - accuracy: 0.6479 - val_loss: 2.1634 - val_accuracy: 0.3770\n","Epoch 246/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6580 - accuracy: 0.6479 - val_loss: 2.1595 - val_accuracy: 0.3770\n","Epoch 247/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.6486 - accuracy: 0.6585 - val_loss: 2.1485 - val_accuracy: 0.3770\n","Epoch 248/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6960 - accuracy: 0.5986 - val_loss: 2.1592 - val_accuracy: 0.3689\n","Epoch 249/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6408 - accuracy: 0.6796 - val_loss: 2.1625 - val_accuracy: 0.3770\n","Epoch 250/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6500 - accuracy: 0.6549 - val_loss: 2.1345 - val_accuracy: 0.3689\n","Epoch 251/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6671 - accuracy: 0.6444 - val_loss: 2.1505 - val_accuracy: 0.3689\n","Epoch 252/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6411 - accuracy: 0.6690 - val_loss: 2.1120 - val_accuracy: 0.3934\n","Epoch 253/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6629 - accuracy: 0.6338 - val_loss: 2.1819 - val_accuracy: 0.3525\n","Epoch 254/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6553 - accuracy: 0.6479 - val_loss: 2.1181 - val_accuracy: 0.3852\n","Epoch 255/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6768 - accuracy: 0.6514 - val_loss: 2.0987 - val_accuracy: 0.3770\n","Epoch 256/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6602 - accuracy: 0.6514 - val_loss: 2.1251 - val_accuracy: 0.3770\n","Epoch 257/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6653 - accuracy: 0.6127 - val_loss: 2.1962 - val_accuracy: 0.3607\n","Epoch 258/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6490 - accuracy: 0.6514 - val_loss: 2.1210 - val_accuracy: 0.3689\n","Epoch 259/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6523 - accuracy: 0.6373 - val_loss: 2.1462 - val_accuracy: 0.3770\n","Epoch 260/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6463 - accuracy: 0.6444 - val_loss: 2.1738 - val_accuracy: 0.3607\n","Epoch 261/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6403 - accuracy: 0.6479 - val_loss: 2.1297 - val_accuracy: 0.3934\n","Epoch 262/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6292 - accuracy: 0.6655 - val_loss: 2.1550 - val_accuracy: 0.3607\n","Epoch 263/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6504 - accuracy: 0.6092 - val_loss: 2.1888 - val_accuracy: 0.3607\n","Epoch 264/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6335 - accuracy: 0.6514 - val_loss: 2.1690 - val_accuracy: 0.3770\n","Epoch 265/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6420 - accuracy: 0.6585 - val_loss: 2.1788 - val_accuracy: 0.3689\n","Epoch 266/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6540 - accuracy: 0.6479 - val_loss: 2.2047 - val_accuracy: 0.3689\n","Epoch 267/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6812 - accuracy: 0.5986 - val_loss: 2.1385 - val_accuracy: 0.3852\n","Epoch 268/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6507 - accuracy: 0.6197 - val_loss: 2.1916 - val_accuracy: 0.3689\n","Epoch 269/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6386 - accuracy: 0.6690 - val_loss: 2.1308 - val_accuracy: 0.3934\n","Epoch 270/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6402 - accuracy: 0.6338 - val_loss: 2.1512 - val_accuracy: 0.3689\n","Epoch 271/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6489 - accuracy: 0.6479 - val_loss: 2.1815 - val_accuracy: 0.3770\n","Epoch 272/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6272 - accuracy: 0.6796 - val_loss: 2.2104 - val_accuracy: 0.3770\n","Epoch 273/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6326 - accuracy: 0.6690 - val_loss: 2.2240 - val_accuracy: 0.3689\n","Epoch 274/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6684 - accuracy: 0.6408 - val_loss: 2.2371 - val_accuracy: 0.3770\n","Epoch 275/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.6195 - accuracy: 0.6585 - val_loss: 2.2705 - val_accuracy: 0.3689\n","Epoch 276/300\n","9/9 [==============================] - 2s 239ms/step - loss: 0.6472 - accuracy: 0.6444 - val_loss: 2.2246 - val_accuracy: 0.3770\n","Epoch 277/300\n","9/9 [==============================] - 2s 238ms/step - loss: 0.6695 - accuracy: 0.6268 - val_loss: 2.1810 - val_accuracy: 0.3852\n","Epoch 278/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6568 - accuracy: 0.6796 - val_loss: 2.2307 - val_accuracy: 0.3607\n","Epoch 279/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6574 - accuracy: 0.6585 - val_loss: 2.1959 - val_accuracy: 0.3770\n","Epoch 280/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6295 - accuracy: 0.6761 - val_loss: 2.1544 - val_accuracy: 0.3934\n","Epoch 281/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6460 - accuracy: 0.6197 - val_loss: 2.2168 - val_accuracy: 0.3934\n","Epoch 282/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6489 - accuracy: 0.6690 - val_loss: 2.1852 - val_accuracy: 0.3852\n","Epoch 283/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6504 - accuracy: 0.6162 - val_loss: 2.1866 - val_accuracy: 0.3689\n","Epoch 284/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6666 - accuracy: 0.6408 - val_loss: 2.2334 - val_accuracy: 0.3770\n","Epoch 285/300\n","9/9 [==============================] - 2s 237ms/step - loss: 0.6568 - accuracy: 0.6549 - val_loss: 2.1813 - val_accuracy: 0.3852\n","Epoch 286/300\n","9/9 [==============================] - 2s 236ms/step - loss: 0.6503 - accuracy: 0.6620 - val_loss: 2.2191 - val_accuracy: 0.3770\n","Epoch 287/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6585 - accuracy: 0.6268 - val_loss: 2.2331 - val_accuracy: 0.3934\n","Epoch 288/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6645 - accuracy: 0.6408 - val_loss: 2.2160 - val_accuracy: 0.3770\n","Epoch 289/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6435 - accuracy: 0.6444 - val_loss: 2.2285 - val_accuracy: 0.3689\n","Epoch 290/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6111 - accuracy: 0.7042 - val_loss: 2.2334 - val_accuracy: 0.3525\n","Epoch 291/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6538 - accuracy: 0.6690 - val_loss: 2.2183 - val_accuracy: 0.3770\n","Epoch 292/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6381 - accuracy: 0.6479 - val_loss: 2.2349 - val_accuracy: 0.3852\n","Epoch 293/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6292 - accuracy: 0.6796 - val_loss: 2.2075 - val_accuracy: 0.3852\n","Epoch 294/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6243 - accuracy: 0.6866 - val_loss: 2.1986 - val_accuracy: 0.3852\n","Epoch 295/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6710 - accuracy: 0.6232 - val_loss: 2.2636 - val_accuracy: 0.3689\n","Epoch 296/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6615 - accuracy: 0.6197 - val_loss: 2.2329 - val_accuracy: 0.3689\n","Epoch 297/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6539 - accuracy: 0.6408 - val_loss: 2.2146 - val_accuracy: 0.3770\n","Epoch 298/300\n","9/9 [==============================] - 2s 234ms/step - loss: 0.6455 - accuracy: 0.6549 - val_loss: 2.1874 - val_accuracy: 0.3770\n","Epoch 299/300\n","9/9 [==============================] - 2s 233ms/step - loss: 0.6502 - accuracy: 0.6338 - val_loss: 2.1925 - val_accuracy: 0.3852\n","Epoch 300/300\n","9/9 [==============================] - 2s 235ms/step - loss: 0.6325 - accuracy: 0.6444 - val_loss: 2.2420 - val_accuracy: 0.3770\n","Accuracy: 0.30392156862745096\n","Detail:\n","              precision    recall  f1-score   support\n","\n","         SR1       0.24      0.25      0.24        32\n","         SR2       0.06      0.05      0.05        19\n","         SR3       0.43      0.48      0.45        44\n","         SR4       1.00      0.14      0.25         7\n","\n","    accuracy                           0.30       102\n","   macro avg       0.43      0.23      0.25       102\n","weighted avg       0.34      0.30      0.30       102\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"IWzCyz8UpSBS","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}