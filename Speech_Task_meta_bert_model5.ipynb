{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44575,
     "status": "ok",
     "timestamp": 1596806693006,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "4kEFttWg0B4y",
    "outputId": "a241238f-f8da-4ab4-99ea-693a5ed90031"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive',  force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10253,
     "status": "ok",
     "timestamp": 1596806706217,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "7xBUaZBf0Bor",
    "outputId": "395046c0-157f-4792-dd68-9df048399e23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
      "\r",
      "\u001b[K     |▍                               | 10kB 26.1MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 20kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 30kB 4.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 40kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 51kB 3.9MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 61kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 71kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 81kB 5.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 92kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 102kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 112kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 122kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 133kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 143kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 153kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 163kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 174kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 184kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 194kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 204kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 215kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 225kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 235kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 245kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 256kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 266kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 276kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 286kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 296kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 307kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 317kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 327kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 337kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 348kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 358kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 368kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 378kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 389kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 399kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 409kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 419kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 430kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 440kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 450kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 460kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 471kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 481kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 491kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 501kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 512kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 522kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 532kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 542kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 552kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 563kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 573kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 583kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 593kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 604kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 614kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 624kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 634kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 645kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 655kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 665kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 675kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 686kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 696kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 706kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 716kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 727kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 737kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 747kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 757kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 768kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 778kB 5.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 28.0MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 28.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 55.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=81b3a12905dd330582b2cb3af1f0c18f4cddba197238197b198d47289253116e\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14170,
     "status": "ok",
     "timestamp": 1596806711226,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "fwYkpYAP0LD8"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1363,
     "status": "ok",
     "timestamp": 1596808270441,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "cPah4WHvMICz"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "294ebad7ff094513a0b3c9d00704946c",
      "1527e8a6f0cc461bbefcb92746618ac6",
      "ac379847d5fd4686a6c7fb6f2ec71cf6",
      "a887a85d22f14c4aa515acb63009e3d9",
      "aa6c68a500484e15bb2e0bf54609c8a2",
      "4a46cff0310646c192ed258a156d083f",
      "b0e5f89d621d40af9664f6b0e1ef373b",
      "b65011f77e124c0ab8a33171d5be282f",
      "08a2c8ed74bf4cd08c5939eaa12c6c30",
      "5e84a75672ef4d288f69c496dddd9d5d",
      "824f91d723884145ae508fedcecd83fc",
      "6409a1f0c8304c43af822fd007bc978d",
      "0c3eadb86f284d8fb0e1b27e67aa2553",
      "3cec680932da4b50b9158a7dd18f3bcf",
      "e0b235adf4b94ff8a0ac3d480f4dc986",
      "194f670ca18c437ba540378aa527749b"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34631,
     "status": "ok",
     "timestamp": 1596806733948,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "wbl-sqxJ0Qt1",
    "outputId": "895c0db2-941d-4fbc-bc32-e9b314e3b712"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294ebad7ff094513a0b3c9d00704946c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a2c8ed74bf4cd08c5939eaa12c6c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=363423424.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFBertModel: ['vocab_transform', 'vocab_projector', 'distilbert', 'vocab_layer_norm', 'activation_13']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of TFBertModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['bert']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "nlp_bert = transformers.TFBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "05247ce9a2d24cabbab4cd0cc20f16c1",
      "6f0ed3a6e5224ab5b50bd50029613414",
      "38747afd44ed42788ae8c197d642eacf",
      "8338cb44f04a4e099debb6edbdf93ad5",
      "46ea1cf3050e46b69e1c9d9a67804fe9",
      "fefed274e3814140b0cb304103744020",
      "00004b34205c4414ad59a86460d1eb16",
      "65e1f222b7754b7b8c71e4120cc5bb42"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30309,
     "status": "ok",
     "timestamp": 1596806734675,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "axTuRVsx0Tkb",
    "outputId": "5b25387c-9007-44c9-d836-15cb4dcd95c7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05247ce9a2d24cabbab4cd0cc20f16c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7qHEd58YoMdL"
   },
   "source": [
    "# Generating Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27647,
     "status": "ok",
     "timestamp": 1596806734677,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "5qbUimGofhiE"
   },
   "outputs": [],
   "source": [
    "def get_metadata_features(i):\n",
    "    print(\"Inside get_metadata_features\")\n",
    "    \"\"\"\n",
    "    Obtain the dataset\n",
    "    \"\"\"\n",
    "    # Extracted the text for nlp embeddings  \n",
    "    df_X_train= pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/X_train_' + str(i) + '.pkl')\n",
    "    #print(df_X_train.head())\n",
    "    df_X_test= pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/X_test_' + str(i) + '.pkl')\n",
    "    df_Y_train=pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/Y_train_' + str(i) + '.pkl')\n",
    "    df_Y_test=pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/Y_test_' + str(i) + '.pkl')\n",
    "    #print(df_X_train.shape) #(835, 5)\n",
    "    #print(df_Y_train.shape) #(835, 1)\n",
    "    #print(df_X_test.shape) #(209, 5)\n",
    "    #print(df_Y_test.shape) #(209, 1)\n",
    "    \n",
    "    X_train_meta = df_X_train.drop(['Content', 'Previous_User_Utterance'], axis=1)\n",
    "    X_test_meta = df_X_test.drop(['Content', 'Previous_User_Utterance'], axis=1)\n",
    "    \n",
    "    #print(X_train_meta['Previous_Speech_Act'].unique())\n",
    "    #print(X_train_meta['Previous_Search_Act'].unique())\n",
    "    \n",
    "    return X_train_meta, X_test_meta, df_Y_train, df_Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g9dNbyTVomQB"
   },
   "source": [
    "# Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26971,
     "status": "ok",
     "timestamp": 1596806736258,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "CGZkzItVoLgX"
   },
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "class AttentionLayer(Layer):\n",
    "\n",
    "    def __init__(self,attention_dim=100,return_coefficients=False,**kwargs):\n",
    "        # Initializer \n",
    "        self.supports_masking = True\n",
    "        self.return_coefficients = return_coefficients\n",
    "        self.init = initializers.get('glorot_uniform') # initializes values with uniform distribution\n",
    "        self.attention_dim = attention_dim\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Builds all weights\n",
    "        # W = Weight matrix, b = bias vector, u = context vector\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)),name='W')\n",
    "        self.b = K.variable(self.init((self.attention_dim, )),name='b')\n",
    "        self.u = K.variable(self.init((self.attention_dim, 1)),name='u')\n",
    "        self.trainable_weight = [self.W, self.b, self.u]\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, hit, mask=None):\n",
    "        # Here, the actual calculation is done\n",
    "        uit = K.bias_add(K.dot(hit, self.W),self.b)\n",
    "        uit = K.tanh(uit)\n",
    "        \n",
    "        ait = K.dot(uit, self.u)\n",
    "        ait = K.squeeze(ait, -1)\n",
    "        ait = K.exp(ait)\n",
    "        \n",
    "        if mask is not None:\n",
    "            ait *= K.cast(mask, K.floatx())\n",
    "\n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        ait = K.expand_dims(ait)\n",
    "        weighted_input = hit * ait\n",
    "        \n",
    "        if self.return_coefficients:\n",
    "            return [K.sum(weighted_input, axis=1), ait]\n",
    "        else:\n",
    "            return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_coefficients:\n",
    "            return [(input_shape[0], input_shape[-1]), (input_shape[0], input_shape[-1], 1)]\n",
    "        else:\n",
    "            return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PURM9ikIt8uf"
   },
   "source": [
    "# BERT feature generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25211,
     "status": "ok",
     "timestamp": 1596806736260,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "zKKfFcpnuG6y"
   },
   "outputs": [],
   "source": [
    "def load_files(i):\n",
    "\n",
    "    df_X_train= pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/X_train_' + str(i) + '.pkl')\n",
    "    df_X_test= pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/X_test_' + str(i) + '.pkl')\n",
    "    df_Y_train=pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/Y_train_' + str(i) + '.pkl')\n",
    "    df_Y_test=pd.read_pickle('/content/drive/My Drive/Python Notebook/SCS_CONVEX/data-files/Y_test_' + str(i) + '.pkl')\n",
    "    df_train = pd.concat([df_X_train,df_Y_train], axis=1)\n",
    "    df_test = pd.concat([df_X_test,df_Y_test], axis=1)\n",
    "\n",
    "    #print(list(df_train.columns))\n",
    "\n",
    "    df_train = df_train[[\"Speech_acts\",\"Content\"]]\n",
    "    df_train = df_train.rename(columns={\"Speech_acts\":\"y\", \"Content\":\"text\"})\n",
    "\n",
    "    \n",
    "\n",
    "    df_test = df_test[[\"Speech_acts\",\"Content\"]]\n",
    "    df_test = df_test.rename(columns={\"Speech_acts\":\"y\", \"Content\":\"text\"})\n",
    "\n",
    "    return df_train,df_test,df_Y_train,df_Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24249,
     "status": "ok",
     "timestamp": 1596806736261,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "9Fh_bG0NuoFL"
   },
   "outputs": [],
   "source": [
    "def generate_maskid(training, test):\n",
    "  #print(training['text'])\n",
    "  corpus_train = training['text']\n",
    "  corpus_test = test['text']\n",
    "  #the length of the feature vector is 150\n",
    "  maxlen = 150\n",
    "\n",
    "  #add special tokens\n",
    "  maxqnans = np.int((maxlen-20)/2)\n",
    "  corpus_tokenized_train = [\"[CLS] \"+\n",
    "              \" \".join(tokenizer.tokenize(re.sub(r'[^\\w\\s]+|\\n', '', \n",
    "              str(txt).lower().strip()))[:maxqnans])+\n",
    "              \" [SEP] \" for txt in corpus_train]\n",
    "  corpus_tokenized_test = [\"[CLS] \"+\n",
    "              \" \".join(tokenizer.tokenize(re.sub(r'[^\\w\\s]+|\\n', '', \n",
    "              str(txt).lower().strip()))[:maxqnans])+\n",
    "              \" [SEP] \" for txt in corpus_test]\n",
    "  #generate masks\n",
    "  masks_train = [[1]*len(txt.split(\" \")) + [0]*(maxlen - len(txt.split(\" \"))) for txt in corpus_tokenized_train]\n",
    "  masks_test = [[1]*len(txt.split(\" \")) + [0]*(maxlen - len(txt.split(\" \"))) for txt in corpus_tokenized_test]\n",
    "\n",
    "  #padding\n",
    "  txt2seq_train = [txt + \" [PAD]\"*(maxlen-len(txt.split(\" \"))-2) if len(txt.split(\" \")) != (maxlen) else txt for txt in corpus_tokenized_train]\n",
    "  txt2seq_test = [txt + \" [PAD]\"*(maxlen-len(txt.split(\" \"))-2) if len(txt.split(\" \")) != (maxlen) else txt for txt in corpus_tokenized_test]\n",
    "\n",
    "  #generate idx\n",
    "  idx_train = [tokenizer.encode(seq.split(\" \")) for seq in txt2seq_train]\n",
    "  idx_test = [tokenizer.encode(seq.split(\" \")) for seq in txt2seq_test]      \n",
    "\n",
    "  ## feature matrix\n",
    "  X_train = [np.asarray(idx_train, dtype='int32'), \n",
    "            np.asarray(masks_train, dtype='int32')]\n",
    "  X_test = [np.asarray(idx_test, dtype='int32'), \n",
    "            np.asarray(masks_test, dtype='int32')]\n",
    "  \n",
    "\n",
    "  idx_train = np.asarray(idx_train, dtype='int32')\n",
    "  masks_train = np.asarray(masks_train, dtype='int32')\n",
    "  idx_test = np.asarray(idx_test, dtype='int32')\n",
    "  masks_test = np.asarray(masks_test, dtype='int32')\n",
    "\n",
    "  #print(\"txt: \", training[\"text\"].iloc[0])\n",
    "  #print(\"tokenized:\", [tokenizer.convert_ids_to_tokens(idx) for idx in X_train[0][i].tolist()])\n",
    "  #print(\"idx: \", X_train[0][i])\n",
    "  #print(\"mask: \", X_train[1][i])\n",
    "  return idx_train, masks_train, idx_test, masks_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O2Cqo7YUp6ji"
   },
   "source": [
    "# Deep Neural Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22282,
     "status": "ok",
     "timestamp": 1596806736262,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "OTW2A-hSpzQO"
   },
   "outputs": [],
   "source": [
    "def create_bilstm_meta_bert_channels(reshaped_data_meta):\n",
    "    \n",
    "    idx = Input((150), dtype=\"int32\", name=\"input_idx\")\n",
    "    masks = Input((150), dtype=\"int32\", name=\"input_masks\")\n",
    "    ## pre-trained bert with config\n",
    "    config = transformers.DistilBertConfig(dropout=0.2,attention_dropout=0.2)\n",
    "    config.output_hidden_states = False\n",
    "    nlp_bert = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config)\n",
    "    bert_out = nlp_bert(idx, attention_mask=masks)[0]\n",
    "    ## fine-tuning\n",
    "    x = GlobalAveragePooling1D()(bert_out)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    #x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    y_out = Dense(12, activation='softmax')(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    samples,timesteps,features = reshaped_data_meta.shape\n",
    "    inp_meta = Input(shape=(timesteps,features), name='input_meta')\n",
    "    # lstm needs (samples,timesteps,features) tensor as the input\n",
    "    x1 = Bidirectional(LSTM(BATCH_SIZE, return_sequences=True, dropout=0.25, recurrent_dropout=0.1))(inp_meta) \n",
    "    x1, sent_coeffs1 = AttentionLayer(features,return_coefficients=True,name='sent_attention1')(x1)\n",
    "    #x1 = GlobalMaxPool1D()(x1)\n",
    "    #x1 = Dense(100, activation=\"relu\")(x1)\n",
    "    x1 = Dropout(0.25)(x1)\n",
    "    x1 = Dense(12, activation=\"softmax\")(x1) #output layer  \n",
    "    \n",
    "    \n",
    "      \n",
    "    \n",
    "    \"\"\"\n",
    "    Merging outputs of nlp and meta\n",
    "    \"\"\"\n",
    "    merge_meta_bert = concatenate([x1, y_out])\n",
    "\n",
    "\n",
    "    output_meta_bert = Dense(12, activation=\"softmax\")(merge_meta_bert)\n",
    "    model_meta_bert_combined = Model(inputs=[inp_meta, idx, masks], outputs=output_meta_bert)\n",
    "    \n",
    "    return model_meta_bert_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xG6A0LNAvI5b"
   },
   "source": [
    "# META BERT model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1299,
     "status": "ok",
     "timestamp": 1596808284714,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "T7uwFVM_vCeg"
   },
   "outputs": [],
   "source": [
    "def execute_bilstm_meta_bert_channel(i):\n",
    "\n",
    "  \"\"\"\n",
    "  meta data\n",
    "  \"\"\"\n",
    "  df_train_meta, df_test_meta, df_Y_train_meta, df_Y_test_meta = get_metadata_features(i)\n",
    "  train_meta = df_train_meta.values\n",
    "  test_meta = df_test_meta.values\n",
    "      \n",
    "  timestamp = 1 #number of successive sequences combined\n",
    "      \n",
    "  r, c = df_train_meta.shape\n",
    "  staggering = r - timestamp + 1 # final number of instances generated \n",
    "  X_train_reshaped_meta = np.concatenate([train_meta[x:x+timestamp,:] for x in range(r-timestamp+1)])\n",
    "  X_train_reshaped_meta = X_train_reshaped_meta.reshape(staggering, timestamp, c) # c is the number of features\n",
    "    \n",
    "  r2, c2 = df_test_meta.shape\n",
    "  staggering2 = r2 - timestamp + 1 # final number of instances generated \n",
    "  X_test_reshaped_meta = np.concatenate([test_meta[x:x+timestamp,:] for x in range(r2-timestamp+1)])\n",
    "  X_test_reshaped_meta = X_test_reshaped_meta.reshape(staggering2, timestamp, c2) # c is the number of features\n",
    "      \n",
    "  print(\"Meta data\\n------------------\")\n",
    "  print(\"Training set\\n------------------\")\n",
    "  print(X_train_reshaped_meta)\n",
    "  print(X_train_reshaped_meta.shape)\n",
    "      \n",
    "  print(\"Meta data\\n------------------\")\n",
    "  print(\"Test set\\n------------------\")\n",
    "  print(X_test_reshaped_meta)\n",
    "  print(X_test_reshaped_meta.shape)\n",
    "      \n",
    "  df_Y_train_meta = df_Y_train_meta.iloc[timestamp-1:,]\n",
    "  df_Y_test_meta = df_Y_test_meta.iloc[timestamp-1:,]\n",
    "  \n",
    "  \n",
    "  print(\"Output Labels\\n------------------\")\n",
    "  print(df_Y_train_meta.shape, df_Y_test_meta.shape)\n",
    "\n",
    "  \"\"\"\n",
    "  bert data\n",
    "  \"\"\"\n",
    "  df_train_bert,df_test_bert,df_Y_train_bert,df_Y_test_bert = load_files(i)\n",
    "  y_train_bert = df_Y_train_bert['Speech_acts'].to_list()\n",
    "  y_test_bert = df_Y_test_bert['Speech_acts'].to_list()\n",
    "  X_train_id, X_train_mask, X_test_id, X_test_mask = generate_maskid(df_train_bert,df_test_bert)\n",
    "      \n",
    "  model_meta_bert = create_bilstm_meta_bert_channels(X_train_reshaped_meta)\n",
    "\n",
    "\n",
    "  print(\"\\n\\n THESE ARE THE LAYERS\")\n",
    "  for layer in model_meta_bert.layers[:5]:\n",
    "    if(layer.name == 'input_meta' or layer.name == 'bidirectional'):\n",
    "      layer.trainable = True\n",
    "    else:\n",
    "      layer.trainable = False\n",
    "\n",
    "  model_meta_bert.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['binary_accuracy', 'categorical_accuracy'])\n",
    "  model_meta_bert.summary()\n",
    "\n",
    "\n",
    "  \"\"\"\n",
    "  encoding the output labels\n",
    "  \"\"\"\n",
    "      \n",
    "  encoder = LabelEncoder()\n",
    "  encoder.fit(y_train_bert)\n",
    "  training_op_labels_encoded = encoder.transform(y_train_bert)\n",
    "  test_op_labels_encoded = encoder.transform(y_test_bert)\n",
    "  print(\"Output Labels\\n-------------------\")\n",
    "  print(training_op_labels_encoded.shape, test_op_labels_encoded.shape)\n",
    "      \n",
    "  \"\"\"\n",
    "  converting the output labels to one-hot form\n",
    "  \"\"\"\n",
    "  training_op_labels_onehot= np_utils.to_categorical(training_op_labels_encoded)\n",
    "  test_op_labels_onehot = np_utils.to_categorical(test_op_labels_encoded)\n",
    "\n",
    "  print(training_op_labels_onehot.shape, len(training_op_labels_onehot))\n",
    "  print(test_op_labels_onehot.shape, len(test_op_labels_onehot))\n",
    "\n",
    "\n",
    "  X_train_reshaped_meta = np.asarray(X_train_reshaped_meta, dtype='float32')\n",
    "  #training_op_labels_onehot = tf.convert_to_tensor(training_op_labels_onehot)\n",
    "  \n",
    "  \n",
    "  model_meta_bert_train = model_meta_bert.fit(x=[X_train_reshaped_meta,X_train_id,X_train_mask], y=training_op_labels_onehot,batch_size=BATCH_SIZE, epochs=EPOCHS,  validation_split=0.1)\n",
    "  # load model if required \n",
    "  # compile model\n",
    "\n",
    "\n",
    "  model_meta_bert.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['binary_accuracy', 'categorical_accuracy'])\n",
    "      \n",
    "  # evaluate model\n",
    "  print(model_meta_bert.metrics_names)\n",
    "  #change the input_\n",
    "\n",
    "  #loss, binary_accuracy, categorical_accuracy = model_nlp_bert.evaluate(x=[X_test_reshaped_nlp,X_test_id,X_test_mask], y=test_op_labels_onehot,batch_size=BATCH_SIZE,verbose=1)\n",
    "      \n",
    "  #print(loss, binary_accuracy, categorical_accuracy)\n",
    "      \n",
    "\n",
    "  \"\"\"\n",
    "  predict the probabilty of output classes\n",
    "  and pick the best one\n",
    "  \"\"\"\n",
    "  #change the input_\n",
    "\n",
    "  X_test_reshaped_meta = np.asarray(X_test_reshaped_meta, dtype='float32')\n",
    "  prediction_vector = model_meta_bert.predict(x=[X_test_reshaped_meta,X_test_id,X_test_mask], \\\n",
    "                            batch_size=BATCH_SIZE,\\\n",
    "                            verbose=1)\n",
    "  predicted_classes = np.argmax(prediction_vector, axis=1)\n",
    "  original_classes = np.argmax(test_op_labels_onehot, axis=1)\n",
    "  accuracy = metrics.accuracy_score(original_classes, predicted_classes)\n",
    "\n",
    "  print(\"ACCURACY:\")\n",
    "  print(accuracy)\n",
    "      \n",
    "  \"\"\"\n",
    "  # verification of correctness:\n",
    "  total_correct = sum(original_classes == predicted_classes)\n",
    "  print(\"Total number of correct predictions:\",total_correct)\n",
    "  print(\"Accuracy:\",total_correct/len(test_op_labels_onehot))\n",
    "  acc = np.sum(conf_mat.diagonal()) / np.sum(conf_mat)\n",
    "  print('Overall accuracy: {} %'.format(acc*100))\n",
    "  \"\"\"\n",
    "  conf_mat = confusion_matrix(predicted_classes, original_classes)\n",
    "  print(\"\\n\", conf_mat, \"\\n\")\n",
    "      \n",
    "  return predicted_classes, accuracy, conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vL9o8LMEydoI"
   },
   "source": [
    "# Main Method and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 157319,
     "status": "ok",
     "timestamp": 1596808442597,
     "user": {
      "displayName": "Satanu Ghosh",
      "photoUrl": "",
      "userId": "04517623213450830512"
     },
     "user_tz": -330
    },
    "id": "1U29WTZGyg-J",
    "outputId": "d10b7087-90c1-4b88-e0d1-d217324d8e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside get_metadata_features\n",
      "Meta data\n",
      "------------------\n",
      "Training set\n",
      "------------------\n",
      "[[[7.0 2.0 0 ... 10 10 1]]\n",
      "\n",
      " [[1.0 2.0 1 ... 12 12 4]]\n",
      "\n",
      " [[26.0 5.0 0 ... 10 10 3]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[5.0 4.0 1 ... 1 9 1]]\n",
      "\n",
      " [[53.0 38.0 0 ... 10 2 3]]\n",
      "\n",
      " [[11.0 7.0 1 ... 9 9 4]]]\n",
      "(1467, 1, 8)\n",
      "Meta data\n",
      "------------------\n",
      "Test set\n",
      "------------------\n",
      "[[[23.0 14.0 0 ... 1 2 3]]\n",
      "\n",
      " [[16.0 22.0 0 ... 9 9 2]]\n",
      "\n",
      " [[36.0 8.0 0 ... 1 1 1]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[2.0 5.0 0 ... 12 12 2]]\n",
      "\n",
      " [[16.0 12.0 0 ... 1 4 3]]\n",
      "\n",
      " [[29.0 7.0 0 ... 1 2 3]]]\n",
      "(367, 1, 8)\n",
      "Output Labels\n",
      "------------------\n",
      "(1467, 1) (367, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "\n",
      " THESE ARE THE LAYERS\n",
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_meta (InputLayer)         [(None, 1, 8)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_idx (InputLayer)          [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1, 64)        10496       input_meta[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_3 (TFDisti ((None, 150, 768),)  66362880    input_idx[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sent_attention1 (AttentionLayer [(None, 64), (None,  528         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 768)          0           tf_distil_bert_model_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)           (None, 64)           0           sent_attention1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           49216       global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 12)           780         dropout_116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 12)           780         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 24)           0           dense_14[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 12)           300         concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 66,424,980\n",
      "Trainable params: 51,604\n",
      "Non-trainable params: 66,373,376\n",
      "__________________________________________________________________________________________________\n",
      "Output Labels\n",
      "-------------------\n",
      "(1467,) (367,)\n",
      "(1467, 12) 1467\n",
      "(367, 12) 367\n",
      "42/42 [==============================] - 9s 219ms/step - loss: 2.3692 - binary_accuracy: 0.9167 - categorical_accuracy: 0.1932 - val_loss: 2.2443 - val_binary_accuracy: 0.9167 - val_categorical_accuracy: 0.3401\n",
      "[]\n",
      "12/12 [==============================] - 2s 134ms/step\n",
      "ACCURACY:\n",
      "0.3024523160762943\n",
      "\n",
      " [[ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0 32  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [24 10  0 17  2  1 48  2  3  0 23]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [46  8  8  7 59  4  3 34  2  1 31]] \n",
      "\n",
      "Inside get_metadata_features\n",
      "Meta data\n",
      "------------------\n",
      "Training set\n",
      "------------------\n",
      "[[[4.0 8.0 0 ... 6 6 1]]\n",
      "\n",
      " [[7.0 7.0 0 ... 1 1 2]]\n",
      "\n",
      " [[25.0 20.0 1 ... 10 2 2]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[7.0 8.0 1 ... 11 4 3]]\n",
      "\n",
      " [[14.0 7.0 1 ... 1 5 3]]\n",
      "\n",
      " [[4.0 7.0 1 ... 6 6 2]]]\n",
      "(1467, 1, 8)\n",
      "Meta data\n",
      "------------------\n",
      "Test set\n",
      "------------------\n",
      "[[[1.0 5.0 0 ... 12 12 4]]\n",
      "\n",
      " [[7.0 6.0 0 ... 6 6 2]]\n",
      "\n",
      " [[32.0 2.0 1 ... 6 5 3]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[2.0 6.0 0 ... 12 12 1]]\n",
      "\n",
      " [[54.0 8.0 0 ... 1 1 2]]\n",
      "\n",
      " [[17.0 6.0 0 ... 1 1 2]]]\n",
      "(367, 1, 8)\n",
      "Output Labels\n",
      "------------------\n",
      "(1467, 1) (367, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "\n",
      " THESE ARE THE LAYERS\n",
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_meta (InputLayer)         [(None, 1, 8)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_idx (InputLayer)          [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1, 64)        10496       input_meta[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_4 (TFDisti ((None, 150, 768),)  66362880    input_idx[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sent_attention1 (AttentionLayer [(None, 64), (None,  528         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 768)          0           tf_distil_bert_model_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)           (None, 64)           0           sent_attention1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 64)           49216       global_average_pooling1d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 12)           780         dropout_136[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 12)           780         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 24)           0           dense_18[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 12)           300         concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 66,424,980\n",
      "Trainable params: 51,604\n",
      "Non-trainable params: 66,373,376\n",
      "__________________________________________________________________________________________________\n",
      "Output Labels\n",
      "-------------------\n",
      "(1467,) (367,)\n",
      "(1467, 12) 1467\n",
      "(367, 12) 367\n",
      "42/42 [==============================] - 9s 220ms/step - loss: 2.3586 - binary_accuracy: 0.9167 - categorical_accuracy: 0.2364 - val_loss: 2.2199 - val_binary_accuracy: 0.9167 - val_categorical_accuracy: 0.4354\n",
      "[]\n",
      "12/12 [==============================] - 2s 135ms/step\n",
      "ACCURACY:\n",
      "0.4550408719346049\n",
      "\n",
      " [[79  2  1  1 17  1 66 28  9  0  2 27]\n",
      " [ 0  2  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 44  0  0  0  0  0  1  0  0]\n",
      " [ 2  4  6  6 33  0  0  1  2  0  0 10]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  9  1  1  0  0  0  0  0  1  0  9]] \n",
      "\n",
      "Inside get_metadata_features\n",
      "Meta data\n",
      "------------------\n",
      "Training set\n",
      "------------------\n",
      "[[[7.0 6.0 0 ... 1 1 2]]\n",
      "\n",
      " [[7.0 15.0 1 ... 1 5 1]]\n",
      "\n",
      " [[18.0 5.0 0 ... 10 10 3]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[24.0 15.0 0 ... 11 11 3]]\n",
      "\n",
      " [[30.0 7.0 1 ... 10 4 4]]\n",
      "\n",
      " [[8.0 9.0 0 ... 6 6 1]]]\n",
      "(1467, 1, 8)\n",
      "Meta data\n",
      "------------------\n",
      "Test set\n",
      "------------------\n",
      "[[[13.0 67.0 0 ... 9 9 3]]\n",
      "\n",
      " [[1.0 5.0 1 ... 12 12 3]]\n",
      "\n",
      " [[15.0 24.0 0 ... 1 2 3]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[10.0 11.0 1 ... 6 4 2]]\n",
      "\n",
      " [[22.0 35.0 0 ... 9 9 3]]\n",
      "\n",
      " [[30.0 7.0 0 ... 7 7 3]]]\n",
      "(367, 1, 8)\n",
      "Output Labels\n",
      "------------------\n",
      "(1467, 1) (367, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "\n",
      " THESE ARE THE LAYERS\n",
      "Model: \"functional_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_meta (InputLayer)         [(None, 1, 8)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_idx (InputLayer)          [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1, 64)        10496       input_meta[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_5 (TFDisti ((None, 150, 768),)  66362880    input_idx[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sent_attention1 (AttentionLayer [(None, 64), (None,  528         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 768)          0           tf_distil_bert_model_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_156 (Dropout)           (None, 64)           0           sent_attention1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 64)           49216       global_average_pooling1d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 12)           780         dropout_156[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 12)           780         dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 24)           0           dense_22[0][0]                   \n",
      "                                                                 dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 12)           300         concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 66,424,980\n",
      "Trainable params: 51,604\n",
      "Non-trainable params: 66,373,376\n",
      "__________________________________________________________________________________________________\n",
      "Output Labels\n",
      "-------------------\n",
      "(1467,) (367,)\n",
      "(1467, 12) 1467\n",
      "(367, 12) 367\n",
      "42/42 [==============================] - 9s 220ms/step - loss: 2.3383 - binary_accuracy: 0.9167 - categorical_accuracy: 0.3182 - val_loss: 2.2051 - val_binary_accuracy: 0.9167 - val_categorical_accuracy: 0.3946\n",
      "[]\n",
      "12/12 [==============================] - 2s 137ms/step\n",
      "ACCURACY:\n",
      "0.3869209809264305\n",
      "\n",
      " [[ 7  4  0  0  0  0 19  3  1  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0 48  0  0  0  0  0  1  0]\n",
      " [ 0  0  3  0 43  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  1  0  4  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [68 17  3  1  0  5 45 32 11  1 44]] \n",
      "\n",
      "Inside get_metadata_features\n",
      "Meta data\n",
      "------------------\n",
      "Training set\n",
      "------------------\n",
      "[[[14.0 5.0 0 ... 1 1 4]]\n",
      "\n",
      " [[36.0 11.0 0 ... 1 2 2]]\n",
      "\n",
      " [[24.0 24.0 1 ... 1 4 3]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[8.0 5.0 1 ... 1 4 4]]\n",
      "\n",
      " [[4.0 31.0 0 ... 1 1 4]]\n",
      "\n",
      " [[8.0 22.0 0 ... 6 2 4]]]\n",
      "(1467, 1, 8)\n",
      "Meta data\n",
      "------------------\n",
      "Test set\n",
      "------------------\n",
      "[[[11.0 17.0 0 ... 1 2 3]]\n",
      "\n",
      " [[24.0 55.0 0 ... 11 11 1]]\n",
      "\n",
      " [[4.0 34.0 0 ... 1 1 3]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[31.0 11.0 0 ... 10 10 3]]\n",
      "\n",
      " [[40.0 22.0 1 ... 1 4 3]]\n",
      "\n",
      " [[39.0 5.0 1 ... 9 4 3]]]\n",
      "(367, 1, 8)\n",
      "Output Labels\n",
      "------------------\n",
      "(1467, 1) (367, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "\n",
      " THESE ARE THE LAYERS\n",
      "Model: \"functional_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_meta (InputLayer)         [(None, 1, 8)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_idx (InputLayer)          [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1, 64)        10496       input_meta[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_6 (TFDisti ((None, 150, 768),)  66362880    input_idx[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sent_attention1 (AttentionLayer [(None, 64), (None,  528         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 768)          0           tf_distil_bert_model_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_176 (Dropout)           (None, 64)           0           sent_attention1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 64)           49216       global_average_pooling1d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 12)           780         dropout_176[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 12)           780         dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 24)           0           dense_26[0][0]                   \n",
      "                                                                 dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 12)           300         concatenate_6[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 66,424,980\n",
      "Trainable params: 51,604\n",
      "Non-trainable params: 66,373,376\n",
      "__________________________________________________________________________________________________\n",
      "Output Labels\n",
      "-------------------\n",
      "(1467,) (367,)\n",
      "(1467, 12) 1467\n",
      "(367, 12) 367\n",
      "42/42 [==============================] - 10s 229ms/step - loss: 2.3465 - binary_accuracy: 0.9167 - categorical_accuracy: 0.2439 - val_loss: 2.2603 - val_binary_accuracy: 0.9167 - val_categorical_accuracy: 0.3061\n",
      "[]\n",
      "12/12 [==============================] - 2s 136ms/step\n",
      "ACCURACY:\n",
      "0.2779291553133515\n",
      "\n",
      " [[ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [62 18  1 41  1  5 73 19 11  5 41]\n",
      " [ 7  0  2  0 59  0  0  8  3  0  4]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  1  0  1  0  2]] \n",
      "\n",
      "Inside get_metadata_features\n",
      "Meta data\n",
      "------------------\n",
      "Training set\n",
      "------------------\n",
      "[[[36.0 1.0 1 ... 1 5 3]]\n",
      "\n",
      " [[26.0 6.0 0 ... 1 1 3]]\n",
      "\n",
      " [[7.0 11.0 1 ... 1 5 1]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[21.0 18.0 0 ... 1 2 1]]\n",
      "\n",
      " [[8.0 6.0 0 ... 10 10 3]]\n",
      "\n",
      " [[4.0 2.0 0 ... 1 1 3]]]\n",
      "(1467, 1, 8)\n",
      "Meta data\n",
      "------------------\n",
      "Test set\n",
      "------------------\n",
      "[[[3.0 3.0 1 ... 12 12 3]]\n",
      "\n",
      " [[6.0 4.0 0 ... 1 1 2]]\n",
      "\n",
      " [[12.0 106.0 0 ... 1 2 2]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[14.0 9.0 1 ... 1 5 2]]\n",
      "\n",
      " [[5.0 10.0 0 ... 1 12 3]]\n",
      "\n",
      " [[8.0 3.0 0 ... 1 1 3]]]\n",
      "(367, 1, 8)\n",
      "Output Labels\n",
      "------------------\n",
      "(1467, 1) (367, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "\n",
      " THESE ARE THE LAYERS\n",
      "Model: \"functional_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_meta (InputLayer)         [(None, 1, 8)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_idx (InputLayer)          [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1, 64)        10496       input_meta[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_7 (TFDisti ((None, 150, 768),)  66362880    input_idx[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sent_attention1 (AttentionLayer [(None, 64), (None,  528         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 768)          0           tf_distil_bert_model_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_196 (Dropout)           (None, 64)           0           sent_attention1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 64)           49216       global_average_pooling1d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 12)           780         dropout_196[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 12)           780         dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 24)           0           dense_30[0][0]                   \n",
      "                                                                 dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 12)           300         concatenate_7[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 66,424,980\n",
      "Trainable params: 51,604\n",
      "Non-trainable params: 66,373,376\n",
      "__________________________________________________________________________________________________\n",
      "Output Labels\n",
      "-------------------\n",
      "(1467,) (367,)\n",
      "(1467, 12) 1467\n",
      "(367, 12) 367\n",
      "42/42 [==============================] - 9s 222ms/step - loss: 2.3614 - binary_accuracy: 0.9167 - categorical_accuracy: 0.1561 - val_loss: 2.2771 - val_binary_accuracy: 0.9167 - val_categorical_accuracy: 0.1769\n",
      "[]\n",
      "12/12 [==============================] - 2s 138ms/step\n",
      "ACCURACY:\n",
      "0.26975476839237056\n",
      "\n",
      " [[42  2  0  4  1  0 50 13  7  1  1 13]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [41 17  0 52  2  3  8 23  3  3  0 19]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  6  0 50  0  0  1  0  0  0  5]] \n",
      "\n",
      "Inside get_metadata_features\n",
      "Meta data\n",
      "------------------\n",
      "Training set\n",
      "------------------\n",
      "[[[12.0 10.0 0 ... 12 12 4]]\n",
      "\n",
      " [[9.0 3.0 0 ... 1 1 3]]\n",
      "\n",
      " [[40.0 50.0 0 ... 10 2 3]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[36.0 8.0 0 ... 1 1 1]]\n",
      "\n",
      " [[38.0 8.0 1 ... 1 9 3]]\n",
      "\n",
      " [[10.0 5.0 1 ... 1 4 4]]]\n",
      "(1467, 1, 8)\n",
      "Meta data\n",
      "------------------\n",
      "Test set\n",
      "------------------\n",
      "[[[1.0 2.0 1 ... 12 12 3]]\n",
      "\n",
      " [[10.0 12.0 0 ... 10 2 3]]\n",
      "\n",
      " [[15.0 26.0 0 ... 6 6 3]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[4.0 6.0 0 ... 1 1 3]]\n",
      "\n",
      " [[28.0 8.0 0 ... 9 2 2]]\n",
      "\n",
      " [[24.0 4.0 0 ... 10 10 1]]]\n",
      "(367, 1, 8)\n",
      "Output Labels\n",
      "------------------\n",
      "(1467, 1) (367, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "\n",
      " THESE ARE THE LAYERS\n",
      "Model: \"functional_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_meta (InputLayer)         [(None, 1, 8)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_idx (InputLayer)          [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1, 64)        10496       input_meta[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_8 (TFDisti ((None, 150, 768),)  66362880    input_idx[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sent_attention1 (AttentionLayer [(None, 64), (None,  528         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 768)          0           tf_distil_bert_model_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_216 (Dropout)           (None, 64)           0           sent_attention1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 64)           49216       global_average_pooling1d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 12)           780         dropout_216[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 12)           780         dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 24)           0           dense_34[0][0]                   \n",
      "                                                                 dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 12)           300         concatenate_8[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 66,424,980\n",
      "Trainable params: 51,604\n",
      "Non-trainable params: 66,373,376\n",
      "__________________________________________________________________________________________________\n",
      "Output Labels\n",
      "-------------------\n",
      "(1467,) (367,)\n",
      "(1467, 12) 1467\n",
      "(367, 12) 367\n",
      "42/42 [==============================] - 9s 222ms/step - loss: 2.3419 - binary_accuracy: 0.9167 - categorical_accuracy: 0.2492 - val_loss: 2.2524 - val_binary_accuracy: 0.9167 - val_categorical_accuracy: 0.3401\n",
      "[]\n",
      "12/12 [==============================] - 2s 138ms/step\n",
      "ACCURACY:\n",
      "0.3188010899182561\n",
      "\n",
      " [[71 14  3  0  5  4 63 37  9  0  1 46]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  4  7 54 46  0  0  0  0  3  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "tf_config = tf.compat.v1.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "tf_config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "tf_config.allow_soft_placement = True\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Bidirectional, GlobalMaxPool1D, GlobalAveragePooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, model_from_json\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# checkpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.layers import Attention\n",
    "\n",
    "\"\"\"\n",
    "Required for NLP model\n",
    "\"\"\"\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()   \n",
    "\n",
    "# set parameters for word embeddings\n",
    "embed_size = 100 # how big is each word vector\n",
    "vocab_size = 25000 # how many unique words to use (i.e num rows in embedding vector) max\n",
    "input_length = 100 # max number of words in the input \n",
    "\n",
    "#set parameters for bilstm\n",
    "BATCH_SIZE=32\n",
    "EPOCHS=1 #300\n",
    "\n",
    "#EMBEDDING_FILE='glove.6B.100d.txt'    \n",
    "\n",
    "file = open('/content/drive/My Drive/Python Notebook/SCS_CONVEX/output/meta-bert-attn/bilstm_meta_bert_attn_op.txt','w') #overwrites previous\n",
    "file.close()\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    df_prediction = pd.DataFrame()\n",
    "    df_accuracy =  pd.DataFrame()\n",
    "    file = open('/content/drive/My Drive/Python Notebook/SCS_CONVEX/output/meta-bert-attn/bilstm_meta_bert_attn_op.txt','a') #append mode \n",
    "    \"\"\"\n",
    "    Change the range before executing\n",
    "    \"\"\"\n",
    "    for i in range(5,11):\n",
    "        outputname = 'meta_bert_attn'+ str(i)        \n",
    "        predictions, acc, conf_matrix = execute_bilstm_meta_bert_channel(i)\n",
    "        df_prediction[outputname] = predictions\n",
    "        df_accuracy[i] = [acc]\n",
    "        file.write(\"\\nIteration:\" + str(i) + \"\\nCategorical Accuracy:\" + str(acc) + \n",
    "                    \"\\nConfusion Matrix:\\n\" + str(conf_matrix) + \"\\n\\n\")\n",
    "        df_prediction.to_csv('/content/drive/My Drive/Python Notebook/SCS_CONVEX/output/meta-bert-attn/predictions_bilstm_meta_bert_attn_' + str(i) + '.csv')    \n",
    "        df_accuracy.to_csv('/content/drive/My Drive/Python Notebook/SCS_CONVEX/output/meta-bert-attn/accuracy_bilstm_meta_bert_attn_' + str(i) + '.csv')    \n",
    "    \n",
    "    df_prediction.to_csv('/content/drive/My Drive/Python Notebook/SCS_CONVEX/output/meta-bert-attn/predictions_bilstm_meta_bert_attn.csv')    \n",
    "    df_accuracy.to_csv('/content/drive/My Drive/Python Notebook/SCS_CONVEX/output/meta-bert-attn/accuracy_bilstm_meta_bert_attn.csv')    \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NeapZe3j6XUn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP8uhDqZLetdNdJZgMQdFaD",
   "collapsed_sections": [
    "7qHEd58YoMdL",
    "g9dNbyTVomQB"
   ],
   "name": "meta_bert_attn_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00004b34205c4414ad59a86460d1eb16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "05247ce9a2d24cabbab4cd0cc20f16c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_38747afd44ed42788ae8c197d642eacf",
       "IPY_MODEL_8338cb44f04a4e099debb6edbdf93ad5"
      ],
      "layout": "IPY_MODEL_6f0ed3a6e5224ab5b50bd50029613414"
     }
    },
    "08a2c8ed74bf4cd08c5939eaa12c6c30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_824f91d723884145ae508fedcecd83fc",
       "IPY_MODEL_6409a1f0c8304c43af822fd007bc978d"
      ],
      "layout": "IPY_MODEL_5e84a75672ef4d288f69c496dddd9d5d"
     }
    },
    "0c3eadb86f284d8fb0e1b27e67aa2553": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1527e8a6f0cc461bbefcb92746618ac6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "194f670ca18c437ba540378aa527749b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "294ebad7ff094513a0b3c9d00704946c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ac379847d5fd4686a6c7fb6f2ec71cf6",
       "IPY_MODEL_a887a85d22f14c4aa515acb63009e3d9"
      ],
      "layout": "IPY_MODEL_1527e8a6f0cc461bbefcb92746618ac6"
     }
    },
    "38747afd44ed42788ae8c197d642eacf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fefed274e3814140b0cb304103744020",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46ea1cf3050e46b69e1c9d9a67804fe9",
      "value": 231508
     }
    },
    "3cec680932da4b50b9158a7dd18f3bcf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46ea1cf3050e46b69e1c9d9a67804fe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4a46cff0310646c192ed258a156d083f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e84a75672ef4d288f69c496dddd9d5d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6409a1f0c8304c43af822fd007bc978d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_194f670ca18c437ba540378aa527749b",
      "placeholder": "​",
      "style": "IPY_MODEL_e0b235adf4b94ff8a0ac3d480f4dc986",
      "value": " 363M/363M [00:19&lt;00:00, 18.5MB/s]"
     }
    },
    "65e1f222b7754b7b8c71e4120cc5bb42": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f0ed3a6e5224ab5b50bd50029613414": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "824f91d723884145ae508fedcecd83fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3cec680932da4b50b9158a7dd18f3bcf",
      "max": 363423424,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0c3eadb86f284d8fb0e1b27e67aa2553",
      "value": 363423424
     }
    },
    "8338cb44f04a4e099debb6edbdf93ad5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65e1f222b7754b7b8c71e4120cc5bb42",
      "placeholder": "​",
      "style": "IPY_MODEL_00004b34205c4414ad59a86460d1eb16",
      "value": " 232k/232k [00:00&lt;00:00, 1.04MB/s]"
     }
    },
    "a887a85d22f14c4aa515acb63009e3d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b65011f77e124c0ab8a33171d5be282f",
      "placeholder": "​",
      "style": "IPY_MODEL_b0e5f89d621d40af9664f6b0e1ef373b",
      "value": " 442/442 [00:00&lt;00:00, 5.36kB/s]"
     }
    },
    "aa6c68a500484e15bb2e0bf54609c8a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ac379847d5fd4686a6c7fb6f2ec71cf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a46cff0310646c192ed258a156d083f",
      "max": 442,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aa6c68a500484e15bb2e0bf54609c8a2",
      "value": 442
     }
    },
    "b0e5f89d621d40af9664f6b0e1ef373b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b65011f77e124c0ab8a33171d5be282f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0b235adf4b94ff8a0ac3d480f4dc986": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fefed274e3814140b0cb304103744020": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
